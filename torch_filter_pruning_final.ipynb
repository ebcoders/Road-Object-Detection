{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "070d82c0bb98406f8098343bd80c80c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_628c112490534fb58623569b7b8ef773",
              "IPY_MODEL_0ff96f4ed59447b499d8907a45582d40",
              "IPY_MODEL_2c93b94d732049de98cc1537e43419e4"
            ],
            "layout": "IPY_MODEL_dc1d352ab5504101a152495e3a2435de"
          }
        },
        "628c112490534fb58623569b7b8ef773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92579fc965b45ffbb41a2d39233d532",
            "placeholder": "​",
            "style": "IPY_MODEL_84916d4216c248d7a0c16a156f769494",
            "value": "Epoch 1 Training: 100%"
          }
        },
        "0ff96f4ed59447b499d8907a45582d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187445f64c654066923c2fc4a51f5b7f",
            "max": 879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_093b7a2927a64c539b1c6689b67adf7b",
            "value": 879
          }
        },
        "2c93b94d732049de98cc1537e43419e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2069ec7d9cbd494490ebee9051bb2118",
            "placeholder": "​",
            "style": "IPY_MODEL_dc527372008340249196492250f964da",
            "value": " 879/879 [24:55&lt;00:00,  1.94s/it, loss=0.0036, avg_loss=9.1055]"
          }
        },
        "dc1d352ab5504101a152495e3a2435de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e92579fc965b45ffbb41a2d39233d532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84916d4216c248d7a0c16a156f769494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "187445f64c654066923c2fc4a51f5b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "093b7a2927a64c539b1c6689b67adf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2069ec7d9cbd494490ebee9051bb2118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc527372008340249196492250f964da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d80868e3fb46d0b5b17cded7b5c704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b389649b534b9fbd934ce7a237a40d",
              "IPY_MODEL_2b13b5906b3a41bfb3001539099f5c04",
              "IPY_MODEL_3f0e6e7e129d4c8093c1a08b0f668ed3"
            ],
            "layout": "IPY_MODEL_d94117748ff041b38406bb4c75d50f2c"
          }
        },
        "b3b389649b534b9fbd934ce7a237a40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f0f555ab824517b65f71795cf985c2",
            "placeholder": "​",
            "style": "IPY_MODEL_cf51d318d2b64f4f9caba663940eac23",
            "value": "Epoch 1 Validation: 100%"
          }
        },
        "2b13b5906b3a41bfb3001539099f5c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311dc8d714f64984a177b3df76b15f92",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_599957a2d965433fa2e12b88bf4434eb",
            "value": 49
          }
        },
        "3f0e6e7e129d4c8093c1a08b0f668ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f8fdbb27d94871a6cef7ddf4b00dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_86c3f2f80f08421dbf01a409f546e665",
            "value": " 49/49 [01:45&lt;00:00,  2.50s/it]"
          }
        },
        "d94117748ff041b38406bb4c75d50f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e4f0f555ab824517b65f71795cf985c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf51d318d2b64f4f9caba663940eac23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311dc8d714f64984a177b3df76b15f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599957a2d965433fa2e12b88bf4434eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0f8fdbb27d94871a6cef7ddf4b00dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c3f2f80f08421dbf01a409f546e665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63949660e46e4650a4722b0787588102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_914b1ff30308476abf265309fbe99228",
              "IPY_MODEL_f87a2576411f4f128b3074919fcbf519",
              "IPY_MODEL_e61df5b388804e1b8fc654550b791adb"
            ],
            "layout": "IPY_MODEL_982ed36a62114e5ab76a2a217daf91f3"
          }
        },
        "914b1ff30308476abf265309fbe99228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c77e084b934f86baecd25f689d53ad",
            "placeholder": "​",
            "style": "IPY_MODEL_91cc31f82f954fb5b393e025e6bb7854",
            "value": "Epoch 2 Training: 100%"
          }
        },
        "f87a2576411f4f128b3074919fcbf519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f26466c45c8b47e0912975a0736390ce",
            "max": 879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c995dc2f89e74266911a6d2be6b62b79",
            "value": 879
          }
        },
        "e61df5b388804e1b8fc654550b791adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710ec358e3e14292be1456e43ab2d5e7",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2e5f799d6f46a0a542bd5ffd5fefc9",
            "value": " 879/879 [15:30&lt;00:00,  1.06s/it, loss=0.0004, avg_loss=0.0011]"
          }
        },
        "982ed36a62114e5ab76a2a217daf91f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "08c77e084b934f86baecd25f689d53ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cc31f82f954fb5b393e025e6bb7854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f26466c45c8b47e0912975a0736390ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c995dc2f89e74266911a6d2be6b62b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "710ec358e3e14292be1456e43ab2d5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2e5f799d6f46a0a542bd5ffd5fefc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "605c4b4ebabe4e768544ae31065746b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fe5538f52674fa5ae3cd7330f47e194",
              "IPY_MODEL_d22414fc7ba041149014d62a7729e4a3",
              "IPY_MODEL_efd5b3b44d5d4a179facdc879105caed"
            ],
            "layout": "IPY_MODEL_466c44337b5d4a2e9dfe5e208031918a"
          }
        },
        "0fe5538f52674fa5ae3cd7330f47e194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1eb525ac5e4cd59491610174ecec59",
            "placeholder": "​",
            "style": "IPY_MODEL_f0c32b88719a4f7495f8a3e1681322e0",
            "value": "Epoch 2 Validation: 100%"
          }
        },
        "d22414fc7ba041149014d62a7729e4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffa10b606a24ec086dfebe66c09610f",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd1f1f6f6ca044f0aa30b4fb7c38386a",
            "value": 49
          }
        },
        "efd5b3b44d5d4a179facdc879105caed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81141a34b524bc8b94a406b7a3a8a65",
            "placeholder": "​",
            "style": "IPY_MODEL_fd2a8275f20648e2ab757a707546e092",
            "value": " 49/49 [00:41&lt;00:00,  1.22it/s]"
          }
        },
        "466c44337b5d4a2e9dfe5e208031918a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bf1eb525ac5e4cd59491610174ecec59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c32b88719a4f7495f8a3e1681322e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ffa10b606a24ec086dfebe66c09610f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1f1f6f6ca044f0aa30b4fb7c38386a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b81141a34b524bc8b94a406b7a3a8a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2a8275f20648e2ab757a707546e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9dd84d623b74c7db4a42660a834c435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3414eec5d6c74af8a3db50600fe0b0f5",
              "IPY_MODEL_b5672fa7860a43e3ba842aa9255db302",
              "IPY_MODEL_910890650790490ab5b6f0d15a5c86c7"
            ],
            "layout": "IPY_MODEL_f3c35a1ae96147fd93071ebf4997aec0"
          }
        },
        "3414eec5d6c74af8a3db50600fe0b0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd0ec61362c4f00b0a408ac7968a717",
            "placeholder": "​",
            "style": "IPY_MODEL_43b492b1b18a4610a0e6e31882088591",
            "value": "Epoch 3 Training: 100%"
          }
        },
        "b5672fa7860a43e3ba842aa9255db302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcab443238164624a753ab50c661461c",
            "max": 879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e83c1c01c2241618aaffa7f398f4304",
            "value": 879
          }
        },
        "910890650790490ab5b6f0d15a5c86c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a351f0e6a4e4a42a081f0e6fc4ac60b",
            "placeholder": "​",
            "style": "IPY_MODEL_8c593136ba21491bb340679c18f42318",
            "value": " 879/879 [15:31&lt;00:00,  1.04s/it, loss=0.0002, avg_loss=0.0003]"
          }
        },
        "f3c35a1ae96147fd93071ebf4997aec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8dd0ec61362c4f00b0a408ac7968a717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b492b1b18a4610a0e6e31882088591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcab443238164624a753ab50c661461c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e83c1c01c2241618aaffa7f398f4304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a351f0e6a4e4a42a081f0e6fc4ac60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c593136ba21491bb340679c18f42318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e9cf68f7890467ebfa1fcf8260c329d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f00a559f0a8488b96c06c3b51a677dd",
              "IPY_MODEL_e7c6e3b751484c84bdb7d4a22aaca50e",
              "IPY_MODEL_122e3914cf834675913696aa99c22eb6"
            ],
            "layout": "IPY_MODEL_6cf16609e30e4988bf680b1b7461c4b4"
          }
        },
        "8f00a559f0a8488b96c06c3b51a677dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b8c8b168454d468bfdaf4ed5b1bfb2",
            "placeholder": "​",
            "style": "IPY_MODEL_17e73a6045ce402381a73be9581789c2",
            "value": "Epoch 3 Validation: 100%"
          }
        },
        "e7c6e3b751484c84bdb7d4a22aaca50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adffe91038e34da29134028532021d4a",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e8f5cbec97f4194bf6f5810223c95bc",
            "value": 49
          }
        },
        "122e3914cf834675913696aa99c22eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab31e0a5224491380117186b1c59b84",
            "placeholder": "​",
            "style": "IPY_MODEL_c25cb53fa2014bff88c457b5b90bdcb6",
            "value": " 49/49 [00:41&lt;00:00,  1.21it/s]"
          }
        },
        "6cf16609e30e4988bf680b1b7461c4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "02b8c8b168454d468bfdaf4ed5b1bfb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e73a6045ce402381a73be9581789c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adffe91038e34da29134028532021d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8f5cbec97f4194bf6f5810223c95bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bab31e0a5224491380117186b1c59b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c25cb53fa2014bff88c457b5b90bdcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c1753369ea646c0b8275ff8d19dc47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91f3e8bb3b494d8898856c5fc31a79ee",
              "IPY_MODEL_579be0d454a64f118c2c56fb757add50",
              "IPY_MODEL_b1085c32153547f9b802fbad4b44d715"
            ],
            "layout": "IPY_MODEL_e8869ba5aff8459ca759475752d4d489"
          }
        },
        "91f3e8bb3b494d8898856c5fc31a79ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eae2c5b4b5e4ef1beb3e2602536d0f7",
            "placeholder": "​",
            "style": "IPY_MODEL_961652313228408dbd13bf970c4bf3ad",
            "value": "Epoch 4 Training: 100%"
          }
        },
        "579be0d454a64f118c2c56fb757add50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd946b05200c48349c2c646983840693",
            "max": 879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e305531b4fb24e4f84928292661283cd",
            "value": 879
          }
        },
        "b1085c32153547f9b802fbad4b44d715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_494f065a16bb488f9c76687399e166dc",
            "placeholder": "​",
            "style": "IPY_MODEL_ba604fff017b4363b9bffcd7ba7ab6af",
            "value": " 879/879 [15:32&lt;00:00,  1.09s/it, loss=0.0001, avg_loss=0.0001]"
          }
        },
        "e8869ba5aff8459ca759475752d4d489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3eae2c5b4b5e4ef1beb3e2602536d0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961652313228408dbd13bf970c4bf3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd946b05200c48349c2c646983840693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e305531b4fb24e4f84928292661283cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "494f065a16bb488f9c76687399e166dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba604fff017b4363b9bffcd7ba7ab6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7abccaee1624faf89ce4dadc9d25d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6688d574a9c4db4b2904291b7ef8838",
              "IPY_MODEL_52ce1a13935d4a5f9cc9850c7fbf0572",
              "IPY_MODEL_ef4153298be248a5a4df1417e9302003"
            ],
            "layout": "IPY_MODEL_c11e046dd3574ff2a9c28fab5c9ed9cd"
          }
        },
        "b6688d574a9c4db4b2904291b7ef8838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7513387f3a194dee8c600fbd8a337007",
            "placeholder": "​",
            "style": "IPY_MODEL_6e8f3d9e6a6e41d58df389f738b6bd69",
            "value": "Epoch 4 Validation: 100%"
          }
        },
        "52ce1a13935d4a5f9cc9850c7fbf0572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21dcb8b016e4c859e19c517bafa37ca",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b204dbded584004badcfbdb9b2b61fc",
            "value": 49
          }
        },
        "ef4153298be248a5a4df1417e9302003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b74256f4a0f4fb7ba0378a8b36ec40a",
            "placeholder": "​",
            "style": "IPY_MODEL_04d8429c49494ae980ac18bece059f7b",
            "value": " 49/49 [00:41&lt;00:00,  1.18it/s]"
          }
        },
        "c11e046dd3574ff2a9c28fab5c9ed9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7513387f3a194dee8c600fbd8a337007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8f3d9e6a6e41d58df389f738b6bd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e21dcb8b016e4c859e19c517bafa37ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b204dbded584004badcfbdb9b2b61fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b74256f4a0f4fb7ba0378a8b36ec40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d8429c49494ae980ac18bece059f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8031b6124360488f980ca83f72e19574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c66f6eaeae494a0893048fdb0c2a7ccc",
              "IPY_MODEL_733116468b3e4273918f15423f1f7699",
              "IPY_MODEL_800103b86e8c49e49687c5e72363c07d"
            ],
            "layout": "IPY_MODEL_84206f0dfc8a4434a68c90fd97ab8224"
          }
        },
        "c66f6eaeae494a0893048fdb0c2a7ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d3526b1f104e4cb9ff73995b3af91f",
            "placeholder": "​",
            "style": "IPY_MODEL_3c9be7d88fca48fab1fe4fb54d0cd705",
            "value": "Epoch 5 Training: 100%"
          }
        },
        "733116468b3e4273918f15423f1f7699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2544fbc492e748ddb1027c330a213026",
            "max": 879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3733973699c44f683327b1051bff9f3",
            "value": 879
          }
        },
        "800103b86e8c49e49687c5e72363c07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55890fe745248348f9aaee579043053",
            "placeholder": "​",
            "style": "IPY_MODEL_13b997c39a6047bd8f15e776856c0ead",
            "value": " 879/879 [15:30&lt;00:00,  1.05s/it, loss=0.0000, avg_loss=0.0001]"
          }
        },
        "84206f0dfc8a4434a68c90fd97ab8224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "72d3526b1f104e4cb9ff73995b3af91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9be7d88fca48fab1fe4fb54d0cd705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2544fbc492e748ddb1027c330a213026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3733973699c44f683327b1051bff9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d55890fe745248348f9aaee579043053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b997c39a6047bd8f15e776856c0ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e203d9c7c7fb4257970fa04e790798b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d3901cbc4d740a884d90d193390d671",
              "IPY_MODEL_5b76924bbce0443a8601fe4bf4781c5a",
              "IPY_MODEL_38f5390cb79949738c975bc25dc2582c"
            ],
            "layout": "IPY_MODEL_1fa3ead525b94bfb8a8d5dd0ec6f9184"
          }
        },
        "9d3901cbc4d740a884d90d193390d671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c1f543dc4d4a70ae719a50a759acb3",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3d967824444b14a5b872bdd36194e8",
            "value": "Epoch 5 Validation: 100%"
          }
        },
        "5b76924bbce0443a8601fe4bf4781c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ba5af529074ab38c5d3856004e5c96",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ad35d206490478b8b6df941612dde41",
            "value": 49
          }
        },
        "38f5390cb79949738c975bc25dc2582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a9e7c9dd9942a69ec3066ba2ed678a",
            "placeholder": "​",
            "style": "IPY_MODEL_c4681ca1d24d4d87966332aaae3d9f5b",
            "value": " 49/49 [00:40&lt;00:00,  1.23it/s]"
          }
        },
        "1fa3ead525b94bfb8a8d5dd0ec6f9184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "81c1f543dc4d4a70ae719a50a759acb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3d967824444b14a5b872bdd36194e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ba5af529074ab38c5d3856004e5c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad35d206490478b8b6df941612dde41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25a9e7c9dd9942a69ec3066ba2ed678a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4681ca1d24d4d87966332aaae3d9f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6943b74d04f54336aa2b0018a44ab373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8b7fbc516834c1ab48ea6534f2ac70f",
              "IPY_MODEL_678671d72f5a43dead17969a26bea8d9",
              "IPY_MODEL_06110da8335b4dce99dbb3966ed196f4"
            ],
            "layout": "IPY_MODEL_8a81969d02484baea87ead0697c86a5a"
          }
        },
        "a8b7fbc516834c1ab48ea6534f2ac70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0946e4bdbd624a95ae613c69aea2eadf",
            "placeholder": "​",
            "style": "IPY_MODEL_8a7ff4ec56c048489a708d71a1f93eaa",
            "value": "Calculating GFLOPs: 100%"
          }
        },
        "678671d72f5a43dead17969a26bea8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212667b3dc604579871fbfcaf5914672",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b72991a7a1374a3a85b2841e8b04da7b",
            "value": 5
          }
        },
        "06110da8335b4dce99dbb3966ed196f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3175da1bdc034d92af4df662c47cb7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_78668c2f94bc42a89db8c972251f7afa",
            "value": " 5/5 [00:06&lt;00:00,  1.32s/it]"
          }
        },
        "8a81969d02484baea87ead0697c86a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0946e4bdbd624a95ae613c69aea2eadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7ff4ec56c048489a708d71a1f93eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "212667b3dc604579871fbfcaf5914672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72991a7a1374a3a85b2841e8b04da7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3175da1bdc034d92af4df662c47cb7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78668c2f94bc42a89db8c972251f7afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2557bb8fe0e84c4dbf2c712c6b6040bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a18299ae505448d0836682b8123e0b22",
              "IPY_MODEL_abdb19b73db04908a13a095a5f30eda9",
              "IPY_MODEL_bb4e43d3629c490da429489a7b1faa28"
            ],
            "layout": "IPY_MODEL_bbf00858a6de44f7b2e545abfc6069da"
          }
        },
        "a18299ae505448d0836682b8123e0b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b585430f0734fad8ae992da0bc9a78a",
            "placeholder": "​",
            "style": "IPY_MODEL_ac39f380593d48529fdfdca91d43fd8e",
            "value": "Baseline Evaluation: 100%"
          }
        },
        "abdb19b73db04908a13a095a5f30eda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6068b3a91c4be899b320641a4a23cc",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c69347005964b619996e780a0a73a1b",
            "value": 200
          }
        },
        "bb4e43d3629c490da429489a7b1faa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca64d3272024cb3993cea1a17e00f1a",
            "placeholder": "​",
            "style": "IPY_MODEL_a46751f44cb84eeba1cc729cd9103edf",
            "value": " 200/200 [01:33&lt;00:00,  2.23it/s]"
          }
        },
        "bbf00858a6de44f7b2e545abfc6069da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b585430f0734fad8ae992da0bc9a78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac39f380593d48529fdfdca91d43fd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be6068b3a91c4be899b320641a4a23cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c69347005964b619996e780a0a73a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ca64d3272024cb3993cea1a17e00f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46751f44cb84eeba1cc729cd9103edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e5bea110c0f4d6582e3014f946b6699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d201b70c7bb94a4ebd54520bccaf54a5",
              "IPY_MODEL_97b23fa1fcbc43b48ca0b50d205585d7",
              "IPY_MODEL_70d1e6a3e21d4afda59880e201c25bde"
            ],
            "layout": "IPY_MODEL_60dd382a024e4250a71b49eeafc8f0b9"
          }
        },
        "d201b70c7bb94a4ebd54520bccaf54a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62062d5499ed426588a49bab40d1df1f",
            "placeholder": "​",
            "style": "IPY_MODEL_df5e2d9e2d434aaab680801c226b3767",
            "value": "Evaluating Ratio 0.10: 100%"
          }
        },
        "97b23fa1fcbc43b48ca0b50d205585d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f3f0cff6b64b83862117df16396fd3",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21c3867dc87d4749b9e25f88fadb2abb",
            "value": 200
          }
        },
        "70d1e6a3e21d4afda59880e201c25bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d14ae46bb0543fdb362391a0ca11993",
            "placeholder": "​",
            "style": "IPY_MODEL_963ebedd867a40688e9133f9d6d591e6",
            "value": " 200/200 [00:49&lt;00:00,  4.39it/s]"
          }
        },
        "60dd382a024e4250a71b49eeafc8f0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "62062d5499ed426588a49bab40d1df1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5e2d9e2d434aaab680801c226b3767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f3f0cff6b64b83862117df16396fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c3867dc87d4749b9e25f88fadb2abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d14ae46bb0543fdb362391a0ca11993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963ebedd867a40688e9133f9d6d591e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92079b134c9743d493d60b6d59fb4e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a5a47485e75497692f30c2739f9b87c",
              "IPY_MODEL_0a83af4b24514755aeb7e1895d3a3cf7",
              "IPY_MODEL_b6ebe99182be4bef853174d2fbb9cd68"
            ],
            "layout": "IPY_MODEL_1846da366c83402ebc8add4f3255abef"
          }
        },
        "4a5a47485e75497692f30c2739f9b87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0e2c4daee340958afe2b52bc78842b",
            "placeholder": "​",
            "style": "IPY_MODEL_99b1dd112b134077b79eea2060df11b0",
            "value": "Evaluating Ratio 0.20: 100%"
          }
        },
        "0a83af4b24514755aeb7e1895d3a3cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff6a6d5f37a4802ba399d063aeba119",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a9c92a3b5ec4cebb9cadaeabe10765e",
            "value": 200
          }
        },
        "b6ebe99182be4bef853174d2fbb9cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6be36618e2b47fa86984927bddb19f4",
            "placeholder": "​",
            "style": "IPY_MODEL_51863891d6c44ec1b4c18bd80a658d37",
            "value": " 200/200 [00:49&lt;00:00,  4.36it/s]"
          }
        },
        "1846da366c83402ebc8add4f3255abef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7c0e2c4daee340958afe2b52bc78842b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b1dd112b134077b79eea2060df11b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff6a6d5f37a4802ba399d063aeba119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9c92a3b5ec4cebb9cadaeabe10765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6be36618e2b47fa86984927bddb19f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51863891d6c44ec1b4c18bd80a658d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2af4969aacf4e9784780be683bfbda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebcf7b80d7e14b38b0ab0012c19a33a8",
              "IPY_MODEL_15ab12615f5745059f04a3b96117c243",
              "IPY_MODEL_eea43a0bf7dc4fbdb36bf50251e7244d"
            ],
            "layout": "IPY_MODEL_81c87310c53343819f36eb78778a6726"
          }
        },
        "ebcf7b80d7e14b38b0ab0012c19a33a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e586670cc5f44e186750cb4a9ed7d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_702c906920d3476ca618438f29d90e53",
            "value": "Evaluating Ratio 0.30: 100%"
          }
        },
        "15ab12615f5745059f04a3b96117c243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9fd54ac50234c7eb866617278c4c8fb",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_780017fc9f0d41fda9510ba974284b53",
            "value": 200
          }
        },
        "eea43a0bf7dc4fbdb36bf50251e7244d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da1170cee547492c99e0457c618cd5bc",
            "placeholder": "​",
            "style": "IPY_MODEL_086f79c663734690be8cc26816b9f1bc",
            "value": " 200/200 [00:49&lt;00:00,  4.30it/s]"
          }
        },
        "81c87310c53343819f36eb78778a6726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8e586670cc5f44e186750cb4a9ed7d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702c906920d3476ca618438f29d90e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9fd54ac50234c7eb866617278c4c8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780017fc9f0d41fda9510ba974284b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da1170cee547492c99e0457c618cd5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086f79c663734690be8cc26816b9f1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d073933744406a9e7c233f14b04d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_854d405794d74415aa63d73da47892fd",
              "IPY_MODEL_ce6d27d70b9741ef97e7348aba8b2083",
              "IPY_MODEL_5508933406b347209d16d300fd62ff8f"
            ],
            "layout": "IPY_MODEL_ab711ab9ecfc441e82fc9d030c73ca69"
          }
        },
        "854d405794d74415aa63d73da47892fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c41e6e234e4208bd55bcd4630317e9",
            "placeholder": "​",
            "style": "IPY_MODEL_1580650a26004d1eabad003dad473cf5",
            "value": "Evaluating Ratio 0.40: 100%"
          }
        },
        "ce6d27d70b9741ef97e7348aba8b2083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea525fe5dc54ddd852fe78d5bfbebe4",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8030bb2013054c299fc16ffacea0469b",
            "value": 200
          }
        },
        "5508933406b347209d16d300fd62ff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1efe367800524974ab8526a5fe7707e0",
            "placeholder": "​",
            "style": "IPY_MODEL_bb0321ca5c314cd5b6c13e37f204df52",
            "value": " 200/200 [00:48&lt;00:00,  3.98it/s]"
          }
        },
        "ab711ab9ecfc441e82fc9d030c73ca69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "98c41e6e234e4208bd55bcd4630317e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1580650a26004d1eabad003dad473cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bea525fe5dc54ddd852fe78d5bfbebe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8030bb2013054c299fc16ffacea0469b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1efe367800524974ab8526a5fe7707e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0321ca5c314cd5b6c13e37f204df52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3ac69eb828b42d6b92218fb245154ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c356779c2544c09b23cdbf4f1278fc6",
              "IPY_MODEL_29842bf2f05c4b7e9ef0f25c481d4b02",
              "IPY_MODEL_33dc254393d141658b900942164d8bef"
            ],
            "layout": "IPY_MODEL_3bbb308c2fbd43dbaee38a1ddead9851"
          }
        },
        "2c356779c2544c09b23cdbf4f1278fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26934d1cd3aa45959589cafa3f2c099f",
            "placeholder": "​",
            "style": "IPY_MODEL_dad3ef7115f8462ab2914172318d26be",
            "value": "Evaluating Ratio 0.50: 100%"
          }
        },
        "29842bf2f05c4b7e9ef0f25c481d4b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f86c3764e044598b2b1efa93d01f5e7",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48e670c1ae1843ae8d0bc7aad67b144d",
            "value": 200
          }
        },
        "33dc254393d141658b900942164d8bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_662afbfaf2a64fb982c0d19216c48370",
            "placeholder": "​",
            "style": "IPY_MODEL_05242b67b92645e6a424d1463bdff672",
            "value": " 200/200 [00:47&lt;00:00,  4.60it/s]"
          }
        },
        "3bbb308c2fbd43dbaee38a1ddead9851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "26934d1cd3aa45959589cafa3f2c099f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad3ef7115f8462ab2914172318d26be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f86c3764e044598b2b1efa93d01f5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e670c1ae1843ae8d0bc7aad67b144d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "662afbfaf2a64fb982c0d19216c48370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05242b67b92645e6a424d1463bdff672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 1: Setup Environment, Mount Drive, Define Paths\n",
        "# =============================================================================\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "import copy\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import traceback\n",
        "\n",
        "print(\"--- Environment Setup ---\")\n",
        "\n",
        "# Set CUDA Launch Blocking (Optional but Recommended for Debugging GPU errors)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "print(\"CUDA_LAUNCH_BLOCKING set to 1.\")\n",
        "\n",
        "# Check if in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Install necessary libraries\n",
        "print(\"Installing required libraries...\")\n",
        "# Using default Colab torch should be fine unless specific version needed\n",
        "# !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other libraries, including torch-pruning\n",
        "# Updated transformers version might be needed if internal structures change\n",
        "!pip install -q --upgrade transformers datasets accelerate evaluate timm Pillow safetensors pycocotools thop torch-pruning tqdm\n",
        "print(\"Libraries installation attempt finished.\")\n",
        "\n",
        "# Import key libraries (do this after install)\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import numpy as np\n",
        "    from transformers import (\n",
        "        AutoImageProcessor, AutoModelForObjectDetection, AutoConfig, Trainer, TrainingArguments\n",
        "    )\n",
        "    # Import MLP class was intended for head recreation fallback (Cell 2), but standard modules are used instead.\n",
        "    # from transformers.models.deformable_detr.modeling_deformable_detr import DeformableDetrMLP # <<< COMMENTED OUT\n",
        "    import torchvision\n",
        "    from tqdm.notebook import tqdm\n",
        "    from PIL import Image\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import torch_pruning as tp\n",
        "    from thop import profile\n",
        "    from pycocotools.coco import COCO\n",
        "    from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "    print(\"Core libraries imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"ERROR: Failed to import libraries: {e}\")\n",
        "    print(\"Please check the pip install logs above.\")\n",
        "    raise e\n",
        "\n",
        "# Mount Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive mounted.\")\n",
        "        except Exception as e_mount:\n",
        "            print(f\"Error mounting drive: {e_mount}\")\n",
        "            raise e_mount\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "    base_drive_path = \"/content/drive/MyDrive/\"\n",
        "else:\n",
        "    base_drive_path = \"./\" # Adjust if running locally\n",
        "\n",
        "# --- Configuration ---\n",
        "print(\"\\n--- Configuration ---\")\n",
        "# !!! Important: Adjust these paths to your actual Drive locations !!!\n",
        "model_dir = os.path.join(base_drive_path, \"deformable-detr-finetuned-kitti\") # DIR where fine-tuned model was saved\n",
        "dataset_base_dir = os.path.join(base_drive_path, \"kitti_subset\") # Base DIR for KITTI subset\n",
        "images_dir = os.path.join(dataset_base_dir, \"images\") # Specific image folder\n",
        "annotation_dir = os.path.join(dataset_base_dir, \"annotations\") # Specific annotation folder (for KITTI format)\n",
        "# --- CHANGE THIS LINE to point to your COCO format VALIDATION json ---\n",
        "# coco_annotation_file = os.path.join(dataset_base_dir, \"val_annotations.json\") # Old line\n",
        "coco_annotation_file = os.path.join(dataset_base_dir, \"annotations\", \"instances_val2017.json\") # <== CORRECTED PATH\n",
        "# --- END CHANGE ---\n",
        "output_dir = os.path.join(base_drive_path, \"kitti_torch_pruning_output_v1\") # Output directory for this run\n",
        "\n",
        "# Pruning & Fine-tuning Params\n",
        "GLOBAL_PRUNING_RATIO = 0.1 # Target sparsity for *each* prunable Conv2D layer's channels\n",
        "DO_FINE_TUNING = False\n",
        "FINE_TUNE_EPOCHS = 5\n",
        "FINE_TUNE_LR = 1e-5\n",
        "FINE_TUNE_BATCH_SIZE = 2 # Keep small for Colab memory\n",
        "TRAIN_VAL_SPLIT_RATIO = 0.9 # 90% for training, 10% for validation\n",
        "\n",
        "# Dataset Params (ensure these match your KITTI subset)\n",
        "NUM_KITTI_CLASSES = 3 # Car, Pedestrian, Cyclist\n",
        "NUM_OUTPUTS_REQUIRED = NUM_KITTI_CLASSES + 1 # Add 1 for the background/no-object class\n",
        "\n",
        "# --- End Configuration ---\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Model directory: {model_dir}\")\n",
        "print(f\"Dataset directory: {dataset_base_dir}\")\n",
        "print(f\"COCO Annotation file: {coco_annotation_file}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: CUDA not available, running on CPU. This will be very slow.\")\n",
        "\n",
        "# Helper Functions (if needed by multiple cells, define here)\n",
        "def get_module_by_name(model: nn.Module, name: str) -> nn.Module:\n",
        "    \"\"\"Gets a module from a model using its full name.\"\"\"\n",
        "    names = name.split('.')\n",
        "    obj = model\n",
        "    for n in names:\n",
        "        if hasattr(obj, n):\n",
        "            obj = getattr(obj, n)\n",
        "        else:\n",
        "            try: # Handle sequential indexing like layer1.0.conv1\n",
        "                idx = int(n)\n",
        "                obj = obj[idx]\n",
        "            except (ValueError, IndexError, TypeError):\n",
        "                raise AttributeError(f\"Module part '{n}' not found in name '{name}'. Parent type: {type(obj)}\")\n",
        "    return obj\n",
        "\n",
        "def set_module_by_name(model: nn.Module, name: str, new_module: nn.Module):\n",
        "    \"\"\"Sets a module in a model using its full name.\"\"\"\n",
        "    names = name.split('.')\n",
        "    parent_name = '.'.join(names[:-1])\n",
        "    leaf_name = names[-1]\n",
        "\n",
        "    try:\n",
        "        # Use get_submodule which is safer for nested modules\n",
        "        parent_module = model.get_submodule(parent_name) if parent_name else model\n",
        "    except AttributeError:\n",
        "         # Fallback for nested Sequentials/ModuleLists if get_submodule fails\n",
        "         parent_module = get_module_by_name(model, parent_name)\n",
        "\n",
        "    if hasattr(parent_module, leaf_name):\n",
        "        setattr(parent_module, leaf_name, new_module)\n",
        "    else:\n",
        "        try: # Handle replacing item in ModuleList/Sequential\n",
        "            idx = int(leaf_name)\n",
        "            parent_module[idx] = new_module\n",
        "        except (ValueError, IndexError, TypeError):\n",
        "            raise AttributeError(f\"Could not set attribute or index '{leaf_name}' in parent module '{parent_name}' of type {type(parent_module)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQYReSHwPfrQ",
        "outputId": "b0c0f48a-8860-43e8-f44c-2f18985a7128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Environment Setup ---\n",
            "CUDA_LAUNCH_BLOCKING set to 1.\n",
            "Installing required libraries...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLibraries installation attempt finished.\n",
            "Core libraries imported successfully.\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted.\n",
            "\n",
            "--- Configuration ---\n",
            "Model directory: /content/drive/MyDrive/deformable-detr-finetuned-kitti\n",
            "Dataset directory: /content/drive/MyDrive/kitti_subset\n",
            "COCO Annotation file: /content/drive/MyDrive/kitti_subset/annotations/instances_val2017.json\n",
            "Output directory: /content/drive/MyDrive/kitti_torch_pruning_output_v1\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91kECVA8XMqJ",
        "outputId": "d6867b6d-9618-47e8-fe0e-dc7a6c2dabbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Load Model, Resize Head, Replace BN (GPU Execution)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Loading Model, Resizing Head, Replacing BN ---\")\n",
        "\n",
        "# Ensure variables from Cell 1 are accessible\n",
        "assert 'model_dir' in locals(), \"Cell 1 must be run first to define paths.\"\n",
        "assert 'device' in locals(), \"Cell 1 must be run first to define device.\"\n",
        "assert 'NUM_OUTPUTS_REQUIRED' in locals(), \"Cell 1 must define NUM_OUTPUTS_REQUIRED.\"\n",
        "assert str(device) == 'cuda', \"This cell expects CUDA device for final model placement.\"\n",
        "\n",
        "model = None\n",
        "image_processor = None\n",
        "config = None\n",
        "hidden_dim = 256\n",
        "decoder_layers = 6\n",
        "num_queries = 300\n",
        "original_params = -1 # Will be calculated at the end\n",
        "\n",
        "try:\n",
        "    # Load processor\n",
        "    image_processor = AutoImageProcessor.from_pretrained(model_dir)\n",
        "    print(f\"Image processor loaded from {model_dir}\")\n",
        "\n",
        "    # Load config\n",
        "    try:\n",
        "        config = AutoConfig.from_pretrained(model_dir)\n",
        "        num_queries = getattr(config, 'num_queries', 300)\n",
        "        hidden_dim = getattr(config, 'd_model', 256)\n",
        "        decoder_layers = getattr(config, 'decoder_layers', 6)\n",
        "        print(f\"Loaded config: num_queries={num_queries}, hidden_dim={hidden_dim}, decoder_layers={decoder_layers}\")\n",
        "        id2label = {i: f\"LABEL_{i}\" for i in range(NUM_OUTPUTS_REQUIRED)}\n",
        "        label2id = {v: k for k, v in id2label.items()}\n",
        "        config.id2label = id2label; config.label2id = label2id; config.num_labels = NUM_OUTPUTS_REQUIRED\n",
        "        print(f\"Updated config for {NUM_OUTPUTS_REQUIRED} outputs (incl. background).\")\n",
        "    except Exception as e_conf:\n",
        "        print(f\"WARNING: Could not load/parse config: {e_conf}. Using defaults.\")\n",
        "        id2label = {i: f\"LABEL_{i}\" for i in range(NUM_OUTPUTS_REQUIRED)}\n",
        "        label2id = {v: k for k, v in id2label.items()}\n",
        "        config = AutoConfig.from_pretrained(\"SenseTime/deformable-detr\", num_labels=NUM_OUTPUTS_REQUIRED, id2label=id2label, label2id=label2id)\n",
        "        num_queries = getattr(config, 'num_queries', num_queries); hidden_dim = getattr(config, 'd_model', hidden_dim); decoder_layers = getattr(config, 'decoder_layers', decoder_layers)\n",
        "        print(f\"Using potentially default config values: num_queries={num_queries}, hidden_dim={hidden_dim}, decoder_layers={decoder_layers}\")\n",
        "\n",
        "    # Load model structure (on CPU initially)\n",
        "    print(\"Loading model structure (ignore mismatched sizes)...\")\n",
        "    model = AutoModelForObjectDetection.from_pretrained(\n",
        "        model_dir,\n",
        "        config=config,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    print(\"Model structure loaded (on CPU initially).\")\n",
        "\n",
        "    # --- Resize Head AFTER Loading (on CPU) ---\n",
        "    print(\"Checking and potentially resizing model heads (on CPU)...\")\n",
        "    try:\n",
        "        current_cls_outputs = -1; final_class_layer = None\n",
        "        if hasattr(model, 'class_embed') and isinstance(model.class_embed, nn.ModuleList) and len(model.class_embed) > 0:\n",
        "             last_mod_in_list = model.class_embed[-1]\n",
        "             if isinstance(last_mod_in_list, nn.Linear): final_class_layer = last_mod_in_list\n",
        "             elif hasattr(last_mod_in_list, 'layers') and isinstance(last_mod_in_list.layers, nn.Sequential):\n",
        "                 if len(last_mod_in_list.layers) > 0 and isinstance(last_mod_in_list.layers[-1], nn.Linear): final_class_layer = last_mod_in_list.layers[-1]\n",
        "        elif hasattr(model, 'class_embed') and isinstance(model.class_embed, nn.Sequential): # ... (other checks) ...\n",
        "            if len(model.class_embed) > 0 and isinstance(model.class_embed[-1], nn.Linear): final_class_layer = model.class_embed[-1]\n",
        "        elif hasattr(model, 'class_embed') and isinstance(model.class_embed, nn.Linear): final_class_layer = model.class_embed\n",
        "\n",
        "        if isinstance(final_class_layer, nn.Linear): current_cls_outputs = final_class_layer.out_features; print(f\"  Detected {current_cls_outputs} outputs in loaded classification head.\")\n",
        "        else: print(f\"  Could not reliably detect output features of class_embed (Type: {type(model.class_embed)}). Assuming resize needed.\"); current_cls_outputs = -1\n",
        "\n",
        "        if current_cls_outputs != NUM_OUTPUTS_REQUIRED:\n",
        "            print(f\"  Head mismatch/uncertainty: Recreating heads for {decoder_layers} layers with {NUM_OUTPUTS_REQUIRED} outputs (CPU).\")\n",
        "            if hasattr(config, 'decoder_layers'): # ... (Recreate heads based on config) ...\n",
        "                model.class_embed = nn.ModuleList([nn.Linear(hidden_dim, NUM_OUTPUTS_REQUIRED) for _ in range(config.decoder_layers)])\n",
        "                bbox_head_mlp = lambda: nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 4))\n",
        "                model.bbox_embed = nn.ModuleList([bbox_head_mlp() for _ in range(config.decoder_layers)])\n",
        "            else: # ... (Fallback) ...\n",
        "                 model.class_embed = nn.Linear(hidden_dim, NUM_OUTPUTS_REQUIRED); model.bbox_embed = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 4))\n",
        "            # ... (Query embedding check/resize) ...\n",
        "            if hasattr(model, 'query_position_embeddings') and isinstance(model.query_position_embeddings, nn.Embedding):\n",
        "                 if model.query_position_embeddings.num_embeddings != num_queries: print(f\"  Resizing query embeds.\"); model.query_position_embeddings = nn.Embedding(num_queries, hidden_dim)\n",
        "                 else: print(\"  Query embeds size OK.\")\n",
        "            else: print(\"  Creating query embeds.\"); model.query_position_embeddings = nn.Embedding(num_queries, hidden_dim)\n",
        "            print(\"  Heads recreated/resized on CPU.\")\n",
        "        else: print(\"  Loaded model heads appear to have the correct number of outputs.\")\n",
        "    except Exception as e_head: print(f\"  Error during head check/resize: {e_head}\"); traceback.print_exc(); raise RuntimeError(\"Failed head check/resize.\") from e_head\n",
        "\n",
        "    # --- Replace FrozenBatchNorm2d (on CPU) ---\n",
        "    print(\"\\nReplacing FrozenBatchNorm2d layers (on CPU)...\")\n",
        "    FROZEN_BN_TYPE = None\n",
        "    try: # Find the FrozenBN class\n",
        "        from transformers.models.deformable_detr.modeling_deformable_detr import DeformableDetrFrozenBatchNorm2d\n",
        "        FROZEN_BN_TYPE = DeformableDetrFrozenBatchNorm2d\n",
        "        print(\"  Found DeformableDetrFrozenBatchNorm2d class.\")\n",
        "    except ImportError: print(\"  DeformableDetrFrozenBatchNorm2d not found.\") # Add fallback if needed\n",
        "\n",
        "    if FROZEN_BN_TYPE:\n",
        "        replacement_count = 0; error_count = 0\n",
        "        module_list = list(model.named_modules())\n",
        "        print(f\"  Iterating through {len(module_list)} modules...\")\n",
        "        from tqdm import tqdm as regular_tqdm # Use standard tqdm\n",
        "        for name, module in regular_tqdm(module_list, desc=\"Replacing FrozenBN (CPU)\", leave=False):\n",
        "            if isinstance(module, FROZEN_BN_TYPE):\n",
        "                try: # Replace with standard BN\n",
        "                    if hasattr(module, 'weight') and module.weight is not None: num_features = module.weight.shape[0]\n",
        "                    else: print(f\"    WARNING: Skipping {name} - no weight attr.\"); error_count += 1; continue\n",
        "                    # --- Use eps=1e-5 fix ---\n",
        "                    new_bn = nn.BatchNorm2d(num_features, eps=1e-5, affine=True, track_running_stats=True)\n",
        "                    # --- Copy parameters ---\n",
        "                    if hasattr(module, 'weight') and module.weight is not None and hasattr(new_bn,'weight') and new_bn.weight.shape == module.weight.shape: new_bn.weight.data.copy_(module.weight.data)\n",
        "                    if hasattr(module, 'bias') and module.bias is not None and hasattr(new_bn,'bias') and new_bn.bias.shape == module.bias.shape: new_bn.bias.data.copy_(module.bias.data)\n",
        "                    if hasattr(module, 'running_mean') and module.running_mean is not None and hasattr(new_bn,'running_mean') and new_bn.running_mean.shape == module.running_mean.shape: new_bn.running_mean.data.copy_(module.running_mean.data)\n",
        "                    if hasattr(module, 'running_var') and module.running_var is not None and hasattr(new_bn,'running_var') and new_bn.running_var.shape == module.running_var.shape: new_bn.running_var.data.copy_(module.running_var.data)\n",
        "                    if hasattr(module, 'num_batches_tracked') and module.num_batches_tracked is not None and hasattr(new_bn, 'num_batches_tracked'): new_bn.num_batches_tracked.data.copy_(module.num_batches_tracked.data)\n",
        "                    set_module_by_name(model, name, new_bn)\n",
        "                    replacement_count += 1\n",
        "                except Exception as e_replace: print(f\"    ERROR replacing {name}: {e_replace}\"); traceback.print_exc(); error_count += 1\n",
        "        print(f\"  Finished FrozenBN Replacement. Replaced: {replacement_count}, Errors: {error_count}\")\n",
        "        if error_count > 0: raise RuntimeError(\"Errors occurred during BatchNorm replacement.\")\n",
        "    else: print(\"  No FrozenBatchNorm class identified for replacement.\")\n",
        "\n",
        "    # --- Move final model (with std BN) to target device (GPU) ---\n",
        "    print(f\"\\nMoving final prepared model to: {device}\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model is ready on device.\")\n",
        "\n",
        "    # --- Calculate original params *after* prep and move to GPU ---\n",
        "    original_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Model parameters after prep (trainable): {original_params:,}\")\n",
        "    # Make variable available globally for Cell 4\n",
        "    # (Alternatively, Cell 4 could access model.parameters() directly)\n",
        "    globals()['original_params'] = original_params\n",
        "\n",
        "except Exception as e_load_prep:\n",
        "    print(f\"ERROR during model loading/preparation: {e_load_prep}\")\n",
        "    traceback.print_exc(); model = None; raise e_load_prep\n",
        "\n",
        "# Clean up memory\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUOnS_UzP1v9",
        "outputId": "dc919588-73d8-4679-f991-cd7a5e87af29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading Model, Resizing Head, Replacing BN ---\n",
            "Image processor loaded from /content/drive/MyDrive/deformable-detr-finetuned-kitti\n",
            "Loaded config: num_queries=300, hidden_dim=256, decoder_layers=6\n",
            "Updated config for 4 outputs (incl. background).\n",
            "Loading model structure (ignore mismatched sizes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "Some weights of DeformableDetrForObjectDetection were not initialized from the model checkpoint at /content/drive/MyDrive/deformable-detr-finetuned-kitti and are newly initialized because the shapes did not match:\n",
            "- class_embed.0.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
            "- class_embed.0.weight: found shape torch.Size([3, 256]) in the checkpoint and torch.Size([4, 256]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure loaded (on CPU initially).\n",
            "Checking and potentially resizing model heads (on CPU)...\n",
            "  Detected 4 outputs in loaded classification head.\n",
            "  Loaded model heads appear to have the correct number of outputs.\n",
            "\n",
            "Replacing FrozenBatchNorm2d layers (on CPU)...\n",
            "  Found DeformableDetrFrozenBatchNorm2d class.\n",
            "  Iterating through 425 modules...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Finished FrozenBN Replacement. Replaced: 53, Errors: 0\n",
            "\n",
            "Moving final prepared model to: cuda\n",
            "Model is ready on device.\n",
            "Model parameters after prep (trainable): 39,878,026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 3: Calculate Original Metrics (GPU Execution)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Calculating Original Model Metrics ---\\n\")\n",
        "\n",
        "# Ensure model and param count from Cell 2 are available\n",
        "assert 'model' in locals() and model is not None, \"Cell 2 must be run first.\"\n",
        "assert 'original_params' in locals() and original_params > 0, \"Cell 2 must set original_params > 0.\"\n",
        "assert str(next(model.parameters()).device) == 'cuda:0', \"Model expected on CUDA device.\" # Check device\n",
        "\n",
        "original_gflops = 0.0\n",
        "dummy_input = None\n",
        "\n",
        "if model is not None:\n",
        "    print(f\"Using Original Trainable Parameters (Post-BN Replace): {original_params:,}\")\n",
        "\n",
        "    # Calculate GFLOPs using thop\n",
        "    bs = 1\n",
        "    try:\n",
        "         # Determine input size\n",
        "         img_h, img_w = 800, 1333\n",
        "         if hasattr(image_processor, 'size') and isinstance(image_processor.size, dict):\n",
        "            # ... (Robust size calculation logic) ...\n",
        "            size_dict = image_processor.size\n",
        "            if 'shortest_edge' in size_dict:\n",
        "                shortest = size_dict['shortest_edge']; max_size = getattr(image_processor, 'max_size', 1333); aspect_ratio = 1333 / 800\n",
        "                if shortest == 800 and max_size == 1333: img_h, img_w = 800, 1333\n",
        "                else: img_h = shortest; img_w = int(shortest * aspect_ratio);\n",
        "                if img_w > max_size: img_w = max_size; img_h = int(max_size / aspect_ratio)\n",
        "            elif 'height' in size_dict and 'width' in size_dict: img_h = size_dict['height']; img_w = size_dict['width']\n",
        "            img_h = max(img_h, 32); img_w = max(img_w, 32)\n",
        "         print(f\"Using dummy input size H={img_h}, W={img_w}\")\n",
        "\n",
        "         # --- Create dummy input on GPU ---\n",
        "         dummy_input = torch.randn(bs, 3, img_h, img_w, device=device)\n",
        "         print(f\"Using dummy input shape for GFLOPs: {dummy_input.shape} on {device}\")\n",
        "\n",
        "         # Profile on GPU\n",
        "         print(f\"Calculating GFLOPs on {device} (thop)...\")\n",
        "         try:\n",
        "              # Ensure model is on GPU (should be already)\n",
        "              model.to(device)\n",
        "              flops, params_thop = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "              original_gflops = flops / 1e9\n",
        "              print(f\"GFLOPs calculated on {device}: {original_gflops:.2f} GFLOPs\")\n",
        "         except Exception as e_prof_gpu:\n",
        "              print(f\"  Thop profile on GPU failed ({e_prof_gpu}), trying on CPU...\")\n",
        "              # --- Fallback to CPU profiling ---\n",
        "              try:\n",
        "                   model_cpu_copy = copy.deepcopy(model).cpu()\n",
        "                   dummy_input_cpu = dummy_input.cpu()\n",
        "                   flops, _ = profile(model_cpu_copy, inputs=(dummy_input_cpu,), verbose=False)\n",
        "                   original_gflops = flops / 1e9\n",
        "                   print(f\"GFLOPs calculated on CPU: {original_gflops:.2f} GFLOPs\")\n",
        "                   del model_cpu_copy, dummy_input_cpu; gc.collect()\n",
        "              except Exception as e_prof_cpu:\n",
        "                   print(f\"  Thop profile on CPU also failed: {e_prof_cpu}\")\n",
        "                   original_gflops = -1.0 # Indicate failure\n",
        "               # --- End Fallback ---\n",
        "\n",
        "    except Exception as e_metrics:\n",
        "        print(f\"Error during original metrics calculation: {e_metrics}\")\n",
        "        traceback.print_exc(); original_gflops = -1.0\n",
        "else:\n",
        "    print(\"Model not loaded, cannot calculate original metrics.\")\n",
        "    original_gflops = -1.0\n",
        "\n",
        "# Store dummy_input globally if needed by Cell 4, otherwise delete\n",
        "# del dummy_input # Keep dummy_input for Cell 4\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXt6ldI9P4EK",
        "outputId": "abe826aa-858e-4daf-e61b-0781d5374ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Original Model Metrics ---\n",
            "\n",
            "Using Original Trainable Parameters (Post-BN Replace): 39,878,026\n",
            "Using dummy input size H=800, W=1333\n",
            "Using dummy input shape for GFLOPs: torch.Size([1, 3, 800, 1333]) on cuda\n",
            "Calculating GFLOPs on cuda (thop)...\n",
            "GFLOPs calculated on cuda: 204.87 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Pruning with torch-pruning (GPU Execution)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Pruning Model with torch-pruning (GPU Execution) ---\\n\")\n",
        "\n",
        "model_pruned = None # Initialize\n",
        "original_params = -1 # Initialize, will be calculated below\n",
        "\n",
        "# --- Prerequisite Checks ---\n",
        "if 'model' not in locals() or model is None:\n",
        "    print(\"Original model ('model') not available. Skipping pruning.\")\n",
        "elif not torch.cuda.is_available():\n",
        "     # This shouldn't happen now, but good practice to keep check\n",
        "    print(\"CUDA not available. Skipping GPU pruning.\")\n",
        "else:\n",
        "    try:\n",
        "        # --- Calculate original params directly from model object ---\n",
        "        print(\"Calculating original params from model object...\")\n",
        "        assert 'model' in locals() and model is not None, \"Model not loaded from Cell 2\"\n",
        "        # Ensure model is on the correct device before counting\n",
        "        device = next(model.parameters()).device\n",
        "        print(f\"  Model is on device: {device}\")\n",
        "        original_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        assert original_params > 0, \"Could not calculate positive original_params from model\"\n",
        "        print(f\"Using original trainable params (Post-BN Replace): {original_params:,}\")\n",
        "        # --- End Param Calculation ---\n",
        "\n",
        "        # 1. Create a deep copy directly on GPU\n",
        "        print(f\"\\nCreating deepcopy on device ({device})...\")\n",
        "        # Ensure original model is on the correct device (redundant check, but safe)\n",
        "        model.to(device)\n",
        "        model_pruned = copy.deepcopy(model)\n",
        "        model_pruned.eval()\n",
        "        print(\"Deepcopy created on target device.\")\n",
        "\n",
        "        # --- BN Replacement is done in Cell 2 now ---\n",
        "        print(\"\\nSkipping BN Replacement (should be done in Cell 2).\")\n",
        "\n",
        "        # --- Model Structure Debugging (Optional but can keep) ---\n",
        "        print(\"\\n--- Debugging Model Structure ---\")\n",
        "        print(f\"Model pruned is on device: {next(model_pruned.parameters()).device}\")\n",
        "        print(\"Top-level modules in model_pruned:\")\n",
        "        for name, module in model_pruned.named_children(): print(f\"  - {name} ({type(module).__name__})\")\n",
        "        if hasattr(model_pruned, 'model'):\n",
        "             nested_model_debug = model_pruned.model # Define for clarity\n",
        "             print(\"\\nModules in model_pruned.model (nested):\")\n",
        "             for name, module in nested_model_debug.named_children(): print(f\"  - model.{name} ({type(module).__name__})\")\n",
        "             if hasattr(nested_model_debug, 'backbone'):\n",
        "                  print(\"\\nModules in model_pruned.model.backbone:\")\n",
        "                  for name, module in nested_model_debug.backbone.named_children(): print(f\"  - model.backbone.{name} ({type(module).__name__})\")\n",
        "\n",
        "        # ... Add more detailed backbone checks if needed ...\n",
        "        print(\"--- End Debugging ---\")\n",
        "\n",
        "        # 2. Define Dummy Input on GPU\n",
        "        # Reuse from Cell 3 if possible, otherwise recreate\n",
        "        if 'dummy_input' not in locals() or dummy_input is None:\n",
        "             print(\"\\nDummy input not found, recreating on GPU...\")\n",
        "             bs = 1; img_h, img_w = 800, 1333\n",
        "             try: # Simplified size logic\n",
        "                 if hasattr(image_processor, 'size') and isinstance(image_processor.size, dict):\n",
        "                    size_dict = image_processor.size\n",
        "                    if 'shortest_edge' in size_dict: shortest = size_dict['shortest_edge']; max_size = getattr(image_processor, 'max_size', 1333); img_h = shortest; img_w = int(shortest * (1333/800)); img_w = min(img_w, max_size)\n",
        "                    elif 'height' in size_dict and 'width' in size_dict: img_h = size_dict['height']; img_w = size_dict['width']\n",
        "                 img_h = max(img_h, 32); img_w = max(img_w, 32)\n",
        "                 print(f\"Determined dummy input size: H={img_h}, W={img_w}\")\n",
        "             except Exception as e_size: print(f\"Warning: Size error: {e_size}. Using default.\"); img_h, img_w = 800, 1333\n",
        "             dummy_input = torch.randn(bs, 3, img_h, img_w, device=device) # Create on GPU device\n",
        "             print(f\"Recreated GPU dummy input: {dummy_input.shape} on {dummy_input.device}\")\n",
        "        elif dummy_input.device != device:\n",
        "             print(f\"\\nMoving existing dummy input to {device}\"); dummy_input = dummy_input.to(device)\n",
        "        else:\n",
        "             print(f\"\\nUsing existing dummy input: {dummy_input.shape} on {dummy_input.device}\")\n",
        "\n",
        "\n",
        "        # 3. Define Ignored Layers (Using Corrected Nested Access)\n",
        "        ignored_layers_modules = []\n",
        "        print(\"\\nIdentifying layers to ignore...\")\n",
        "        if not hasattr(model_pruned, 'model') or not isinstance(model_pruned.model, nn.Module):\n",
        "             raise AttributeError(\"Nested 'model' module not found in model_pruned\")\n",
        "        else:\n",
        "             nested_model = model_pruned.model # Use the nested model for backbone checks\n",
        "             print(f\"  Accessing nested model of type: {type(nested_model).__name__}\")\n",
        "             def add_module_and_submodules(module_instance, name_prefix=\"\"):\n",
        "                  if module_instance is None or not isinstance(module_instance, nn.Module): return\n",
        "                  if module_instance not in ignored_layers_modules: ignored_layers_modules.append(module_instance)\n",
        "                  for submodule in module_instance.modules():\n",
        "                      if submodule not in ignored_layers_modules and submodule is not module_instance: ignored_layers_modules.append(submodule)\n",
        "\n",
        "             # A. Ignore backbone's initial conv and bn\n",
        "             if hasattr(nested_model, 'backbone') and hasattr(nested_model.backbone, 'conv_encoder') and hasattr(nested_model.backbone.conv_encoder, 'model'):\n",
        "                 timm_model = nested_model.backbone.conv_encoder.model; print(\"  Checking backbone conv1/bn1...\")\n",
        "                 if hasattr(timm_model, 'conv1') and isinstance(timm_model.conv1, nn.Conv2d): ignored_layers_modules.append(timm_model.conv1); print(f\"    Added model.backbone.conv1\")\n",
        "                 # Use standard BN type here as it should have been replaced in Cell 2\n",
        "                 if hasattr(timm_model, 'bn1') and isinstance(timm_model.bn1, (nn.BatchNorm2d, nn.SyncBatchNorm)): ignored_layers_modules.append(timm_model.bn1); print(f\"    Added model.backbone.bn1\")\n",
        "\n",
        "                 # B. Ignore backbone's downsample layers\n",
        "                 print(\"  Checking backbone downsample blocks...\")\n",
        "                 for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                      if hasattr(timm_model, layer_name):\n",
        "                          res_layer = getattr(timm_model, layer_name)\n",
        "                          if hasattr(res_layer, '__iter__'):\n",
        "                              for block_idx, block in enumerate(res_layer):\n",
        "                                   if hasattr(block, 'downsample') and block.downsample is not None: print(f\"    Adding downsample block: model.backbone.{layer_name}.{block_idx}.downsample\"); add_module_and_submodules(block.downsample, f\"ds_{layer_name}_{block_idx}\")\n",
        "\n",
        "             # C. Ignore heads (parallel to nested_model)\n",
        "             print(\"  Checking heads, level_embed, input_proj...\")\n",
        "             if hasattr(model_pruned, 'class_embed'): print(\"    Adding class_embed and submodules\"); add_module_and_submodules(model_pruned.class_embed, \"class_embed\")\n",
        "             if hasattr(model_pruned, 'bbox_embed'): print(\"    Adding bbox_embed and submodules\"); add_module_and_submodules(model_pruned.bbox_embed, \"bbox_embed\")\n",
        "\n",
        "             # D. Ignore level_embed (inside nested_model)\n",
        "             if hasattr(nested_model, 'level_embed') and isinstance(nested_model.level_embed, nn.Embedding): ignored_layers_modules.append(nested_model.level_embed); print(\"    Added model.level_embed\")\n",
        "\n",
        "             # E. Ignore input projection (inside nested_model)\n",
        "             if hasattr(nested_model, 'input_proj'): print(\"    Adding model.input_proj and submodules\"); add_module_and_submodules(nested_model.input_proj, \"input_proj\")\n",
        "\n",
        "             # F. No need to check for FrozenBN here\n",
        "             print(\"  Skipping check for FrozenBN (should be replaced in Cell 2).\")\n",
        "\n",
        "        ignored_layers = list(set(m for m in ignored_layers_modules if isinstance(m, nn.Module) and m is not model_pruned and (not 'nested_model' in locals() or m is not nested_model)))\n",
        "        print(f\"\\nIdentified {len(ignored_layers)} unique nn.Module instances to ignore.\")\n",
        "        print(\"--- Ignored Modules ---\")\n",
        "        from collections import Counter\n",
        "        type_counts = Counter(type(m).__name__ for m in ignored_layers)\n",
        "        print(f\"Ignored layer type counts: {type_counts}\")\n",
        "        print(\"-----------------------\")\n",
        "\n",
        "\n",
        "        # 4. Define Importance and Pruner (on GPU)\n",
        "        print(f\"\\nSetting up Pruner on GPU with layer channel sparsity target: {GLOBAL_PRUNING_RATIO}\")\n",
        "        importance = tp.importance.MagnitudeImportance(p=1)\n",
        "\n",
        "        pruner = tp.pruner.MagnitudePruner(\n",
        "            model_pruned,               # On GPU, has standard BN\n",
        "            example_inputs=dummy_input, # On GPU\n",
        "            importance=importance,\n",
        "            pruning_ratio=GLOBAL_PRUNING_RATIO, # Use ratio from Cell 1\n",
        "            ignored_layers=ignored_layers,\n",
        "            root_module_types=[nn.Conv2d],\n",
        "            round_to=8,\n",
        "        )\n",
        "\n",
        "        # 5. Apply Pruning (on GPU)\n",
        "        print(\"Applying pruner.step() on GPU...\")\n",
        "        pruner.step() # Execute on GPU\n",
        "        print(\"torch-pruning step finished on GPU.\")\n",
        "        model_pruned.eval()\n",
        "\n",
        "        print(f\"Pruned model ready on {next(model_pruned.parameters()).device}.\")\n",
        "\n",
        "    except Exception as e_prune:\n",
        "        print(f\"ERROR during torch-pruning: {e_prune}\")\n",
        "        traceback.print_exc()\n",
        "        model_pruned = None\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g947Fj0P6Gc",
        "outputId": "54d87b78-bd40-4f94-e969-d1ab0be32d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Pruning Model with torch-pruning (GPU Execution) ---\n",
            "\n",
            "Calculating original params from model object...\n",
            "  Model is on device: cuda:0\n",
            "Using original trainable params (Post-BN Replace): 39,878,026\n",
            "\n",
            "Creating deepcopy on device (cuda:0)...\n",
            "Deepcopy created on target device.\n",
            "\n",
            "Skipping BN Replacement (should be done in Cell 2).\n",
            "\n",
            "--- Debugging Model Structure ---\n",
            "Model pruned is on device: cuda:0\n",
            "Top-level modules in model_pruned:\n",
            "  - model (DeformableDetrModel)\n",
            "  - class_embed (ModuleList)\n",
            "  - bbox_embed (ModuleList)\n",
            "\n",
            "Modules in model_pruned.model (nested):\n",
            "  - model.backbone (DeformableDetrConvModel)\n",
            "  - model.input_proj (ModuleList)\n",
            "  - model.query_position_embeddings (Embedding)\n",
            "  - model.encoder (DeformableDetrEncoder)\n",
            "  - model.decoder (DeformableDetrDecoder)\n",
            "  - model.reference_points (Linear)\n",
            "\n",
            "Modules in model_pruned.model.backbone:\n",
            "  - model.backbone.conv_encoder (DeformableDetrConvEncoder)\n",
            "  - model.backbone.position_embedding (DeformableDetrSinePositionEmbedding)\n",
            "--- End Debugging ---\n",
            "\n",
            "Using existing dummy input: torch.Size([1, 3, 800, 1333]) on cuda:0\n",
            "\n",
            "Identifying layers to ignore...\n",
            "  Accessing nested model of type: DeformableDetrModel\n",
            "  Checking backbone conv1/bn1...\n",
            "    Added model.backbone.conv1\n",
            "    Added model.backbone.bn1\n",
            "  Checking backbone downsample blocks...\n",
            "    Adding downsample block: model.backbone.layer1.0.downsample\n",
            "    Adding downsample block: model.backbone.layer2.0.downsample\n",
            "    Adding downsample block: model.backbone.layer3.0.downsample\n",
            "    Adding downsample block: model.backbone.layer4.0.downsample\n",
            "  Checking heads, level_embed, input_proj...\n",
            "    Adding class_embed and submodules\n",
            "    Adding bbox_embed and submodules\n",
            "    Adding model.input_proj and submodules\n",
            "  Skipping check for FrozenBN (should be replaced in Cell 2).\n",
            "\n",
            "Identified 35 unique nn.Module instances to ignore.\n",
            "--- Ignored Modules ---\n",
            "Ignored layer type counts: Counter({'Conv2d': 9, 'Sequential': 8, 'BatchNorm2d': 5, 'Linear': 4, 'ModuleList': 4, 'GroupNorm': 4, 'DeformableDetrMLPPredictionHead': 1})\n",
            "-----------------------\n",
            "\n",
            "Setting up Pruner on GPU with layer channel sparsity target: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_pruning/dependency.py:699: UserWarning: Unwrapped parameters detected: ['model.level_embed'].\n",
            " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
            "  warnings.warn(warning_str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying pruner.step() on GPU...\n",
            "torch-pruning step finished on GPU.\n",
            "Pruned model ready on cuda:0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Calculate Pruned Model Metrics\n",
        "# =============================================================================\n",
        "print(\"\\n--- Calculating Pruned Model Metrics ---\")\n",
        "\n",
        "pruned_params = -1 # Initialize\n",
        "pruned_gflops = -1.0 # Initialize\n",
        "\n",
        "if 'model_pruned' in locals() and model_pruned is not None:\n",
        "    try:\n",
        "        # Ensure model is on the correct device for calculations\n",
        "        model_pruned.to(device)\n",
        "        model_pruned.eval()\n",
        "\n",
        "        pruned_params = sum(p.numel() for p in model_pruned.parameters() if p.requires_grad)\n",
        "        print(f\"Pruned Trainable Parameters: {pruned_params:,}\")\n",
        "        if 'original_params' in locals() and original_params > 0:\n",
        "            reduction = (original_params - pruned_params) / original_params * 100\n",
        "            print(f\"Parameter Reduction: {reduction:.2f}%\")\n",
        "        else:\n",
        "            print(\"Cannot calculate reduction (original_params unavailable).\")\n",
        "\n",
        "        # Calculate GFLOPs using thop\n",
        "        if 'dummy_input' not in locals() or dummy_input is None:\n",
        "             print(\"Dummy input not found from Cell 3, recreating...\")\n",
        "             bs = 1; height, width = 800, 1333\n",
        "             dummy_input = torch.randn(bs, 3, height, width, device=device)\n",
        "             print(f\"Recreated dummy input shape: {dummy_input.shape}\")\n",
        "        elif dummy_input.device != device: # Ensure dummy input is on the correct device\n",
        "             dummy_input = dummy_input.to(device)\n",
        "\n",
        "        print(\"Calculating pruned GFLOPs...\")\n",
        "        try:\n",
        "            flops, params_thop = profile(model_pruned, inputs=(dummy_input,), verbose=False)\n",
        "            pruned_gflops = flops / 1e9\n",
        "            print(f\"Pruned GFLOPs calculated on {device}: {pruned_gflops:.2f} GFLOPs\")\n",
        "        except Exception as e_prof_gpu:\n",
        "            print(f\"  Thop profile on GPU failed ({e_prof_gpu}), trying on CPU...\")\n",
        "            try:\n",
        "                model_pruned_cpu = copy.deepcopy(model_pruned).cpu()\n",
        "                dummy_input_cpu = dummy_input.cpu()\n",
        "                flops, _ = profile(model_pruned_cpu, inputs=(dummy_input_cpu,), verbose=False)\n",
        "                pruned_gflops = flops / 1e9\n",
        "                print(f\"Pruned GFLOPs calculated on CPU: {pruned_gflops:.2f} GFLOPs\")\n",
        "                del model_pruned_cpu, dummy_input_cpu\n",
        "                gc.collect()\n",
        "            except Exception as e_prof_cpu:\n",
        "                print(f\"  Thop profile on CPU also failed: {e_prof_cpu}\")\n",
        "                pruned_gflops = -1.0\n",
        "\n",
        "        if 'original_gflops' in locals() and original_gflops > 0 and pruned_gflops >= 0:\n",
        "             gflops_reduction = (original_gflops - pruned_gflops) / original_gflops * 100\n",
        "             print(f\"GFLOPs Reduction: {gflops_reduction:.2f}%\")\n",
        "        elif 'original_gflops' in locals() and original_gflops <= 0:\n",
        "             print(\"Cannot calculate GFLOPs reduction (original_gflops unavailable).\")\n",
        "\n",
        "    except Exception as e_metrics:\n",
        "        print(f\"Error calculating pruned metrics: {e_metrics}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"Pruned model not available, cannot calculate metrics.\")"
      ],
      "metadata": {
        "id": "WS82HTk1P7vy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27c5868-5bfc-4e5e-d63d-903388e12386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Pruned Model Metrics ---\n",
            "Pruned Trainable Parameters: 36,535,818\n",
            "Parameter Reduction: 8.38%\n",
            "Calculating pruned GFLOPs...\n",
            "Pruned GFLOPs calculated on cuda:0: 191.19 GFLOPs\n",
            "GFLOPs Reduction: 6.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Save Pruned Model Structure\n",
        "# =============================================================================\n",
        "print(\"\\n--- Saving Pruned Model Structure ---\")\n",
        "\n",
        "pruned_model_saved_path = None\n",
        "if 'model_pruned' in locals() and model_pruned is not None:\n",
        "    try:\n",
        "        save_filename = f\"ddetr_torchpruned_ratio{GLOBAL_PRUNING_RATIO:.1f}_structure.safetensors\"\n",
        "        pruned_model_saved_path = os.path.join(output_dir, save_filename)\n",
        "        print(f\"Attempting to save pruned structure to: {pruned_model_saved_path}\")\n",
        "\n",
        "        # Use Hugging Face save_pretrained for better compatibility if structure changed significantly\n",
        "        model_pruned.save_pretrained(output_dir) # Saves config, weights etc. in the output dir\n",
        "        print(f\"Pruned model saved using save_pretrained to: {output_dir}\")\n",
        "        # We will use this directory for loading later if needed\n",
        "\n",
        "        # Optional: Also save just the state dict if preferred\n",
        "        # from safetensors.torch import save_file\n",
        "        # model_pruned.cpu()\n",
        "        # save_file(model_pruned.state_dict(), pruned_model_saved_path)\n",
        "        # model_pruned.to(device)\n",
        "        # print(\"Pruned model state_dict saved successfully (.safetensors).\")\n",
        "\n",
        "    except Exception as e_save:\n",
        "        print(f\"Error saving pruned model: {e_save}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"Pruned model not available, skipping save.\")"
      ],
      "metadata": {
        "id": "Oq0zqqZYP9Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba368578-80b9-4bf8-d6ef-c69c8c69dfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Saving Pruned Model Structure ---\n",
            "Attempting to save pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/ddetr_torchpruned_ratio0.1_structure.safetensors\n",
            "Pruned model saved using save_pretrained to: /content/drive/MyDrive/kitti_torch_pruning_output_v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 7: Prepare KITTI Dataset for Fine-tuning / Evaluation\n",
        "# =============================================================================\n",
        "print(\"\\n--- Preparing KITTI Dataset ---\")\n",
        "\n",
        "# Keep DefaultDataCollator import just in case, but we likely won't use it\n",
        "from transformers import DefaultDataCollator\n",
        "import traceback # Ensure traceback is imported\n",
        "\n",
        "train_dataloader = None\n",
        "val_dataloader = None\n",
        "kitti_dataset_full_coco_fmt = None\n",
        "coco_gt = None\n",
        "\n",
        "# --- File existence checks ---\n",
        "if not os.path.isdir(images_dir):\n",
        "    print(f\"ERROR: Image directory not found: {images_dir}\")\n",
        "    raise FileNotFoundError(f\"Image directory not found: {images_dir}\")\n",
        "if not os.path.exists(coco_annotation_file):\n",
        "     print(f\"WARNING: COCO annotation file not found: {coco_annotation_file}. mAP evaluation will not work.\")\n",
        "if not os.path.isdir(annotation_dir):\n",
        "     print(f\"WARNING: KITTI annotation directory not found: {annotation_dir}.\")\n",
        "     if DO_FINE_TUNING: # Only disable if planning to fine-tune\n",
        "         print(\"Disabling fine-tuning because KITTI annotations are missing.\")\n",
        "         DO_FINE_TUNING = False\n",
        "# --- End checks ---\n",
        "\n",
        "\n",
        "# --- Define Dataset Class (KittiObjectDetectionDataset) ---\n",
        "class KittiObjectDetectionDataset(Dataset):\n",
        "    def __init__(self, image_paths, annotation_dir, image_processor, label2id):\n",
        "        self.image_paths = [p for p in image_paths if os.path.exists(p)]\n",
        "        self.annotation_dir = annotation_dir\n",
        "        self.image_processor = image_processor\n",
        "        self.label2id = {k.lower(): v for k, v in label2id.items() if isinstance(k, str)}\n",
        "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
        "        print(f\"Dataset Initialized. Found {len(self.image_paths)} images. Category map: {self.label2id}\")\n",
        "        if not self.label2id: print(\"WARNING: label2id map seems incorrect or empty.\")\n",
        "        if not os.path.isdir(self.annotation_dir): print(f\"WARNING: Annotation directory missing: {self.annotation_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            img_w, img_h = image.size\n",
        "            ann_file_name = os.path.splitext(os.path.basename(img_path))[0] + \".txt\"\n",
        "            ann_file_path = os.path.join(self.annotation_dir, ann_file_name)\n",
        "            annotations_coco_fmt = {\"image_id\": idx, \"annotations\": []}\n",
        "            # --- Parse KITTI annotations ---\n",
        "            if os.path.exists(ann_file_path):\n",
        "                with open(ann_file_path, 'r') as f:\n",
        "                    for line in f:\n",
        "                        parts = line.strip().split()\n",
        "                        if not parts: continue\n",
        "                        cat_name = parts[0].lower()\n",
        "                        if cat_name in self.label2id:\n",
        "                            try:\n",
        "                                bbox_kitti = [float(x) for x in parts[4:8]]\n",
        "                                xmin, ymin, xmax, ymax = bbox_kitti\n",
        "                                xmin_c, ymin_c = max(0., xmin), max(0., ymin)\n",
        "                                xmax_c, ymax_c = min(float(img_w - 1), xmax), min(float(img_h - 1), ymax)\n",
        "                                if xmin_c < xmax_c and ymin_c < ymax_c:\n",
        "                                    box_w, box_h = xmax_c - xmin_c, ymax_c - ymin_c\n",
        "                                    annotations_coco_fmt[\"annotations\"].append({\n",
        "                                        \"image_id\": idx, \"category_id\": self.label2id[cat_name],\n",
        "                                        \"bbox\": [xmin_c, ymin_c, box_w, box_h], \"area\": box_w * box_h, \"iscrowd\": 0,\n",
        "                                    })\n",
        "                            except (ValueError, IndexError) as e_parse: continue\n",
        "            # --- End Parse ---\n",
        "            # --- Preprocess using image_processor ---\n",
        "            try: encoding = self.image_processor(images=image, annotations=annotations_coco_fmt, return_tensors=\"pt\")\n",
        "            except Exception as e_proc:\n",
        "                 print(f\"\\nERROR during image_processor call for {img_path}: {e_proc}\")\n",
        "                 try: # Try image only\n",
        "                      print(\"  Trying image processing without annotations...\")\n",
        "                      encoding = self.image_processor(images=image, return_tensors=\"pt\")\n",
        "                      encoding['labels'] = [{'boxes': torch.empty((0, 4)), 'class_labels': torch.empty((0,), dtype=torch.long)}]\n",
        "                      print(\"  Image processed, using dummy labels.\")\n",
        "                 except Exception as e_img_proc: print(f\"  ERROR processing even just the image: {e_img_proc}\"); return None\n",
        "            pixel_values = encoding[\"pixel_values\"].squeeze(0)\n",
        "            labels = encoding[\"labels\"][0] if isinstance(encoding.get(\"labels\"), list) and len(encoding[\"labels\"]) > 0 else {'boxes': torch.empty((0, 4)), 'class_labels': torch.empty((0,), dtype=torch.long)}\n",
        "            # --- Return dictionary with tensors ---\n",
        "            return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "        except Exception as e: print(f\"\\nERROR processing sample index {idx} ({img_path}): {e}\"); traceback.print_exc(); return None\n",
        "# --- End Dataset Class ---\n",
        "\n",
        "\n",
        "# --- Create Datasets and Dataloaders for Training/Validation ---\n",
        "if DO_FINE_TUNING:\n",
        "    print(\"\\nCreating training and validation datasets...\")\n",
        "    all_image_files = sorted(glob.glob(os.path.join(images_dir,\"**\",\"*.[pP][nN][gG]\"), recursive=True) + glob.glob(os.path.join(images_dir,\"**\",\"*.[jJ][pP][gG]\"), recursive=True) + glob.glob(os.path.join(images_dir,\"**\",\"*.[jJ][pP][eE][gG]\"), recursive=True))\n",
        "    if not all_image_files: print(f\"ERROR: No images found in {images_dir}. Cannot fine-tune.\"); DO_FINE_TUNING = False\n",
        "    else:\n",
        "        print(f\"Found {len(all_image_files)} total images.\")\n",
        "        random.seed(42); random.shuffle(all_image_files)\n",
        "        split_idx = int(len(all_image_files) * TRAIN_VAL_SPLIT_RATIO); train_image_files = all_image_files[:split_idx]; val_image_files = all_image_files[split_idx:]\n",
        "        if not val_image_files and train_image_files: print(\"Warning: No validation files after split, moving one from train.\"); val_image_files.append(train_image_files.pop())\n",
        "        if not train_image_files or not val_image_files: print(\"Error: Could not create non-empty train/val splits. Disabling fine-tuning.\"); DO_FINE_TUNING = False\n",
        "        else:\n",
        "             print(f\"Using {len(train_image_files)} train and {len(val_image_files)} validation images.\")\n",
        "             try:\n",
        "                  # --- label2id setup ---\n",
        "                  kitti_label2id_from_config = getattr(config, 'label2id', None)\n",
        "                  if isinstance(kitti_label2id_from_config, dict) and len(kitti_label2id_from_config) == NUM_KITTI_CLASSES: kitti_label2id = kitti_label2id_from_config; print(\"Using label2id map from loaded config.\")\n",
        "                  else:\n",
        "                       print(f\"Warning: Config label2id map missing/invalid/wrong size. Creating default map.\")\n",
        "                       kitti_cats = ['Car', 'Pedestrian', 'Cyclist']; assert NUM_KITTI_CLASSES == len(kitti_cats), \"Class num mismatch\"\n",
        "                       kitti_label2id = {name: i for i, name in enumerate(kitti_cats)}\n",
        "                  print(f\"Using label2id map for dataset: {kitti_label2id}\")\n",
        "                  assert 'image_processor' in locals() and image_processor is not None, \"Image processor not loaded.\"\n",
        "                  # --- End label2id setup ---\n",
        "\n",
        "                  train_dataset = KittiObjectDetectionDataset(train_image_files, annotation_dir, image_processor, kitti_label2id)\n",
        "                  val_dataset = KittiObjectDetectionDataset(val_image_files, annotation_dir, image_processor, kitti_label2id)\n",
        "\n",
        "                  # --- Define the Custom Collator (Revised) ---\n",
        "                  def custom_object_detection_collator(batch):\n",
        "                      batch = [item for item in batch if item is not None]\n",
        "                      if not batch: return None\n",
        "                      pixel_values = [item[\"pixel_values\"] for item in batch]\n",
        "                      labels = [item[\"labels\"] for item in batch]\n",
        "                      try:\n",
        "                          # --- Pass list directly to pad ---\n",
        "                          batch_encoding = image_processor.pad(\n",
        "                              pixel_values,       # Pass the list directly\n",
        "                              return_tensors=\"pt\"\n",
        "                          )\n",
        "                          # --- End Change ---\n",
        "                      except Exception as e_pad:\n",
        "                          print(f\"Error during image_processor.pad: {e_pad}\")\n",
        "                          shapes = [pv.shape for pv in pixel_values]\n",
        "                          print(f\"  Shapes of tensors passed to pad: {shapes}\")\n",
        "                          return None # Skip batch if padding fails\n",
        "                      # Combine padded values/mask with the original list of label dicts\n",
        "                      batch_encoding['labels'] = labels\n",
        "                      return batch_encoding\n",
        "                  # --- End Custom Collator Definition ---\n",
        "\n",
        "                  print(\"Using custom object detection collator.\")\n",
        "                  print(\"Creating dataloaders (num_workers=0)...\")\n",
        "                  train_dataloader = DataLoader(train_dataset, collate_fn=custom_object_detection_collator, batch_size=FINE_TUNE_BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "                  val_dataloader = DataLoader(val_dataset, collate_fn=custom_object_detection_collator, batch_size=FINE_TUNE_BATCH_SIZE * 2, shuffle=False, num_workers=0)\n",
        "                  print(\"Dataloaders created.\")\n",
        "\n",
        "             except Exception as e_load:\n",
        "                  print(f\"ERROR creating Datasets/Dataloaders: {e_load}\")\n",
        "                  traceback.print_exc(); DO_FINE_TUNING = False\n",
        "\n",
        "# --- Load COCO GT data ---\n",
        "if os.path.exists(coco_annotation_file):\n",
        "     try: print(f\"\\nLoading COCO ground truth for mAP evaluation from: {coco_annotation_file}\"); coco_gt = COCO(coco_annotation_file); print(\"COCO GT loaded.\")\n",
        "     except Exception as e_coco: print(f\"ERROR loading COCO annotations file '{coco_annotation_file}': {e_coco}\"); coco_gt = None\n",
        "else: print(f\"\\nCOCO annotation file for evaluation not found at: {coco_annotation_file}\"); coco_gt = None\n",
        "# --- End COCO load ---\n",
        "\n",
        "if not DO_FINE_TUNING: print(\"\\nFine-tuning disabled due to errors or configuration.\")"
      ],
      "metadata": {
        "id": "p2CWTMMGP_FU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cf3b1a-492f-4772-e1d9-2072b11515f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preparing KITTI Dataset ---\n",
            "\n",
            "Loading COCO ground truth for mAP evaluation from: /content/drive/MyDrive/kitti_subset/annotations/instances_val2017.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "COCO GT loaded.\n",
            "\n",
            "Fine-tuning disabled due to errors or configuration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell A: Pruning, Metrics, and Saving Loop (No Fine-tuning)\n",
        "# =============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import gc\n",
        "import os\n",
        "import torch_pruning as tp\n",
        "from thop import profile\n",
        "from tqdm.notebook import tqdm\n",
        "import traceback # Make sure traceback is imported\n",
        "\n",
        "print(\"\\n--- Starting Pruning & Saving Loop (No Fine-tuning) ---\")\n",
        "\n",
        "# --- Configuration for the loop ---\n",
        "target_ratios = [0.1, 0.2, 0.3, 0.4, 0.5] # Example ratios to test\n",
        "pruning_results = {} # Dictionary to store metrics and save paths\n",
        "\n",
        "# --- Ensure baseline metrics and base model exist ---\n",
        "assert 'model' in locals() and model is not None, \"Run Cell 2 first\"\n",
        "assert 'original_params' in locals() and original_params > 0, \"Run Cell 2 first\"\n",
        "assert 'original_gflops' in locals() and original_gflops > 0, \"Run Cell 3 first\"\n",
        "assert 'dummy_input' in locals() and dummy_input is not None, \"Run Cell 3 first\"\n",
        "assert 'image_processor' in locals() and image_processor is not None, \"Run Cell 2/7 first\"\n",
        "assert 'output_dir' in locals(), \"Run Cell 1 first\"\n",
        "device = next(model.parameters()).device # Get device from model\n",
        "print(f\"Base Model Parameters: {original_params:,}\")\n",
        "print(f\"Base Model GFLOPs: {original_gflops:.2f}\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Loop through each target pruning ratio ---\n",
        "for ratio in target_ratios:\n",
        "    print(f\"\\n--- Processing Ratio: {ratio:.2f} ---\")\n",
        "    pruning_results[ratio] = {} # Initialize dict for this ratio\n",
        "    model_pruned_copy = None # Ensure clean state\n",
        "\n",
        "    try:\n",
        "        # 1. Copy the original prepared model (already on GPU with std BN)\n",
        "        print(\"  Creating deepcopy of base model...\")\n",
        "        model_pruned_copy = copy.deepcopy(model)\n",
        "        model_pruned_copy.eval()\n",
        "        print(f\"  Copy created on {next(model_pruned_copy.parameters()).device}\")\n",
        "\n",
        "        # 2. Define Ignored Layers (on the copy)\n",
        "        ignored_layers_modules = []\n",
        "        print(\"  Identifying layers to ignore...\")\n",
        "        # --- Use corrected logic accessing nested 'model' ---\n",
        "        if not hasattr(model_pruned_copy, 'model') or not isinstance(model_pruned_copy.model, nn.Module): raise AttributeError(\"Nested 'model' module not found\")\n",
        "        nested_model = model_pruned_copy.model\n",
        "        def add_module_and_submodules(module_instance): # Simplified helper\n",
        "             if module_instance is None or not isinstance(module_instance, nn.Module): return\n",
        "             if module_instance not in ignored_layers_modules: ignored_layers_modules.append(module_instance)\n",
        "             for submodule in module_instance.modules():\n",
        "                 if submodule not in ignored_layers_modules and submodule is not module_instance: ignored_layers_modules.append(submodule)\n",
        "        # Add layers to ignore\n",
        "        if hasattr(nested_model, 'backbone') and hasattr(nested_model.backbone, 'conv_encoder') and hasattr(nested_model.backbone.conv_encoder, 'model'):\n",
        "            timm_model = nested_model.backbone.conv_encoder.model\n",
        "            if hasattr(timm_model, 'conv1'): ignored_layers_modules.append(timm_model.conv1)\n",
        "            if hasattr(timm_model, 'bn1'): ignored_layers_modules.append(timm_model.bn1)\n",
        "            for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                if hasattr(timm_model, layer_name):\n",
        "                    res_layer = getattr(timm_model, layer_name)\n",
        "                    if hasattr(res_layer, '__iter__'):\n",
        "                        for block in res_layer:\n",
        "                            if hasattr(block, 'downsample') and block.downsample is not None: add_module_and_submodules(block.downsample)\n",
        "        if hasattr(model_pruned_copy, 'class_embed'): add_module_and_submodules(model_pruned_copy.class_embed)\n",
        "        if hasattr(model_pruned_copy, 'bbox_embed'): add_module_and_submodules(model_pruned_copy.bbox_embed)\n",
        "        if hasattr(nested_model, 'level_embed'): ignored_layers_modules.append(nested_model.level_embed)\n",
        "        if hasattr(nested_model, 'input_proj'): add_module_and_submodules(nested_model.input_proj)\n",
        "        ignored_layers = list(set(m for m in ignored_layers_modules if isinstance(m, nn.Module) and m is not model_pruned_copy and m is not nested_model))\n",
        "        print(f\"  Identified {len(ignored_layers)} unique modules to ignore.\")\n",
        "        # --- End ignored layer identification ---\n",
        "\n",
        "        # 3. Define Pruner\n",
        "        print(f\"  Setting up Pruner for ratio {ratio:.2f}...\")\n",
        "        importance = tp.importance.MagnitudeImportance(p=1)\n",
        "        if dummy_input.device != model_pruned_copy.device: dummy_input = dummy_input.to(model_pruned_copy.device)\n",
        "        pruner = tp.pruner.MagnitudePruner( model_pruned_copy, example_inputs=dummy_input, importance=importance, pruning_ratio=ratio, ignored_layers=ignored_layers, root_module_types=[nn.Conv2d], round_to=8)\n",
        "\n",
        "        # 4. Apply Pruning\n",
        "        print(\"  Applying pruner.step()...\")\n",
        "        pruner.step()\n",
        "        print(\"  Pruning complete.\")\n",
        "        model_pruned_copy.eval()\n",
        "\n",
        "        # 5. Calculate Pruned Metrics (like Cell 5)\n",
        "        print(\"  Calculating pruned metrics...\")\n",
        "        pruned_params = sum(p.numel() for p in model_pruned_copy.parameters() if p.requires_grad)\n",
        "        pruning_results[ratio]['params'] = pruned_params\n",
        "        pruning_results[ratio]['param_reduc%'] = (1 - pruned_params/original_params)*100 if original_params > 0 else 0\n",
        "        try:\n",
        "            flops, _ = profile(model_pruned_copy, inputs=(dummy_input,), verbose=False)\n",
        "            pruned_gflops = flops / 1e9\n",
        "            pruning_results[ratio]['gflops'] = pruned_gflops\n",
        "            pruning_results[ratio]['gflop_reduc%'] = (1 - pruned_gflops/original_gflops)*100 if original_gflops > 0 else 0\n",
        "            print(f\"    Params: {pruned_params:,} (Reduction: {pruning_results[ratio]['param_reduc%']:.2f}%)\")\n",
        "            print(f\"    GFLOPs: {pruned_gflops:.2f} (Reduction: {pruning_results[ratio]['gflop_reduc%']:.2f}%)\")\n",
        "        except Exception as e_prof:\n",
        "            print(f\"    Error calculating GFLOPs: {e_prof}\")\n",
        "            pruning_results[ratio]['gflops'] = -1.0\n",
        "            pruning_results[ratio]['gflop_reduc%'] = 0.0\n",
        "\n",
        "        # 6. Save Pruned Model Structure (like Cell 6)\n",
        "        pruned_model_save_dir = os.path.join(output_dir, f\"pruned_ratio_{ratio:.2f}\")\n",
        "        print(f\"  Saving pruned structure to: {pruned_model_save_dir}\")\n",
        "        os.makedirs(pruned_model_save_dir, exist_ok=True)\n",
        "        model_pruned_copy.save_pretrained(pruned_model_save_dir)\n",
        "        if image_processor: image_processor.save_pretrained(pruned_model_save_dir)\n",
        "        pruning_results[ratio]['save_path'] = pruned_model_save_dir # Store path for later loading\n",
        "\n",
        "    except Exception as e_ratio:\n",
        "        print(f\"ERROR processing ratio {ratio:.2f}: {e_ratio}\")\n",
        "        traceback.print_exc()\n",
        "        # Store error indication\n",
        "        pruning_results[ratio]['params'] = -1; pruning_results[ratio]['gflops'] = -1; pruning_results[ratio]['error'] = str(e_ratio)\n",
        "\n",
        "    finally:\n",
        "        # --- Cleanup for next iteration ---\n",
        "        print(\"  Cleaning up memory for next ratio...\")\n",
        "        if 'model_pruned_copy' in locals() and model_pruned_copy is not None: del model_pruned_copy\n",
        "        if 'pruner' in locals(): del pruner\n",
        "        if 'ignored_layers' in locals(): del ignored_layers\n",
        "        if 'importance' in locals(): del importance\n",
        "        if 'nested_model' in locals(): del nested_model\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n--- Pruning & Saving Loop Finished ---\")\n",
        "# Store results globally if needed by next cells\n",
        "globals()['pruning_results'] = pruning_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE2GkWUteIf2",
        "outputId": "e34bee30-f981-4b1f-ba95-41844f966a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Pruning & Saving Loop (No Fine-tuning) ---\n",
            "Base Model Parameters: 39,878,026\n",
            "Base Model GFLOPs: 204.87\n",
            "Using device: cuda:0\n",
            "\n",
            "--- Processing Ratio: 0.10 ---\n",
            "  Creating deepcopy of base model...\n",
            "  Copy created on cuda:0\n",
            "  Identifying layers to ignore...\n",
            "  Identified 35 unique modules to ignore.\n",
            "  Setting up Pruner for ratio 0.10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_pruning/dependency.py:699: UserWarning: Unwrapped parameters detected: ['model.level_embed'].\n",
            " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
            "  warnings.warn(warning_str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Applying pruner.step()...\n",
            "  Pruning complete.\n",
            "  Calculating pruned metrics...\n",
            "    Params: 36,535,818 (Reduction: 8.38%)\n",
            "    GFLOPs: 191.19 (Reduction: 6.68%)\n",
            "  Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.10\n",
            "  Cleaning up memory for next ratio...\n",
            "\n",
            "--- Processing Ratio: 0.20 ---\n",
            "  Creating deepcopy of base model...\n",
            "  Copy created on cuda:0\n",
            "  Identifying layers to ignore...\n",
            "  Identified 35 unique modules to ignore.\n",
            "  Setting up Pruner for ratio 0.20...\n",
            "  Applying pruner.step()...\n",
            "  Pruning complete.\n",
            "  Calculating pruned metrics...\n",
            "    Params: 33,827,306 (Reduction: 15.17%)\n",
            "    GFLOPs: 180.16 (Reduction: 12.06%)\n",
            "  Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.20\n",
            "  Cleaning up memory for next ratio...\n",
            "\n",
            "--- Processing Ratio: 0.30 ---\n",
            "  Creating deepcopy of base model...\n",
            "  Copy created on cuda:0\n",
            "  Identifying layers to ignore...\n",
            "  Identified 35 unique modules to ignore.\n",
            "  Setting up Pruner for ratio 0.30...\n",
            "  Applying pruner.step()...\n",
            "  Pruning complete.\n",
            "  Calculating pruned metrics...\n",
            "    Params: 31,162,538 (Reduction: 21.86%)\n",
            "    GFLOPs: 171.21 (Reduction: 16.43%)\n",
            "  Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.30\n",
            "  Cleaning up memory for next ratio...\n",
            "\n",
            "--- Processing Ratio: 0.40 ---\n",
            "  Creating deepcopy of base model...\n",
            "  Copy created on cuda:0\n",
            "  Identifying layers to ignore...\n",
            "  Identified 35 unique modules to ignore.\n",
            "  Setting up Pruner for ratio 0.40...\n",
            "  Applying pruner.step()...\n",
            "  Pruning complete.\n",
            "  Calculating pruned metrics...\n",
            "    Params: 28,882,570 (Reduction: 27.57%)\n",
            "    GFLOPs: 161.91 (Reduction: 20.97%)\n",
            "  Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.40\n",
            "  Cleaning up memory for next ratio...\n",
            "\n",
            "--- Processing Ratio: 0.50 ---\n",
            "  Creating deepcopy of base model...\n",
            "  Copy created on cuda:0\n",
            "  Identifying layers to ignore...\n",
            "  Identified 35 unique modules to ignore.\n",
            "  Setting up Pruner for ratio 0.50...\n",
            "  Applying pruner.step()...\n",
            "  Pruning complete.\n",
            "  Calculating pruned metrics...\n",
            "    Params: 26,899,466 (Reduction: 32.55%)\n",
            "    GFLOPs: 156.28 (Reduction: 23.72%)\n",
            "  Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.50\n",
            "  Cleaning up memory for next ratio...\n",
            "\n",
            "--- Pruning & Saving Loop Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell B: Evaluation Loop (Correct Loading and BN Replace)\n",
        "# =============================================================================\n",
        "import torch\n",
        "import torch.nn as nn # Needed for BatchNorm2d\n",
        "import os\n",
        "import gc\n",
        "from transformers import AutoModelForObjectDetection, AutoImageProcessor, AutoConfig\n",
        "# --- Import Safetensors if needed ---\n",
        "try:\n",
        "    from safetensors.torch import load_file as load_safetensors\n",
        "    SAFE_TENSORS_AVAILABLE = True\n",
        "except ImportError: print(\"Warning: safetensors library not found.\"); SAFE_TENSORS_AVAILABLE = False\n",
        "# --- End Import ---\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import traceback\n",
        "# No torch_pruning import needed here anymore\n",
        "\n",
        "# --- Import Helper Functions from Cell 1 ---\n",
        "assert 'set_module_by_name' in globals(), \"Helper function set_module_by_name not defined (run Cell 1)\"\n",
        "# --- End Import ---\n",
        "\n",
        "print(\"\\n--- Starting Evaluation Loop (Correct Loading and BN Replace) ---\")\n",
        "\n",
        "# --- Ensure previous results and COCO GT are available ---\n",
        "assert 'pruning_results' in locals(), \"Pruning results dictionary not found. Run Cell A first.\"\n",
        "assert 'coco_gt' in locals(), \"coco_gt object from Cell 7 is needed.\"\n",
        "assert 'image_processor' in locals(), \"image_processor object needed.\"\n",
        "assert 'images_dir' in locals(), \"images_dir path needed.\"\n",
        "if 'device' not in locals(): device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Function to Replace FrozenBN ---\n",
        "# (Keep the same replace_frozen_bn function as defined in the previous response)\n",
        "def replace_frozen_bn(model_to_modify):\n",
        "    FROZEN_BN_TYPE = None\n",
        "    try:\n",
        "        from transformers.models.deformable_detr.modeling_deformable_detr import DeformableDetrFrozenBatchNorm2d\n",
        "        FROZEN_BN_TYPE = DeformableDetrFrozenBatchNorm2d\n",
        "    except ImportError: print(\"WARNING: DeformableDetrFrozenBatchNorm2d not found during replacement.\"); return model_to_modify, 0\n",
        "    if not FROZEN_BN_TYPE: return model_to_modify, 0\n",
        "    replacement_count = 0; error_count = 0\n",
        "    module_list = list(model_to_modify.named_modules())\n",
        "    print(f\"    Replacing FrozenBN in {len(module_list)} modules...\")\n",
        "    modules_to_replace = []\n",
        "    for name, module in module_list:\n",
        "        if isinstance(module, FROZEN_BN_TYPE): modules_to_replace.append(name)\n",
        "    for name in modules_to_replace:\n",
        "        try:\n",
        "            module = model_to_modify.get_submodule(name)\n",
        "            if not isinstance(module, FROZEN_BN_TYPE): continue\n",
        "            if hasattr(module, 'weight') and module.weight is not None: num_features = module.weight.shape[0]\n",
        "            else: print(f\"      Skipping {name} - no weight attr.\"); error_count += 1; continue\n",
        "            current_mod_device = 'cpu';\n",
        "            try: current_mod_device = next(iter(module.parameters()), torch.tensor(0)).device\n",
        "            except StopIteration: pass\n",
        "            new_bn = nn.BatchNorm2d(num_features, eps=1e-5, affine=True, track_running_stats=True).to(current_mod_device)\n",
        "            # Copy weights *after* creating new BN, *before* replacing\n",
        "            # This is essential if the loaded model already has trained stats in FrozenBN\n",
        "            if hasattr(module, 'weight') and module.weight is not None and hasattr(new_bn,'weight') and new_bn.weight.shape == module.weight.shape: new_bn.weight.data.copy_(module.weight.data)\n",
        "            if hasattr(module, 'bias') and module.bias is not None and hasattr(new_bn,'bias') and new_bn.bias.shape == module.bias.shape: new_bn.bias.data.copy_(module.bias.data)\n",
        "            if hasattr(module, 'running_mean') and module.running_mean is not None and hasattr(new_bn,'running_mean') and new_bn.running_mean.shape == module.running_mean.shape: new_bn.running_mean.data.copy_(module.running_mean.data)\n",
        "            if hasattr(module, 'running_var') and module.running_var is not None and hasattr(new_bn,'running_var') and new_bn.running_var.shape == module.running_var.shape: new_bn.running_var.data.copy_(module.running_var.data)\n",
        "            if hasattr(module, 'num_batches_tracked') and module.num_batches_tracked is not None and hasattr(new_bn, 'num_batches_tracked'): new_bn.num_batches_tracked.data.copy_(module.num_batches_tracked.data)\n",
        "            # Now replace\n",
        "            set_module_by_name(model_to_modify, name, new_bn)\n",
        "            replacement_count += 1\n",
        "        except Exception as e_replace: print(f\"      ERROR replacing {name}: {e_replace}\"); traceback.print_exc(); error_count += 1\n",
        "    print(f\"    Finished replacement. Replaced: {replacement_count}, Errors: {error_count}\")\n",
        "    if error_count > 0: print(\"    WARNING: Errors occurred during BN replacement.\")\n",
        "    return model_to_modify, replacement_count\n",
        "# --- End Replace Function ---\n",
        "\n",
        "\n",
        "if coco_gt is None:\n",
        "    print(\"COCO ground truth not loaded (coco_gt is None). Cannot calculate COCO mAP.\")\n",
        "    for ratio in pruning_results:\n",
        "        if 'mAP' not in pruning_results[ratio]: pruning_results[ratio]['mAP'] = -1.0\n",
        "        if 'mAP50' not in pruning_results[ratio]: pruning_results[ratio]['mAP50'] = -1.0\n",
        "else:\n",
        "    # --- Define CocoEvalDataset (as before) ---\n",
        "    class CocoEvalDataset(Dataset):\n",
        "         def __init__(self, coco_gt_obj, img_dir):\n",
        "             self.coco=coco_gt_obj; self.img_ids=coco_gt_obj.getImgIds(); self.img_dir=img_dir\n",
        "             self.img_info = coco_gt_obj.loadImgs(self.img_ids); self.id_to_path = {info['id']: os.path.join(img_dir, info['file_name']) for info in self.img_info if 'file_name' in info}\n",
        "             print(f\"CocoEvalDataset: Mapped {len(self.id_to_path)} image IDs to paths.\"); missing = [i for i in self.img_ids if i not in self.id_to_path or not os.path.exists(self.id_to_path[i])];\n",
        "             if missing: print(f\"  Warning: Missing files for {len(missing)} IDs (e.g., {missing[:5]})\")\n",
        "         def __len__(self): return len(self.img_ids)\n",
        "         def __getitem__(self, idx):\n",
        "             img_id = self.img_ids[idx]; path = self.id_to_path.get(img_id)\n",
        "             if path and os.path.exists(path):\n",
        "                 try: img = Image.open(path).convert(\"RGB\"); target = {\"image_id\": img_id, \"width\": img.width, \"height\": img.height}; return img, target\n",
        "                 except Exception as e: print(f\"Err loading {path}: {e}\"); return None\n",
        "             return None\n",
        "    # --- End Dataset Def ---\n",
        "\n",
        "    sorted_ratios = sorted(pruning_results.keys())\n",
        "    for ratio in sorted_ratios:\n",
        "        print(f\"\\n--- Evaluating Ratio: {ratio:.2f} ---\")\n",
        "        eval_model = None\n",
        "        pruning_results[ratio]['mAP'] = -1.0; pruning_results[ratio]['mAP50'] = -1.0\n",
        "\n",
        "        if pruning_results[ratio].get('params', -1) == -1 or 'save_path' not in pruning_results[ratio]: print(\"  Skipping evaluation due to previous error or missing save path.\"); continue\n",
        "        saved_model_path = pruning_results[ratio]['save_path']\n",
        "        if not os.path.isdir(saved_model_path): print(f\"  Saved model path not found: {saved_model_path}. Skipping.\"); continue\n",
        "\n",
        "        try:\n",
        "            # 1. Load pruned model structure and weights directly\n",
        "            print(f\"  Loading pruned model using from_pretrained: {saved_model_path}\")\n",
        "            # Set low_cpu_mem_usage=True if memory becomes an issue during loading large models\n",
        "            eval_model = AutoModelForObjectDetection.from_pretrained(\n",
        "                saved_model_path,\n",
        "                # low_cpu_mem_usage=True, # Optional\n",
        "                # ignore_mismatched_sizes=False # Should not be needed now\n",
        "            )\n",
        "            print(\"  Model loaded initially (may have FrozenBN).\")\n",
        "\n",
        "            # 2. Replace FrozenBN layers *after* loading the model\n",
        "            print(\"  Replacing any FrozenBN layers in loaded model...\")\n",
        "            # Move to CPU for replacement safety, then back to GPU\n",
        "            eval_model.cpu()\n",
        "            eval_model, bn_replaced_count = replace_frozen_bn(eval_model)\n",
        "            eval_model.to(device) # Move back to evaluation device\n",
        "            eval_model.eval()\n",
        "            print(\"  BN replacement attempted, model ready on device.\")\n",
        "\n",
        "            # 3. Prepare Evaluation DataLoader\n",
        "            # ... (dataloader setup as before) ...\n",
        "            print(\"  Preparing evaluation dataloader...\")\n",
        "            eval_dataset = CocoEvalDataset(coco_gt_obj=coco_gt, img_dir=images_dir)\n",
        "            def eval_collate_fn(batch): batch = [item for item in batch if item is not None]; return batch[0] if batch else None\n",
        "            eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=eval_collate_fn)\n",
        "            print(f\"  DataLoader ready with {len(eval_dataset)} images.\")\n",
        "\n",
        "\n",
        "            # 4. Run Inference\n",
        "            # ... (inference loop as before) ...\n",
        "            coco_results_eval = []; processed_eval_count = 0\n",
        "            print(\"  Running inference...\")\n",
        "            with torch.no_grad():\n",
        "                for batch_data in tqdm(eval_loader, desc=f\"  Evaluating Ratio {ratio:.2f}\", leave=False):\n",
        "                    if batch_data is None: continue\n",
        "                    image, target = batch_data; image_id = target['image_id']\n",
        "                    try:\n",
        "                        original_size = (target['height'], target['width']); inputs = image_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "                        outputs = eval_model(**inputs)\n",
        "                        target_sizes = torch.tensor([original_size], device=device)\n",
        "                        results_det = image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.1)[0]\n",
        "                        boxes, scores, labels = results_det[\"boxes\"].cpu().tolist(), results_det[\"scores\"].cpu().tolist(), results_det[\"labels\"].cpu().tolist()\n",
        "                        for box, score, label in zip(boxes, scores, labels):\n",
        "                            x_min, y_min, x_max, y_max = box; coco_bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
        "                            coco_results_eval.append({\"image_id\": image_id, \"category_id\": label, \"bbox\": coco_bbox, \"score\": score})\n",
        "                        processed_eval_count += 1\n",
        "                    except Exception as e_infer: print(f\"    Infer Err (img {image_id}): {e_infer}\"); traceback.print_exc(); continue\n",
        "            print(f\"  Processed {processed_eval_count} images for evaluation.\")\n",
        "\n",
        "\n",
        "            # 5. Run COCOeval API\n",
        "            # ... (COCOeval logic as before) ...\n",
        "            if coco_results_eval:\n",
        "                 print(\"  Running COCO evaluation API...\")\n",
        "                 try:\n",
        "                     coco_dt = coco_gt.loadRes(coco_results_eval); coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "                     coco_eval.evaluate(); coco_eval.accumulate(); coco_eval.summarize()\n",
        "                     pruning_results[ratio]['mAP'] = coco_eval.stats[0]; pruning_results[ratio]['mAP50'] = coco_eval.stats[1]\n",
        "                     print(f\"    mAP: {pruning_results[ratio]['mAP']:.4f}, mAP50: {pruning_results[ratio]['mAP50']:.4f}\")\n",
        "                 except Exception as e_coco_api: print(f\"    ERROR during COCOeval: {e_coco_api}\"); traceback.print_exc()\n",
        "            else: print(\"    No evaluation results generated.\")\n",
        "\n",
        "        except Exception as e_eval_ratio:\n",
        "            print(f\"  ERROR during evaluation prep/run for ratio {ratio:.2f}: {e_eval_ratio}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        finally:\n",
        "            # Cleanup\n",
        "            print(\"  Cleaning up evaluation objects...\")\n",
        "            if 'eval_model' in locals(): del eval_model\n",
        "            if 'eval_loader' in locals(): del eval_loader\n",
        "            if 'eval_dataset' in locals(): del eval_dataset\n",
        "            if 'coco_dt' in locals(): del coco_dt\n",
        "            if 'coco_eval' in locals(): del coco_eval\n",
        "            gc.collect();\n",
        "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n--- Evaluation Loop Finished ---\")\n",
        "globals()['pruning_results'] = pruning_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPtWZ47AeMUd",
        "outputId": "7476f215-1351-41a4-93c9-f585ad38fbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Evaluation Loop (Correct Loading and BN Replace) ---\n",
            "Using device: cuda:0\n",
            "\n",
            "--- Evaluating Ratio: 0.10 ---\n",
            "  Loading pruned model using from_pretrained: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.10\n",
            "  ERROR during evaluation prep/run for ratio 0.10: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up evaluation objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-685423b58c8b>\", line 115, in <cell line: 0>\n",
            "    eval_model = AutoModelForObjectDetection.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Ratio: 0.20 ---\n",
            "  Loading pruned model using from_pretrained: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.20\n",
            "  ERROR during evaluation prep/run for ratio 0.20: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up evaluation objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-685423b58c8b>\", line 115, in <cell line: 0>\n",
            "    eval_model = AutoModelForObjectDetection.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Ratio: 0.30 ---\n",
            "  Loading pruned model using from_pretrained: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.30\n",
            "  ERROR during evaluation prep/run for ratio 0.30: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up evaluation objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-685423b58c8b>\", line 115, in <cell line: 0>\n",
            "    eval_model = AutoModelForObjectDetection.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Ratio: 0.40 ---\n",
            "  Loading pruned model using from_pretrained: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.40\n",
            "  ERROR during evaluation prep/run for ratio 0.40: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up evaluation objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-685423b58c8b>\", line 115, in <cell line: 0>\n",
            "    eval_model = AutoModelForObjectDetection.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Ratio: 0.50 ---\n",
            "  Loading pruned model using from_pretrained: /content/drive/MyDrive/kitti_torch_pruning_output_v1/pruned_ratio_0.50\n",
            "  ERROR during evaluation prep/run for ratio 0.50: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up evaluation objects...\n",
            "\n",
            "--- Evaluation Loop Finished ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-685423b58c8b>\", line 115, in <cell line: 0>\n",
            "    eval_model = AutoModelForObjectDetection.from_pretrained(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell C: Final Summary\n",
        "# =============================================================================\n",
        "print(\"\\n--- Summary of Pruning Results (No Fine-tuning) ---\")\n",
        "\n",
        "# Ensure results dictionary exists\n",
        "assert 'pruning_results' in locals(), \"Run Cell A and Cell B first.\"\n",
        "assert 'original_params' in locals(), \"Original params not found.\"\n",
        "assert 'original_gflops' in locals(), \"Original GFLOPs not found.\"\n",
        "\n",
        "print(f\"Baseline Parameters: {original_params:,}\")\n",
        "print(f\"Baseline GFLOPs: {original_gflops:.2f}\")\n",
        "print(\"-\" * 85)\n",
        "print(f\"{'Ratio':<7} | {'Pruned Params':<15} | {'Param Reduc':<12} | {'Pruned GFLOPs':<15} | {'GFLOPs Reduc':<13} | {'mAP':<9} | {'mAP50':<9}\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "sorted_ratios = sorted(pruning_results.keys())\n",
        "for ratio in sorted_ratios:\n",
        "    res = pruning_results[ratio]\n",
        "    if res.get('params', -1) == -1: # Check if pruning failed for this ratio\n",
        "        status = res.get('error', 'Pruning/Metric Error')\n",
        "        print(f\"{ratio:<7.2f} | {'ERROR':<15} | {'ERROR':<12} | {'ERROR':<15} | {'ERROR':<13} | {'ERROR':<9} | {'ERROR':<9}\")\n",
        "        print(f\"  Error msg: {status}\")\n",
        "    else:\n",
        "        param_reduc_str = f\"{res.get('param_reduc%', 0.0):.2f}%\"\n",
        "        gflop_str = f\"{res.get('gflops', -1.0):.2f}\" if res.get('gflops', -1.0) >= 0 else \"Error\"\n",
        "        gflop_reduc_str = f\"{res.get('gflop_reduc%', 0.0):.2f}%\" if res.get('gflops', -1.0) >= 0 else \"Error\"\n",
        "        map_str = f\"{res.get('mAP', -1.0):.4f}\" if res.get('mAP', -1.0) >= 0 else \"N/A\"\n",
        "        map50_str = f\"{res.get('mAP50', -1.0):.4f}\" if res.get('mAP50', -1.0) >= 0 else \"N/A\"\n",
        "\n",
        "        print(f\"{ratio:<7.2f} | {res.get('params', 0):<15,} | {param_reduc_str:<12} | {gflop_str:<15} | {gflop_reduc_str:<13} | {map_str:<9} | {map50_str:<9}\")\n",
        "\n",
        "print(\"-\" * 85)\n",
        "print(\"\\nSaved model paths:\")\n",
        "for ratio in sorted_ratios:\n",
        "    print(f\"  Ratio {ratio:.2f}: {pruning_results[ratio].get('save_path', 'N/A or Error')}\")\n",
        "\n",
        "print(\"\\n--- End of Summary ---\")"
      ],
      "metadata": {
        "id": "GK-aszBIeSxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 8: Fine-tuning Loop\n",
        "# =============================================================================\n",
        "print(\"\\n--- Fine-tuning Pruned Model ---\")\n",
        "\n",
        "final_model_saved_path = None # Initialize path for final model\n",
        "\n",
        "if not DO_FINE_TUNING:\n",
        "    print(\"Skipping fine-tuning (disabled).\")\n",
        "elif 'model_pruned' not in locals() or model_pruned is None:\n",
        "     print(\"Skipping fine-tuning: Pruned model is not available.\")\n",
        "elif train_dataloader is None or val_dataloader is None:\n",
        "     print(\"Skipping fine-tuning: Dataloaders not available.\")\n",
        "else:\n",
        "    print(f\"Starting fine-tuning for {FINE_TUNE_EPOCHS} epochs...\")\n",
        "    model_pruned.to(device) # Ensure model is on GPU\n",
        "\n",
        "    # Filter parameters that require gradients (only necessary if some layers were frozen)\n",
        "    params_to_optimize = filter(lambda p: p.requires_grad, model_pruned.parameters())\n",
        "    optimizer = torch.optim.AdamW(params_to_optimize, lr=FINE_TUNE_LR, weight_decay=1e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # Example scheduler\n",
        "\n",
        "    print(f\"Optimizer: AdamW, LR={FINE_TUNE_LR}, Scheduler: StepLR\")\n",
        "    if not list(filter(lambda p: p.requires_grad, model_pruned.parameters())):\n",
        "         print(\"WARNING: No trainable parameters found in the model!\")\n",
        "         # Set DO_FINE_TUNING to False maybe? Or just let it run doing nothing.\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(FINE_TUNE_EPOCHS):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{FINE_TUNE_EPOCHS} ---\")\n",
        "        model_pruned.train() # Set model to training mode\n",
        "        model_pruned.to(device) # Ensure model is on the correct device at epoch start\n",
        "        total_train_loss = 0\n",
        "        processed_batches = 0\n",
        "\n",
        "        progress_bar_train = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
        "        for batch in progress_bar_train:\n",
        "            if batch is None: continue # Skip bad batches\n",
        "\n",
        "            try:\n",
        "                pixel_values = batch[\"pixel_values\"].to(device)\n",
        "                # pixel_mask = batch[\"pixel_mask\"].to(device) # Usually handled by processor or model internals\n",
        "                labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model_pruned(pixel_values=pixel_values, pixel_mask=None, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                loss_dict = outputs.loss_dict\n",
        "\n",
        "                if not torch.isfinite(loss):\n",
        "                     print(f\"WARNING: NaN/Inf loss detected ({loss.item()}). Skipping batch.\")\n",
        "                     optimizer.zero_grad() # Clear potential bad grads\n",
        "                     continue\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model_pruned.parameters(), max_norm=0.1)\n",
        "                optimizer.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "                processed_batches += 1\n",
        "                progress_bar_train.set_postfix({'loss': f\"{loss.item():.4f}\", 'avg_loss': f\"{total_train_loss/processed_batches:.4f}\"})\n",
        "\n",
        "            except Exception as e_train:\n",
        "                print(f\"\\nERROR during training batch: {e_train}\")\n",
        "                traceback.print_exc()\n",
        "                continue # Continue to next batch\n",
        "\n",
        "        avg_train_loss = total_train_loss / processed_batches if processed_batches > 0 else 0\n",
        "        print(f\"Epoch {epoch+1} Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # --- Validation ---\n",
        "        model_pruned.eval() # Set model to evaluation mode\n",
        "        total_val_loss = 0\n",
        "        val_batches = 0\n",
        "        print(\"Running validation...\")\n",
        "        progress_bar_val = tqdm(val_dataloader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for batch in progress_bar_val:\n",
        "                 if batch is None: continue\n",
        "                 try:\n",
        "                      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "                      labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "                      outputs = model_pruned(pixel_values=pixel_values, pixel_mask=None, labels=labels)\n",
        "                      loss = outputs.loss\n",
        "\n",
        "                      if torch.isfinite(loss):\n",
        "                           total_val_loss += loss.item()\n",
        "                           val_batches += 1\n",
        "                 except Exception as e_val:\n",
        "                      print(f\"\\nERROR during validation batch: {e_val}\")\n",
        "                      continue\n",
        "\n",
        "        avg_val_loss = total_val_loss / val_batches if val_batches > 0 else 0\n",
        "        print(f\"Epoch {epoch+1} Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Step the scheduler\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Epoch {epoch+1} completed. Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        # --- Save Checkpoint ---\n",
        "        checkpoint_saved_this_epoch = False\n",
        "        try:\n",
        "            # Prefer saving full model state using save_pretrained in the checkpoint dir\n",
        "            ckpt_dir = os.path.join(output_dir, f\"checkpoint-epoch-{epoch+1}\")\n",
        "            print(f\"  Saving checkpoint to: {ckpt_dir}\")\n",
        "            model_pruned.save_pretrained(ckpt_dir)\n",
        "            # Also save processor config for easy reloading\n",
        "            if image_processor: image_processor.save_pretrained(ckpt_dir)\n",
        "            print(f\"  Checkpoint saved successfully.\")\n",
        "            checkpoint_saved_this_epoch = True\n",
        "        except Exception as e_ckpt:\n",
        "             print(f\"  ERROR saving checkpoint: {e_ckpt}\")\n",
        "             traceback.print_exc()\n",
        "\n",
        "    print(\"\\n--- Fine-tuning finished ---\")\n",
        "\n",
        "    # --- Save Final Model ---\n",
        "    try:\n",
        "        final_save_dir = os.path.join(output_dir, \"final_model\")\n",
        "        print(f\"Saving final model to: {final_save_dir}\")\n",
        "        model_pruned.save_pretrained(final_save_dir)\n",
        "        if image_processor: image_processor.save_pretrained(final_save_dir)\n",
        "        # Update the path variable for the summary cell\n",
        "        final_model_saved_path = final_save_dir\n",
        "        print(\"Final model saved successfully.\")\n",
        "    except Exception as e_final_save:\n",
        "        print(f\"Error saving final model: {e_final_save}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Cleanup dataloaders to free memory\n",
        "del train_dataloader, val_dataloader, train_dataset, val_dataset\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "print(\"Cleaned up dataloaders.\")"
      ],
      "metadata": {
        "id": "4ZLUHOiuQDSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906,
          "referenced_widgets": [
            "070d82c0bb98406f8098343bd80c80c9",
            "628c112490534fb58623569b7b8ef773",
            "0ff96f4ed59447b499d8907a45582d40",
            "2c93b94d732049de98cc1537e43419e4",
            "dc1d352ab5504101a152495e3a2435de",
            "e92579fc965b45ffbb41a2d39233d532",
            "84916d4216c248d7a0c16a156f769494",
            "187445f64c654066923c2fc4a51f5b7f",
            "093b7a2927a64c539b1c6689b67adf7b",
            "2069ec7d9cbd494490ebee9051bb2118",
            "dc527372008340249196492250f964da",
            "38d80868e3fb46d0b5b17cded7b5c704",
            "b3b389649b534b9fbd934ce7a237a40d",
            "2b13b5906b3a41bfb3001539099f5c04",
            "3f0e6e7e129d4c8093c1a08b0f668ed3",
            "d94117748ff041b38406bb4c75d50f2c",
            "e4f0f555ab824517b65f71795cf985c2",
            "cf51d318d2b64f4f9caba663940eac23",
            "311dc8d714f64984a177b3df76b15f92",
            "599957a2d965433fa2e12b88bf4434eb",
            "d0f8fdbb27d94871a6cef7ddf4b00dbc",
            "86c3f2f80f08421dbf01a409f546e665",
            "63949660e46e4650a4722b0787588102",
            "914b1ff30308476abf265309fbe99228",
            "f87a2576411f4f128b3074919fcbf519",
            "e61df5b388804e1b8fc654550b791adb",
            "982ed36a62114e5ab76a2a217daf91f3",
            "08c77e084b934f86baecd25f689d53ad",
            "91cc31f82f954fb5b393e025e6bb7854",
            "f26466c45c8b47e0912975a0736390ce",
            "c995dc2f89e74266911a6d2be6b62b79",
            "710ec358e3e14292be1456e43ab2d5e7",
            "8b2e5f799d6f46a0a542bd5ffd5fefc9",
            "605c4b4ebabe4e768544ae31065746b7",
            "0fe5538f52674fa5ae3cd7330f47e194",
            "d22414fc7ba041149014d62a7729e4a3",
            "efd5b3b44d5d4a179facdc879105caed",
            "466c44337b5d4a2e9dfe5e208031918a",
            "bf1eb525ac5e4cd59491610174ecec59",
            "f0c32b88719a4f7495f8a3e1681322e0",
            "7ffa10b606a24ec086dfebe66c09610f",
            "dd1f1f6f6ca044f0aa30b4fb7c38386a",
            "b81141a34b524bc8b94a406b7a3a8a65",
            "fd2a8275f20648e2ab757a707546e092",
            "a9dd84d623b74c7db4a42660a834c435",
            "3414eec5d6c74af8a3db50600fe0b0f5",
            "b5672fa7860a43e3ba842aa9255db302",
            "910890650790490ab5b6f0d15a5c86c7",
            "f3c35a1ae96147fd93071ebf4997aec0",
            "8dd0ec61362c4f00b0a408ac7968a717",
            "43b492b1b18a4610a0e6e31882088591",
            "dcab443238164624a753ab50c661461c",
            "1e83c1c01c2241618aaffa7f398f4304",
            "5a351f0e6a4e4a42a081f0e6fc4ac60b",
            "8c593136ba21491bb340679c18f42318",
            "1e9cf68f7890467ebfa1fcf8260c329d",
            "8f00a559f0a8488b96c06c3b51a677dd",
            "e7c6e3b751484c84bdb7d4a22aaca50e",
            "122e3914cf834675913696aa99c22eb6",
            "6cf16609e30e4988bf680b1b7461c4b4",
            "02b8c8b168454d468bfdaf4ed5b1bfb2",
            "17e73a6045ce402381a73be9581789c2",
            "adffe91038e34da29134028532021d4a",
            "2e8f5cbec97f4194bf6f5810223c95bc",
            "bab31e0a5224491380117186b1c59b84",
            "c25cb53fa2014bff88c457b5b90bdcb6",
            "9c1753369ea646c0b8275ff8d19dc47f",
            "91f3e8bb3b494d8898856c5fc31a79ee",
            "579be0d454a64f118c2c56fb757add50",
            "b1085c32153547f9b802fbad4b44d715",
            "e8869ba5aff8459ca759475752d4d489",
            "3eae2c5b4b5e4ef1beb3e2602536d0f7",
            "961652313228408dbd13bf970c4bf3ad",
            "cd946b05200c48349c2c646983840693",
            "e305531b4fb24e4f84928292661283cd",
            "494f065a16bb488f9c76687399e166dc",
            "ba604fff017b4363b9bffcd7ba7ab6af",
            "c7abccaee1624faf89ce4dadc9d25d67",
            "b6688d574a9c4db4b2904291b7ef8838",
            "52ce1a13935d4a5f9cc9850c7fbf0572",
            "ef4153298be248a5a4df1417e9302003",
            "c11e046dd3574ff2a9c28fab5c9ed9cd",
            "7513387f3a194dee8c600fbd8a337007",
            "6e8f3d9e6a6e41d58df389f738b6bd69",
            "e21dcb8b016e4c859e19c517bafa37ca",
            "5b204dbded584004badcfbdb9b2b61fc",
            "2b74256f4a0f4fb7ba0378a8b36ec40a",
            "04d8429c49494ae980ac18bece059f7b",
            "8031b6124360488f980ca83f72e19574",
            "c66f6eaeae494a0893048fdb0c2a7ccc",
            "733116468b3e4273918f15423f1f7699",
            "800103b86e8c49e49687c5e72363c07d",
            "84206f0dfc8a4434a68c90fd97ab8224",
            "72d3526b1f104e4cb9ff73995b3af91f",
            "3c9be7d88fca48fab1fe4fb54d0cd705",
            "2544fbc492e748ddb1027c330a213026",
            "b3733973699c44f683327b1051bff9f3",
            "d55890fe745248348f9aaee579043053",
            "13b997c39a6047bd8f15e776856c0ead",
            "e203d9c7c7fb4257970fa04e790798b1",
            "9d3901cbc4d740a884d90d193390d671",
            "5b76924bbce0443a8601fe4bf4781c5a",
            "38f5390cb79949738c975bc25dc2582c",
            "1fa3ead525b94bfb8a8d5dd0ec6f9184",
            "81c1f543dc4d4a70ae719a50a759acb3",
            "fd3d967824444b14a5b872bdd36194e8",
            "a3ba5af529074ab38c5d3856004e5c96",
            "5ad35d206490478b8b6df941612dde41",
            "25a9e7c9dd9942a69ec3066ba2ed678a",
            "c4681ca1d24d4d87966332aaae3d9f5b"
          ]
        },
        "outputId": "bd471c10-f3f3-42a4-ed15-879503fa2c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning Pruned Model ---\n",
            "Starting fine-tuning for 5 epochs...\n",
            "Optimizer: AdamW, LR=1e-05, Scheduler: StepLR\n",
            "\n",
            "--- Epoch 1/5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1 Training:   0%|          | 0/879 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "070d82c0bb98406f8098343bd80c80c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Average Training Loss: 9.1055\n",
            "Running validation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1 Validation:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38d80868e3fb46d0b5b17cded7b5c704"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Average Validation Loss: 0.0059\n",
            "Epoch 1 completed. Current LR: 1.00e-05\n",
            "  Saving checkpoint to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/checkpoint-epoch-1\n",
            "  Checkpoint saved successfully.\n",
            "\n",
            "--- Epoch 2/5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2 Training:   0%|          | 0/879 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63949660e46e4650a4722b0787588102"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Average Training Loss: 0.0011\n",
            "Running validation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2 Validation:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "605c4b4ebabe4e768544ae31065746b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Average Validation Loss: 0.0007\n",
            "Epoch 2 completed. Current LR: 1.00e-05\n",
            "  Saving checkpoint to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/checkpoint-epoch-2\n",
            "  Checkpoint saved successfully.\n",
            "\n",
            "--- Epoch 3/5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3 Training:   0%|          | 0/879 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9dd84d623b74c7db4a42660a834c435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Average Training Loss: 0.0003\n",
            "Running validation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3 Validation:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e9cf68f7890467ebfa1fcf8260c329d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Average Validation Loss: 0.0003\n",
            "Epoch 3 completed. Current LR: 1.00e-05\n",
            "  Saving checkpoint to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/checkpoint-epoch-3\n",
            "  Checkpoint saved successfully.\n",
            "\n",
            "--- Epoch 4/5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4 Training:   0%|          | 0/879 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c1753369ea646c0b8275ff8d19dc47f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Average Training Loss: 0.0001\n",
            "Running validation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4 Validation:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7abccaee1624faf89ce4dadc9d25d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Average Validation Loss: 0.0001\n",
            "Epoch 4 completed. Current LR: 1.00e-05\n",
            "  Saving checkpoint to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/checkpoint-epoch-4\n",
            "  Checkpoint saved successfully.\n",
            "\n",
            "--- Epoch 5/5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 5 Training:   0%|          | 0/879 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8031b6124360488f980ca83f72e19574"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Average Training Loss: 0.0001\n",
            "Running validation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 5 Validation:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e203d9c7c7fb4257970fa04e790798b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Average Validation Loss: 0.0001\n",
            "Epoch 5 completed. Current LR: 1.00e-06\n",
            "  Saving checkpoint to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/checkpoint-epoch-5\n",
            "  Checkpoint saved successfully.\n",
            "\n",
            "--- Fine-tuning finished ---\n",
            "Saving final model to: /content/drive/MyDrive/kitti_torch_pruning_output_v1/final_model\n",
            "Final model saved successfully.\n",
            "Cleaned up dataloaders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 9: Evaluation (mAP after Fine-tuning)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Evaluating mAP After Fine-tuning (Requires COCO annotations) ---\\n\")\n",
        "\n",
        "# Ensure necessary variables exist\n",
        "assert 'model_pruned' or 'final_model_saved_path' in locals(), \"Fine-tuning cell must run first or model path needed.\"\n",
        "assert 'coco_gt' in locals(), \"COCO GT object needed for evaluation (loaded in Cell 7).\"\n",
        "assert 'image_processor' in locals(), \"Image processor needed.\"\n",
        "\n",
        "# --- Decide which model to evaluate ---\n",
        "eval_model = None\n",
        "eval_model_source = None # For logging\n",
        "\n",
        "# Option 1: Use the model currently in memory if fine-tuning just finished\n",
        "if 'model_pruned' in locals() and model_pruned is not None and 'DO_FINE_TUNING' in locals() and DO_FINE_TUNING:\n",
        "     print(\"Evaluating the model currently in memory (fine-tuned).\")\n",
        "     eval_model = model_pruned # Use the model directly\n",
        "     eval_model_source = \"memory (fine-tuned)\"\n",
        "# Option 2: Load the final saved model (if fine-tuning was done and saved)\n",
        "elif 'final_model_saved_path' in locals() and final_model_saved_path and os.path.isdir(final_model_saved_path):\n",
        "     print(f\"Loading final saved model from: {final_model_saved_path}\")\n",
        "     eval_model_source = final_model_saved_path\n",
        "     try:\n",
        "          # Assume config and processor were saved alongside\n",
        "          # config = AutoConfig.from_pretrained(final_model_saved_path) # Config might be needed if model class changed drastically\n",
        "          # Re-load processor just in case it's needed and not in memory\n",
        "          if 'image_processor' not in locals() or image_processor is None:\n",
        "               image_processor = AutoImageProcessor.from_pretrained(final_model_saved_path)\n",
        "          eval_model = AutoModelForObjectDetection.from_pretrained(final_model_saved_path) # Load config automatically\n",
        "          print(\"Loaded final model successfully.\")\n",
        "     except Exception as e_load_final:\n",
        "          print(f\"ERROR loading final model: {e_load_final}\")\n",
        "          traceback.print_exc(); eval_model = None\n",
        "# Option 3: Load the pruned structure (before fine-tuning, less common for eval)\n",
        "elif 'output_dir' in locals() and os.path.isdir(output_dir) and os.path.exists(os.path.join(output_dir, \"model.safetensors\")):\n",
        "    # Check if the base output directory contains a save_pretrained output (likely the pruned structure)\n",
        "    pruned_structure_path = output_dir\n",
        "    print(f\"Loading pruned structure (before fine-tuning) from: {pruned_structure_path}\")\n",
        "    eval_model_source = pruned_structure_path + \" (pruned only)\"\n",
        "    try:\n",
        "         if 'image_processor' not in locals() or image_processor is None:\n",
        "              image_processor = AutoImageProcessor.from_pretrained(pruned_structure_path)\n",
        "         eval_model = AutoModelForObjectDetection.from_pretrained(pruned_structure_path)\n",
        "         print(\"Loaded pruned (pre-FT) model successfully.\")\n",
        "    except Exception as e_load_pruned:\n",
        "         print(f\"ERROR loading pruned model structure: {e_load_pruned}\")\n",
        "         traceback.print_exc(); eval_model = None\n",
        "else:\n",
        "     print(\"No fine-tuned or pruned model available in memory or standard save locations.\")\n",
        "     eval_model_source = \"None\"\n",
        "\n",
        "# --- Proceed with Evaluation if Model and GT are available ---\n",
        "map_after = -1.0 # Initialize mAP results\n",
        "map_50_after = -1.0\n",
        "\n",
        "if eval_model is None:\n",
        "    print(f\"Model not available for evaluation (Source attempted: {eval_model_source}).\")\n",
        "# Check if coco_gt object was successfully loaded in Cell 7\n",
        "elif coco_gt is None:\n",
        "    print(\"COCO ground truth annotations not loaded (coco_gt is None). Cannot calculate COCO mAP.\")\n",
        "    # Even if GT is missing, we might want to run inference loop just to check for errors\n",
        "    # Set a flag or handle this case based on desired behavior\n",
        "else:\n",
        "    print(f\"Preparing for mAP evaluation using model from: {eval_model_source}\")\n",
        "    # Ensure model is on the correct device and in eval mode\n",
        "    eval_model.to(device)\n",
        "    eval_model.eval()\n",
        "\n",
        "    # --- Prepare DataLoader for COCO evaluation dataset ---\n",
        "    # This requires a dataset that yields (image, target_dict_with_image_id)\n",
        "    # We need to load images based on the image IDs present in coco_gt\n",
        "\n",
        "    # Get all image IDs present in the ground truth annotations\n",
        "    img_ids = coco_gt.getImgIds()\n",
        "    print(f\"Found {len(img_ids)} image IDs in COCO ground truth.\")\n",
        "\n",
        "    # Create a simple dataset that loads images based on COCO image IDs\n",
        "    class CocoEvalDataset(Dataset):\n",
        "        def __init__(self, coco_gt_obj, img_dir, transform=None):\n",
        "            self.coco = coco_gt_obj\n",
        "            self.img_ids = coco_gt_obj.getImgIds()\n",
        "            self.img_dir = img_dir\n",
        "            self.transform = transform # You might apply basic transforms if needed, but processor handles most\n",
        "            self.img_info = coco_gt_obj.loadImgs(self.img_ids)\n",
        "            # Create a mapping from image_id to file path (assuming filename is stored)\n",
        "            self.id_to_path = {info['id']: os.path.join(img_dir, info['file_name']) for info in self.img_info if 'file_name' in info}\n",
        "            print(f\"  Mapped {len(self.id_to_path)} image IDs to file paths.\")\n",
        "            missing_files = [img_id for img_id in self.img_ids if img_id not in self.id_to_path or not os.path.exists(self.id_to_path[img_id])]\n",
        "            if missing_files:\n",
        "                print(f\"  WARNING: Could not find image files for {len(missing_files)} image IDs (e.g., {missing_files[:5]})\")\n",
        "\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.img_ids)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img_id = self.img_ids[idx]\n",
        "            if img_id not in self.id_to_path:\n",
        "                print(f\"Skipping img_id {img_id} - path not found.\")\n",
        "                return None # Skip if path wasn't determined\n",
        "\n",
        "            img_path = self.id_to_path[img_id]\n",
        "            if not os.path.exists(img_path):\n",
        "                print(f\"Skipping img_id {img_id} - file not found at {img_path}\")\n",
        "                return None # Skip if file doesn't exist\n",
        "\n",
        "            try:\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                # Get target dictionary just for image_id (processor needs original image size)\n",
        "                # The actual annotations come from coco_gt later\n",
        "                target = {\"image_id\": img_id, \"width\": image.width, \"height\": image.height}\n",
        "\n",
        "                # Apply transforms if any (usually processor handles this)\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "\n",
        "                return image, target # Return PIL image and target dict\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading/processing image {img_path} for id {img_id}: {e}\")\n",
        "                return None\n",
        "\n",
        "    # Create the evaluation dataset instance\n",
        "    # Pass the base 'images_dir' from Cell 1\n",
        "    eval_dataset = CocoEvalDataset(coco_gt_obj=coco_gt, img_dir=images_dir)\n",
        "\n",
        "    # Define a collate function for evaluation (handles None)\n",
        "    def eval_collate_fn(batch):\n",
        "        batch = [item for item in batch if item is not None]\n",
        "        if not batch:\n",
        "            return None\n",
        "        # Default collator might work if dataset returns dicts, but here we return tuples\n",
        "        # We process images individually in the loop anyway for simplicity with post_process\n",
        "        # If batch_size > 1, more complex collation needed. Assume bs=1 for now.\n",
        "        assert len(batch) == 1, \"Evaluation loop assumes batch size 1 for now\"\n",
        "        return batch[0] # Return the single (image, target) tuple\n",
        "\n",
        "    # Create DataLoader\n",
        "    eval_batch_size = 1 # Recommended for simplicity with post_process_object_detection\n",
        "    eval_loader = DataLoader(eval_dataset,\n",
        "                             batch_size=eval_batch_size,\n",
        "                             shuffle=False,\n",
        "                             num_workers=0, # Use 0 for simplicity, especially if issues arise\n",
        "                             collate_fn=eval_collate_fn)\n",
        "    print(f\"Created evaluation DataLoader with batch size {eval_batch_size}.\")\n",
        "\n",
        "    # --- Run Inference and Collect Results ---\n",
        "    coco_results_after = []\n",
        "    processed_eval_count = 0\n",
        "    print(\"\\nRunning inference for evaluation...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data in tqdm(eval_loader, desc=\"Evaluating mAP\"):\n",
        "            if batch_data is None: continue # Skip bad batches\n",
        "\n",
        "            image, target = batch_data # Unpack tuple for bs=1\n",
        "            image_id = target['image_id'] # Get original image ID from COCO GT info\n",
        "\n",
        "            try:\n",
        "                # Preprocess image using the loaded processor\n",
        "                # Important: Processor needs original image size for post-processing\n",
        "                original_size = (target['height'], target['width'])\n",
        "                inputs = image_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "                # Model inference\n",
        "                outputs = eval_model(**inputs)\n",
        "\n",
        "                # Post-process results\n",
        "                # Use the original image size, not the potentially resized/padded tensor size\n",
        "                target_sizes = torch.tensor([original_size], device=device)\n",
        "                results = image_processor.post_process_object_detection(\n",
        "                    outputs,\n",
        "                    target_sizes=target_sizes,\n",
        "                    threshold=0.1 # Confidence threshold for detections\n",
        "                )[0] # Get results for the first (only) image in the batch\n",
        "\n",
        "                # Format results for COCOeval\n",
        "                boxes = results[\"boxes\"].cpu().tolist()\n",
        "                scores = results[\"scores\"].cpu().tolist()\n",
        "                labels = results[\"labels\"].cpu().tolist()\n",
        "\n",
        "                for box, score, label in zip(boxes, scores, labels):\n",
        "                    # Box is xyxy format from post_process\n",
        "                    x_min, y_min, x_max, y_max = box\n",
        "                    # Convert to COCO's xywh format\n",
        "                    coco_bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
        "                    coco_results_after.append({\n",
        "                        \"image_id\": image_id,\n",
        "                        # Use the raw label ID output by the model's head\n",
        "                        # Ensure this aligns with the category IDs in your coco_gt object\n",
        "                        \"category_id\": label+1,\n",
        "                        \"bbox\": coco_bbox,\n",
        "                        \"score\": score,\n",
        "                    })\n",
        "                processed_eval_count += 1\n",
        "\n",
        "            except Exception as e_infer:\n",
        "                 print(f\"\\nError during inference/postprocessing for image_id {image_id}: {e_infer}\")\n",
        "                 traceback.print_exc()\n",
        "                 continue # Skip this image\n",
        "\n",
        "    print(f\"\\nProcessed {processed_eval_count} images for evaluation.\")\n",
        "\n",
        "    # --- Run COCO Evaluation ---\n",
        "    if not coco_results_after:\n",
        "        print(\"No evaluation results generated to run COCO eval.\")\n",
        "    else:\n",
        "        print(\"Running COCO evaluation API...\")\n",
        "        try:\n",
        "            # Load results into COCO API\n",
        "            coco_dt = coco_gt.loadRes(coco_results_after)\n",
        "\n",
        "            # Run evaluation\n",
        "            coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "            # Configure evaluation parameters if needed (e.g., specific IoU thresholds, area ranges)\n",
        "            # coco_eval.params.iouThrs = np.linspace(.5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n",
        "            # coco_eval.params.areaRng = [[0 ** 2, 1e5 ** 2], [0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
        "            # coco_eval.params.areaRngLbl = ['all', 'small', 'medium', 'large']\n",
        "\n",
        "            coco_eval.evaluate()    # Compute per-image evaluations\n",
        "            coco_eval.accumulate()  # Accumulate results over all images\n",
        "            coco_eval.summarize()   # Print summary metrics\n",
        "\n",
        "            # Extract specific metrics\n",
        "            map_after = coco_eval.stats[0]  # mAP @ IoU=0.50:0.95 area=all maxDets=100\n",
        "            map_50_after = coco_eval.stats[1] # mAP @ IoU=0.50 area=all maxDets=100\n",
        "\n",
        "            print(f\"\\n--- mAP Results ---\")\n",
        "            print(f\"mAP @ IoU=0.50:0.95 (AP): {map_after:.4f}\")\n",
        "            print(f\"mAP @ IoU=0.50 (AP50):     {map_50_after:.4f}\")\n",
        "\n",
        "        except Exception as e_eval:\n",
        "            print(f\"ERROR during COCO evaluation API execution: {e_eval}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "# Cleanup evaluation-specific objects\n",
        "print(\"\\nCleaning up evaluation objects...\")\n",
        "deleted_vars = []\n",
        "if 'eval_model' in locals() and eval_model is not None:\n",
        "    # If eval_model refers to model_pruned, avoid deleting it if needed later\n",
        "    if 'model_pruned' not in locals() or eval_model is not model_pruned:\n",
        "        del eval_model\n",
        "        deleted_vars.append('eval_model')\n",
        "    else:\n",
        "        print(\"  Skipping deletion of eval_model (same as model_pruned).\")\n",
        "if 'eval_loader' in locals() and eval_loader is not None:\n",
        "    del eval_loader\n",
        "    deleted_vars.append('eval_loader')\n",
        "if 'eval_dataset' in locals() and eval_dataset is not None:\n",
        "    del eval_dataset\n",
        "    deleted_vars.append('eval_dataset')\n",
        "# coco_gt might be needed by Cell 10's check, so maybe don't delete here\n",
        "# if 'coco_gt' in locals() and coco_gt is not None:\n",
        "#    del coco_gt\n",
        "#    deleted_vars.append('coco_gt')\n",
        "print(f\"Deleted variables: {deleted_vars}\")\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tWwwm6dfQFhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cefc165-ded2-493a-e6eb-5f4fc61e0738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating mAP After Fine-tuning (Requires COCO annotations) ---\n",
            "\n",
            "Evaluating the model currently in memory (fine-tuned).\n",
            "COCO ground truth annotations not loaded (coco_gt is None). Cannot calculate COCO mAP.\n",
            "\n",
            "Cleaning up evaluation objects...\n",
            "  Skipping deletion of eval_model (same as model_pruned).\n",
            "Deleted variables: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 10: Final Summary\n",
        "# =============================================================================\n",
        "print(\"\\n--- Final Summary ---\")\n",
        "print(f\"Pruning Ratio Target (per layer): {GLOBAL_PRUNING_RATIO:.2f}\")\n",
        "\n",
        "# --- Use calculated metrics if available ---\n",
        "print(f\"\\nParameters:\")\n",
        "if 'original_params' in locals() and original_params > 0 : print(f\"  Original (Post Head Resize): {original_params:,}\")\n",
        "else: print(\"  Original: (Not calculated/available)\")\n",
        "if 'pruned_params' in locals() and pruned_params >= 0 : print(f\"  Pruned (Torch-Pruning):      {pruned_params:,}\")\n",
        "else: print(\"  Pruned:   (Not calculated/available)\")\n",
        "\n",
        "if ('original_params' in locals() and original_params > 0 and\n",
        "    'pruned_params' in locals() and pruned_params >= 0):\n",
        "     reduction = (original_params - pruned_params) / original_params * 100\n",
        "     print(f\"  Reduction:                   {reduction:.2f}%\")\n",
        "\n",
        "print(f\"\\nGFLOPs:\")\n",
        "if 'original_gflops' in locals() and original_gflops > 0: print(f\"  Original: {original_gflops:.2f}\")\n",
        "else: print(\"  Original: (Not calculated/available)\")\n",
        "if 'pruned_gflops' in locals() and pruned_gflops >= 0 : print(f\"  Pruned:   {pruned_gflops:.2f}\")\n",
        "else: print(\"  Pruned:   (Not calculated/available)\")\n",
        "\n",
        "if ('original_gflops' in locals() and original_gflops > 0 and\n",
        "    'pruned_gflops' in locals() and pruned_gflops >= 0):\n",
        "     gflops_reduction = (original_gflops - pruned_gflops) / original_gflops * 100\n",
        "     print(f\"  Reduction: {gflops_reduction:.2f}%\")\n",
        "\n",
        "# --- Report Saved File Locations ---\n",
        "print(f\"\\nSaved Files in: {output_dir}\")\n",
        "pruned_structure_dir = os.path.join(output_dir) # save_pretrained saves to the dir\n",
        "final_model_dir = os.path.join(output_dir, \"final_model\") # Default save_pretrained dir\n",
        "\n",
        "if os.path.isdir(pruned_structure_dir) and os.path.exists(os.path.join(pruned_structure_dir, \"model.safetensors\")): # Check if save_pretrained likely worked\n",
        "    print(f\"  Pruned Structure saved via save_pretrained in: {pruned_structure_dir}\")\n",
        "elif 'pruned_model_saved_path' in locals() and pruned_model_saved_path and os.path.exists(pruned_model_saved_path): # Fallback check for direct state dict save\n",
        "    print(f\"  Pruned Structure state_dict: {os.path.basename(pruned_model_saved_path)} ({os.path.getsize(pruned_model_saved_path)/(1024*1024):.2f} MB)\")\n",
        "else:\n",
        "    print(\"  Pruned Structure: Not saved or path not found.\")\n",
        "\n",
        "if DO_FINE_TUNING and os.path.isdir(final_model_dir) and os.path.exists(os.path.join(final_model_dir, \"model.safetensors\")):\n",
        "     print(f\"  Final Fine-tuned saved via save_pretrained in: {final_model_dir}\")\n",
        "elif DO_FINE_TUNING:\n",
        "     print(f\"  Final Fine-tuned: Not saved or path not found.\")\n",
        "else:\n",
        "     print(f\"  Final Fine-tuned: Fine-tuning skipped.\")\n",
        "\n",
        "# --- Report mAP ---\n",
        "print(f\"\\nmAP Evaluation Results:\")\n",
        "if 'map_after' in locals() and map_after >= 0: # Check if eval ran and produced valid result\n",
        "    print(f\"  mAP @ IoU=0.50:0.95 (AP): {map_after:.4f}\")\n",
        "    print(f\"  mAP @ IoU=0.50 (AP50):     {map_50_after:.4f}\")\n",
        "else:\n",
        "    print(\"  mAP evaluation not performed or failed.\")\n",
        "    if not os.path.exists(coco_annotation_file): print(\"  (COCO annotation file was missing)\")\n",
        "    elif coco_gt is None: print(\"  (COCO GT object failed to load)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- End of Notebook ---\")"
      ],
      "metadata": {
        "id": "MYCzU4HlQILE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79051c08-7f56-4b45-c71c-6cb3e7f16600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Summary ---\n",
            "Pruning Ratio Target (per layer): 0.10\n",
            "\n",
            "Parameters:\n",
            "  Original (Post Head Resize): 39,878,026\n",
            "  Pruned (Torch-Pruning):      36,535,818\n",
            "  Reduction:                   8.38%\n",
            "\n",
            "GFLOPs:\n",
            "  Original: 204.87\n",
            "  Pruned:   191.19\n",
            "  Reduction: 6.68%\n",
            "\n",
            "Saved Files in: /content/drive/MyDrive/kitti_torch_pruning_output_v1\n",
            "  Pruned Structure saved via save_pretrained in: /content/drive/MyDrive/kitti_torch_pruning_output_v1\n",
            "  Final Fine-tuned saved via save_pretrained in: /content/drive/MyDrive/kitti_torch_pruning_output_v1/final_model\n",
            "\n",
            "mAP Evaluation Results:\n",
            "  mAP evaluation not performed or failed.\n",
            "  (COCO annotation file was missing)\n",
            "\n",
            "--- End of Notebook ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shashank's changes"
      ],
      "metadata": {
        "id": "OxR1TcpZsxK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 1: Setup Environment, Mount Drive, Define Paths (MODIFIED)\n",
        "# =============================================================================\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "import copy\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "import traceback\n",
        "import time # <--- Added for inference time measurement\n",
        "\n",
        "print(\"--- Environment Setup ---\")\n",
        "\n",
        "# Set CUDA Launch Blocking (Optional but Recommended for Debugging GPU errors)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "print(\"CUDA_LAUNCH_BLOCKING set to 1.\")\n",
        "\n",
        "# Check if in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Install necessary libraries\n",
        "print(\"Installing required libraries...\")\n",
        "# Note: Installing tqdm separately as sometimes the notebook version conflicts\n",
        "!pip install -q --upgrade transformers datasets accelerate evaluate timm Pillow safetensors pycocotools thop torch-pruning tqdm\n",
        "print(\"Libraries installation attempt finished.\")\n",
        "\n",
        "# Import key libraries (do this after install)\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import numpy as np\n",
        "    from transformers import (\n",
        "        AutoImageProcessor, AutoModelForObjectDetection, AutoConfig\n",
        "    )\n",
        "    import torchvision\n",
        "    from tqdm.notebook import tqdm as tqdm_notebook # For notebook progress bars\n",
        "    from tqdm import tqdm as tqdm_cli # For regular loops if needed\n",
        "    from PIL import Image\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import torch_pruning as tp\n",
        "    from thop import profile\n",
        "    from pycocotools.coco import COCO\n",
        "    from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "    print(\"Core libraries imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"ERROR: Failed to import libraries: {e}\")\n",
        "    print(\"Please check the pip install logs above.\")\n",
        "    raise e\n",
        "\n",
        "# Mount Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive mounted.\")\n",
        "        except Exception as e_mount:\n",
        "            print(f\"Error mounting drive: {e_mount}\")\n",
        "            raise e_mount\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "    base_drive_path = \"/content/drive/MyDrive/\"\n",
        "else:\n",
        "    base_drive_path = \"./\" # Adjust if running locally\n",
        "\n",
        "# --- Configuration (MODIFIED) ---\n",
        "print(\"\\n--- Configuration ---\")\n",
        "# !!! Important: Adjust these paths to your actual Drive locations !!!\n",
        "model_dir = os.path.join(base_drive_path, \"/content/drive/MyDrive/deformable-detr-finetuned-kitti-round2\") # DIR where fine-tuned model was saved\n",
        "dataset_base_dir = os.path.join(base_drive_path, \"kitti_subset\") # Base DIR for KITTI subset\n",
        "images_dir = os.path.join(dataset_base_dir, \"images\") # Specific image folder\n",
        "# --- Make sure this points to your COCO format VALIDATION json ---\n",
        "coco_annotation_file = os.path.join(dataset_base_dir, \"annotations\", \"instances_val2017.json\") # <== COCO format annotations for mAP\n",
        "# --- Output directory ---\n",
        "output_dir = os.path.join(base_drive_path, \"kitti_torch_pruning_results_v2\") # Output directory for this run\n",
        "\n",
        "# Pruning Params\n",
        "TARGET_PRUNING_RATIOS = [0.1, 0.2, 0.3, 0.4, 0.5] # Ratios to test (relative to original)\n",
        "\n",
        "# Dataset Params (ensure these match your KITTI subset)\n",
        "NUM_KITTI_CLASSES = 3 # Car, Pedestrian, Cyclist\n",
        "NUM_OUTPUTS_REQUIRED = NUM_KITTI_CLASSES  # Add 1 for the background/no-object class\n",
        "\n",
        "# Evaluation params\n",
        "EVAL_BATCH_SIZE = 1 # Adjust based on GPU memory for evaluation inference speed\n",
        "CONFIDENCE_THRESHOLD = 0.1 # Threshold for keeping detections during post-processing\n",
        "\n",
        "# --- End Configuration ---\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Model directory: {model_dir}\")\n",
        "print(f\"Dataset directory: {dataset_base_dir}\")\n",
        "print(f\"COCO Annotation file: {coco_annotation_file}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Target Pruning Ratios: {TARGET_PRUNING_RATIOS}\")\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: CUDA not available, running on CPU. This will be very slow.\")\n",
        "\n",
        "# Helper Functions (from original Cell 1)\n",
        "def get_module_by_name(model: nn.Module, name: str) -> nn.Module:\n",
        "    names = name.split('.')\n",
        "    obj = model\n",
        "    for n in names:\n",
        "        if hasattr(obj, n): obj = getattr(obj, n)\n",
        "        else:\n",
        "            try: idx = int(n); obj = obj[idx]\n",
        "            except (ValueError, IndexError, TypeError): raise AttributeError(f\"Module part '{n}' not found in name '{name}'. Parent type: {type(obj)}\")\n",
        "    return obj\n",
        "\n",
        "def set_module_by_name(model: nn.Module, name: str, new_module: nn.Module):\n",
        "    names = name.split('.')\n",
        "    parent_name = '.'.join(names[:-1])\n",
        "    leaf_name = names[-1]\n",
        "    try: parent_module = model.get_submodule(parent_name) if parent_name else model\n",
        "    except AttributeError: parent_module = get_module_by_name(model, parent_name) # Fallback\n",
        "    if hasattr(parent_module, leaf_name): setattr(parent_module, leaf_name, new_module)\n",
        "    else:\n",
        "        try: idx = int(leaf_name); parent_module[idx] = new_module\n",
        "        except (ValueError, IndexError, TypeError): raise AttributeError(f\"Could not set attribute or index '{leaf_name}' in parent module '{parent_name}' of type {type(parent_module)}\")\n",
        "\n",
        "print(\"\\nSetup Complete.\")"
      ],
      "metadata": {
        "id": "FBPt_-RcvQH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ef0766-b231-47a3-af63-463a739e0691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Environment Setup ---\n",
            "CUDA_LAUNCH_BLOCKING set to 1.\n",
            "Installing required libraries...\n",
            "Libraries installation attempt finished.\n",
            "Core libraries imported successfully.\n",
            "Google Drive already mounted.\n",
            "\n",
            "--- Configuration ---\n",
            "Model directory: /content/drive/MyDrive/deformable-detr-finetuned-kitti-round2\n",
            "Dataset directory: /content/drive/MyDrive/kitti_subset\n",
            "COCO Annotation file: /content/drive/MyDrive/kitti_subset/annotations/instances_val2017.json\n",
            "Output directory: /content/drive/MyDrive/kitti_torch_pruning_results_v2\n",
            "Target Pruning Ratios: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
            "Using device: cuda\n",
            "\n",
            "Setup Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Load & Prepare Base Model (Revised for 3 Classes & Correct Loading)\n",
        "# =============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoConfig, AutoModelForObjectDetection, AutoImageProcessor\n",
        "import traceback\n",
        "import gc\n",
        "\n",
        "# --- Import Helper Functions from Cell 1 ---\n",
        "assert 'set_module_by_name' in globals(), \"Helper function set_module_by_name not defined (run Cell 1)\"\n",
        "assert 'NUM_OUTPUTS_REQUIRED' in locals() and NUM_OUTPUTS_REQUIRED == 3, \"NUM_OUTPUTS_REQUIRED should be set to 3 in Cell 1\"\n",
        "assert 'model_dir' in locals(), \"model_dir not defined in Cell 1\"\n",
        "assert 'device' in locals(), \"device not defined in Cell 1\"\n",
        "\n",
        "print(\"\\n--- Loading & Preparing Base Model (Targeting 3 Classes) ---\")\n",
        "\n",
        "prepared_base_model = None\n",
        "image_processor = None\n",
        "config = None\n",
        "# Default values, might be overridden by loaded config\n",
        "hidden_dim = 256\n",
        "decoder_layers = 6\n",
        "num_queries = 300\n",
        "\n",
        "# --- Function to Replace FrozenBN (Essential for pruning/fine-tuning later) ---\n",
        "def replace_frozen_bn(model_to_modify):\n",
        "    FROZEN_BN_TYPE = None\n",
        "    try:\n",
        "        # Try importing the specific FrozenBN class\n",
        "        from transformers.models.deformable_detr.modeling_deformable_detr import DeformableDetrFrozenBatchNorm2d\n",
        "        FROZEN_BN_TYPE = DeformableDetrFrozenBatchNorm2d\n",
        "        print(\"  Found DeformableDetrFrozenBatchNorm2d class.\")\n",
        "    except ImportError:\n",
        "        print(\"  WARNING: DeformableDetrFrozenBatchNorm2d class not found. Cannot replace BN layers.\")\n",
        "        return model_to_modify, 0 # Return unmodified model if class not found\n",
        "\n",
        "    if not FROZEN_BN_TYPE:\n",
        "        return model_to_modify, 0\n",
        "\n",
        "    replacement_count = 0\n",
        "    error_count = 0\n",
        "    module_list = list(model_to_modify.named_modules())\n",
        "    modules_to_replace = []\n",
        "    print(f\"  Checking {len(module_list)} modules for FrozenBN replacement...\")\n",
        "\n",
        "    for name, module in module_list:\n",
        "        if isinstance(module, FROZEN_BN_TYPE):\n",
        "            modules_to_replace.append(name)\n",
        "\n",
        "    if not modules_to_replace:\n",
        "        print(\"  No FrozenBN layers found to replace.\")\n",
        "        return model_to_modify, 0\n",
        "\n",
        "    print(f\"  Found {len(modules_to_replace)} FrozenBN layers to replace.\")\n",
        "    # Perform replacement on CPU for safety, then move back\n",
        "    original_device = next(iter(model_to_modify.parameters()), torch.tensor(0)).device # Get device robustly\n",
        "    model_to_modify.cpu()\n",
        "    print(f\"    Moved model to CPU for BN replacement.\")\n",
        "\n",
        "    from tqdm import tqdm as tqdm_cli # Use standard tqdm for this internal loop\n",
        "    for name in tqdm_cli(modules_to_replace, desc=\"  Replacing FrozenBN\", leave=False):\n",
        "        try:\n",
        "            module = model_to_modify.get_submodule(name) # Use get_submodule\n",
        "            if not isinstance(module, FROZEN_BN_TYPE): continue # Should not happen now\n",
        "\n",
        "            # Check if weight exists to determine num_features\n",
        "            if hasattr(module, 'weight') and module.weight is not None:\n",
        "                num_features = module.weight.shape[0]\n",
        "            else:\n",
        "                # This might happen if the layer was somehow incomplete\n",
        "                print(f\"    WARNING: Skipping {name} - no weight attribute found to determine num_features.\")\n",
        "                error_count += 1\n",
        "                continue\n",
        "\n",
        "            # Create standard BN layer on CPU\n",
        "            new_bn = nn.BatchNorm2d(num_features, eps=1e-5, affine=True, track_running_stats=True) # Created on CPU\n",
        "\n",
        "            # Copy parameters from FrozenBN to standard BN *before* replacing\n",
        "            if hasattr(module, 'weight') and module.weight is not None:\n",
        "                 new_bn.weight.data.copy_(module.weight.data)\n",
        "            if hasattr(module, 'bias') and module.bias is not None:\n",
        "                 new_bn.bias.data.copy_(module.bias.data)\n",
        "            if hasattr(module, 'running_mean') and module.running_mean is not None:\n",
        "                 new_bn.running_mean.data.copy_(module.running_mean.data)\n",
        "            if hasattr(module, 'running_var') and module.running_var is not None:\n",
        "                 new_bn.running_var.data.copy_(module.running_var.data)\n",
        "            # num_batches_tracked might not always exist or be relevant, copy if present\n",
        "            if hasattr(module, 'num_batches_tracked') and module.num_batches_tracked is not None and hasattr(new_bn, 'num_batches_tracked'):\n",
        "                 new_bn.num_batches_tracked.data.copy_(module.num_batches_tracked.data)\n",
        "\n",
        "            # Replace the module using the helper function\n",
        "            set_module_by_name(model_to_modify, name, new_bn)\n",
        "            replacement_count += 1\n",
        "        except Exception as e_replace:\n",
        "            print(f\"    ERROR replacing {name}: {e_replace}\")\n",
        "            traceback.print_exc()\n",
        "            error_count += 1\n",
        "\n",
        "    # Move back to original device\n",
        "    model_to_modify.to(original_device)\n",
        "    print(f\"    Moved model back to {original_device}.\")\n",
        "    print(f\"  Finished BN replacement. Replaced: {replacement_count}, Errors: {error_count}\")\n",
        "    if error_count > 0:\n",
        "        print(\"  WARNING: Errors occurred during BN replacement. This might affect performance.\")\n",
        "    return model_to_modify, replacement_count\n",
        "# --- End Replace Function ---\n",
        "\n",
        "try:\n",
        "    # 1. Load processor\n",
        "    image_processor = AutoImageProcessor.from_pretrained(model_dir)\n",
        "    print(f\"Image processor loaded from {model_dir}\")\n",
        "\n",
        "    # 2. Load config and IMMEDIATELY ensure it has the correct number of labels (3)\n",
        "    print(f\"Loading config from {model_dir} and ensuring num_labels is {NUM_OUTPUTS_REQUIRED}...\")\n",
        "    # Define the correct 3-class label mapping expected by the KITTI fine-tuned model\n",
        "    # IMPORTANT: Verify this matches the classes and order used during YOUR fine-tuning\n",
        "    id2label = {0: 'Car', 1: 'Pedestrian', 2: 'Cyclist'}\n",
        "    label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        model_dir,\n",
        "        num_labels=NUM_OUTPUTS_REQUIRED, # Explicitly set to 3\n",
        "        id2label=id2label,               # Set correct mapping\n",
        "        label2id=label2id                # Set correct mapping\n",
        "    )\n",
        "\n",
        "    # Update other parameters if needed (usually loaded correctly from config.json)\n",
        "    num_queries = getattr(config, 'num_queries', 300)\n",
        "    hidden_dim = getattr(config, 'd_model', 256)\n",
        "    decoder_layers = getattr(config, 'decoder_layers', 6)\n",
        "    print(f\"Using config: num_labels={config.num_labels}, id2label={config.id2label}\")\n",
        "    print(f\"              num_queries={num_queries}, hidden_dim={hidden_dim}, decoder_layers={decoder_layers}\")\n",
        "\n",
        "\n",
        "    # 3. Load model structure and weights using the CORRECTED config\n",
        "    #    Use ignore_mismatched_sizes=False first. It should work now.\n",
        "    print(f\"Loading model weights from {model_dir}...\")\n",
        "    _model = AutoModelForObjectDetection.from_pretrained(\n",
        "        model_dir,\n",
        "        config=config,                  # Pass the corrected config\n",
        "        ignore_mismatched_sizes=False   # <<< TRY THIS FIRST! Should match now.\n",
        "    )\n",
        "    print(\"Model weights loaded.\")\n",
        "     # If the above fails with size mismatch, something is still wrong with the checkpoint file\n",
        "     # or the assumed id2label mapping. Only use ignore_mismatched_sizes=True as a last resort\n",
        "     # and investigate why the checkpoint weights don't match the 3-label config.\n",
        "\n",
        "    # 4. Verify Head Size (Optional but recommended sanity check)\n",
        "    print(\"Verifying loaded model head size...\")\n",
        "    try:\n",
        "        final_class_layer = None\n",
        "        # Add robust checks to find the last linear layer in the classification head\n",
        "        if hasattr(_model, 'class_embed'):\n",
        "            if isinstance(_model.class_embed, nn.ModuleList) and len(_model.class_embed) > 0:\n",
        "                 last_mod_in_list = _model.class_embed[-1]\n",
        "                 if isinstance(last_mod_in_list, nn.Linear): final_class_layer = last_mod_in_list\n",
        "                 elif hasattr(last_mod_in_list, 'layers') and isinstance(last_mod_in_list.layers, nn.Sequential):\n",
        "                     if len(last_mod_in_list.layers) > 0 and isinstance(last_mod_in_list.layers[-1], nn.Linear): final_class_layer = last_mod_in_list.layers[-1]\n",
        "            elif isinstance(_model.class_embed, nn.Linear): final_class_layer = _model.class_embed\n",
        "            # Add more checks if your model structure is different\n",
        "\n",
        "        if final_class_layer is not None:\n",
        "            current_cls_outputs = final_class_layer.out_features\n",
        "            print(f\"  Detected {current_cls_outputs} outputs in the final classification layer.\")\n",
        "            if current_cls_outputs != NUM_OUTPUTS_REQUIRED:\n",
        "                 # This should NOT happen if ignore_mismatched_sizes=False worked\n",
        "                 print(f\"  ERROR: Loaded model head size ({current_cls_outputs}) does not match required ({NUM_OUTPUTS_REQUIRED})!\")\n",
        "                 raise ValueError(\"Head size mismatch after loading with corrected config.\")\n",
        "            else:\n",
        "                 print(f\"  Head size matches required size ({NUM_OUTPUTS_REQUIRED}). Fine-tuned weights presumed loaded.\")\n",
        "        else:\n",
        "            print(\"  WARNING: Could not reliably determine output size of the classification head.\")\n",
        "\n",
        "    except Exception as e_head_check:\n",
        "        print(f\"  Error during head size verification: {e_head_check}\")\n",
        "        raise e_head_check\n",
        "\n",
        "    # 5. Replace FrozenBatchNorm2d layers (necessary for pruning)\n",
        "    print(\"\\nReplacing FrozenBatchNorm2d layers with standard BatchNorm2d...\")\n",
        "    _model, _ = replace_frozen_bn(_model) # Use the function defined at the start of this cell\n",
        "\n",
        "    # 6. Move final prepared model to target device\n",
        "    print(f\"\\nMoving final prepared base model to: {device}\")\n",
        "    _model.to(device)\n",
        "    _model.eval()\n",
        "    prepared_base_model = _model # Assign to the final variable name\n",
        "    print(\"Prepared base model is ready on device.\")\n",
        "\n",
        "    # 7. Calculate and print parameters for the prepared model\n",
        "    base_model_params = sum(p.numel() for p in prepared_base_model.parameters() if p.requires_grad)\n",
        "    print(f\"Prepared Base Model Parameters (trainable): {base_model_params:,}\")\n",
        "\n",
        "except Exception as e_load_prep:\n",
        "    print(f\"!!! ERROR during model loading/preparation: {e_load_prep} !!!\")\n",
        "    traceback.print_exc()\n",
        "    prepared_base_model = None # Ensure it's None on error\n",
        "    raise e_load_prep # Re-raise the exception to stop execution\n",
        "\n",
        "# Cleanup intermediate model variable if it exists and differs\n",
        "if '_model' in locals() and prepared_base_model is not _model:\n",
        "    del _model\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n--- Base Model Preparation Complete ---\")"
      ],
      "metadata": {
        "id": "RAL7e2_3s7Ho",
        "outputId": "afb9f0f6-0435-4488-ec85-982ed49dda92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading & Preparing Base Model (Targeting 3 Classes) ---\n",
            "Image processor loaded from /content/drive/MyDrive/deformable-detr-finetuned-kitti-round2\n",
            "Loading config from /content/drive/MyDrive/deformable-detr-finetuned-kitti-round2 and ensuring num_labels is 3...\n",
            "Using config: num_labels=3, id2label={0: 'Car', 1: 'Pedestrian', 2: 'Cyclist'}\n",
            "              num_queries=300, hidden_dim=256, decoder_layers=6\n",
            "Loading model weights from /content/drive/MyDrive/deformable-detr-finetuned-kitti-round2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded.\n",
            "Verifying loaded model head size...\n",
            "  Detected 3 outputs in the final classification layer.\n",
            "  Head size matches required size (3). Fine-tuned weights presumed loaded.\n",
            "\n",
            "Replacing FrozenBatchNorm2d layers with standard BatchNorm2d...\n",
            "  Found DeformableDetrFrozenBatchNorm2d class.\n",
            "  Checking 425 modules for FrozenBN replacement...\n",
            "  Found 53 FrozenBN layers to replace.\n",
            "    Moved model to CPU for BN replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Moved model back to cpu.\n",
            "  Finished BN replacement. Replaced: 53, Errors: 0\n",
            "\n",
            "Moving final prepared base model to: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared base model is ready on device.\n",
            "Prepared Base Model Parameters (trainable): 39,877,769\n",
            "\n",
            "--- Base Model Preparation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 3: Load COCO GT & Define Eval Dataset/Loader (MODIFIED)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Loading COCO GT and Preparing Evaluation Dataloader ---\")\n",
        "\n",
        "coco_gt = None\n",
        "eval_loader = None\n",
        "\n",
        "# --- Load COCO GT data ---\n",
        "if not os.path.exists(coco_annotation_file):\n",
        "    print(f\"ERROR: COCO annotation file for evaluation not found at: {coco_annotation_file}\")\n",
        "    print(\"Cannot calculate mAP.\")\n",
        "else:\n",
        "    try:\n",
        "        print(f\"Loading COCO ground truth for mAP evaluation from: {coco_annotation_file}\")\n",
        "        coco_gt = COCO(coco_annotation_file)\n",
        "        print(\"COCO GT loaded successfully.\")\n",
        "    except Exception as e_coco:\n",
        "        print(f\"ERROR loading COCO annotations file '{coco_annotation_file}': {e_coco}\")\n",
        "        traceback.print_exc()\n",
        "        coco_gt = None\n",
        "\n",
        "# --- Define CocoEvalDataset ---\n",
        "class CocoEvalDataset(Dataset):\n",
        "    def __init__(self, coco_gt_obj, img_dir):\n",
        "        self.coco = coco_gt_obj\n",
        "        self.img_ids = coco_gt_obj.getImgIds()\n",
        "        self.img_dir = img_dir\n",
        "        self.img_info = coco_gt_obj.loadImgs(self.img_ids)\n",
        "        # Create a mapping from image_id to file path\n",
        "        self.id_to_path = {info['id']: os.path.join(img_dir, info['file_name'])\n",
        "                           for info in self.img_info if 'file_name' in info}\n",
        "        print(f\"  CocoEvalDataset: Mapped {len(self.id_to_path)} image IDs to file paths.\")\n",
        "        # Verify paths exist\n",
        "        missing_files = 0\n",
        "        valid_img_ids = []\n",
        "        for img_id in self.img_ids:\n",
        "            path = self.id_to_path.get(img_id)\n",
        "            if path and os.path.exists(path):\n",
        "                valid_img_ids.append(img_id)\n",
        "            else:\n",
        "                missing_files += 1\n",
        "        if missing_files > 0:\n",
        "            print(f\"  WARNING: Could not find image files for {missing_files} image IDs.\")\n",
        "        self.img_ids = valid_img_ids # Use only IDs with existing images\n",
        "        print(f\"  Using {len(self.img_ids)} valid image IDs for evaluation.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.img_ids[idx]\n",
        "        img_path = self.id_to_path[img_id] # Should exist based on init check\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            # Target dict needed for post-processing size info\n",
        "            target = {\"image_id\": img_id, \"width\": image.width, \"height\": image.height}\n",
        "            return image, target\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading/processing image {img_path} for id {img_id}: {e}\")\n",
        "            return None # Return None if image loading fails\n",
        "\n",
        "# --- Create Evaluation DataLoader if coco_gt loaded ---\n",
        "if coco_gt:\n",
        "    # Ensure image_processor is available\n",
        "    assert 'image_processor' in locals() and image_processor is not None, \"Image processor not loaded in Cell 2.\"\n",
        "\n",
        "    eval_dataset = CocoEvalDataset(coco_gt_obj=coco_gt, img_dir=images_dir)\n",
        "\n",
        "    # Define a collate function for evaluation (handles None)\n",
        "    def eval_collate_fn(batch):\n",
        "        batch = [item for item in batch if item is not None]\n",
        "        if not batch: return None\n",
        "        # Collate images and targets separately\n",
        "        images = [item[0] for item in batch]\n",
        "        targets = [item[1] for item in batch]\n",
        "        # Use image_processor to pad images\n",
        "        try:\n",
        "            # Note: return_tensors=\"pt\" happens inside the loop when calling processor\n",
        "            # Here we just need the list of images and targets\n",
        "             return images, targets\n",
        "        except Exception as e_pad:\n",
        "            print(f\"Error during custom collate: {e_pad}\")\n",
        "            return None\n",
        "\n",
        "    eval_loader = DataLoader(eval_dataset,\n",
        "                             batch_size=EVAL_BATCH_SIZE, # Use config batch size\n",
        "                             shuffle=False,\n",
        "                             num_workers=2, # Can increase if not causing issues\n",
        "                             collate_fn=eval_collate_fn,\n",
        "                             pin_memory=True if device.type == 'cuda' else False)\n",
        "    print(f\"Created evaluation DataLoader with {len(eval_dataset)} images and batch size {EVAL_BATCH_SIZE}.\")\n",
        "else:\n",
        "    print(\"Evaluation DataLoader not created as COCO GT is missing.\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Itkv4vUQtaUH",
        "outputId": "ff48482d-13e7-480d-9fec-cf94b97c6630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading COCO GT and Preparing Evaluation Dataloader ---\n",
            "Loading COCO ground truth for mAP evaluation from: /content/drive/MyDrive/kitti_subset/annotations/instances_val2017.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "COCO GT loaded successfully.\n",
            "  CocoEvalDataset: Mapped 200 image IDs to file paths.\n",
            "  Using 200 valid image IDs for evaluation.\n",
            "Created evaluation DataLoader with 200 images and batch size 1.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Calculate Baseline Metrics (MODIFIED)\n",
        "# =============================================================================\n",
        "print(\"\\n--- Calculating Baseline Metrics ---\")\n",
        "\n",
        "# Ensure base model is available\n",
        "assert 'prepared_base_model' in locals() and prepared_base_model is not None, \"Run Cell 2 first\"\n",
        "assert 'image_processor' in locals() and image_processor is not None, \"Run Cell 2 first\"\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "# 1. Parameters (already calculated in Cell 2)\n",
        "base_model_params = sum(p.numel() for p in prepared_base_model.parameters() if p.requires_grad)\n",
        "baseline_results['params'] = base_model_params\n",
        "print(f\"Baseline Parameters: {base_model_params:,}\")\n",
        "\n",
        "# 2. GFLOPs\n",
        "print(\"Calculating baseline GFLOPs...\")\n",
        "base_model_gflops = -1.0\n",
        "dummy_input = None\n",
        "try:\n",
        "    # Determine input size (consistent logic)\n",
        "    bs = 1; img_h, img_w = 800, 1333 # Default/common size\n",
        "    if hasattr(image_processor, 'size') and isinstance(image_processor.size, dict):\n",
        "         size_dict = image_processor.size\n",
        "         if 'shortest_edge' in size_dict:\n",
        "             shortest = size_dict['shortest_edge']; max_size = getattr(image_processor, 'max_size', 1333); aspect_ratio = 1333 / 800\n",
        "             if shortest == 800 and max_size == 1333: img_h, img_w = 800, 1333\n",
        "             else: img_h = shortest; img_w = int(shortest * aspect_ratio);\n",
        "             if img_w > max_size: img_w = max_size; img_h = int(max_size / aspect_ratio)\n",
        "         elif 'height' in size_dict and 'width' in size_dict: img_h = size_dict['height']; img_w = size_dict['width']\n",
        "         img_h = max(img_h, 32); img_w = max(img_w, 32) # Ensure min size\n",
        "    print(f\"  Using dummy input size H={img_h}, W={img_w} for GFLOPs calculation\")\n",
        "    dummy_input = torch.randn(bs, 3, img_h, img_w, device=device)\n",
        "\n",
        "    # Profile on GPU\n",
        "    flops, params_thop = profile(prepared_base_model, inputs=(dummy_input,), verbose=False)\n",
        "    base_model_gflops = flops / 1e9\n",
        "    print(f\"Baseline GFLOPs: {base_model_gflops:.2f}\")\n",
        "    baseline_results['gflops'] = base_model_gflops\n",
        "except Exception as e_gflops:\n",
        "    print(f\"  Error calculating GFLOPs: {e_gflops}\")\n",
        "    baseline_results['gflops'] = -1.0\n",
        "    # Keep dummy_input if created, might be needed later\n",
        "    if 'dummy_input' not in locals(): dummy_input = None\n",
        "\n",
        "\n",
        "# 3. COCO mAP and Inference Time\n",
        "print(\"\\nCalculating baseline mAP and Average Inference Time...\")\n",
        "baseline_results['mAP'] = -1.0\n",
        "baseline_results['mAP50'] = -1.0\n",
        "baseline_results['avg_inference_ms'] = -1.0\n",
        "\n",
        "if coco_gt is None or eval_loader is None:\n",
        "    print(\"  Skipping mAP/Inference Time calculation (COCO GT or Eval Loader missing).\")\n",
        "else:\n",
        "    coco_results_baseline = []\n",
        "    total_inference_time_ms = 0\n",
        "    processed_images_count = 0\n",
        "    inference_batches = 0\n",
        "\n",
        "    prepared_base_model.eval() # Ensure eval mode\n",
        "    with torch.no_grad():\n",
        "        for batch_data in tqdm_notebook(eval_loader, desc=\"Baseline Evaluation\"):\n",
        "            if batch_data is None: continue\n",
        "            images, targets = batch_data # Unpack images and targets\n",
        "\n",
        "            try:\n",
        "                # --- Batch Preprocessing ---\n",
        "                inputs = image_processor(images=images, return_tensors=\"pt\").to(device)\n",
        "                original_sizes = [(t['height'], t['width']) for t in targets]\n",
        "                target_sizes = torch.tensor(original_sizes, device=device)\n",
        "                image_ids = [t['image_id'] for t in targets]\n",
        "\n",
        "                # --- Timed Inference ---\n",
        "                start_time = time.perf_counter()\n",
        "                outputs = prepared_base_model(**inputs)\n",
        "                end_time = time.perf_counter()\n",
        "                total_inference_time_ms += (end_time - start_time) * 1000\n",
        "                inference_batches += 1\n",
        "                # --- End Timed Inference ---\n",
        "\n",
        "                # --- Post-processing ---\n",
        "                results_list = image_processor.post_process_object_detection(\n",
        "                    outputs,\n",
        "                    target_sizes=target_sizes,\n",
        "                    threshold=CONFIDENCE_THRESHOLD\n",
        "                )\n",
        "\n",
        "                # --- Format for COCO ---\n",
        "                for i, results in enumerate(results_list):\n",
        "                    image_id = image_ids[i]\n",
        "                    boxes = results[\"boxes\"].cpu().tolist()\n",
        "                    scores = results[\"scores\"].cpu().tolist()\n",
        "                    labels = results[\"labels\"].cpu().tolist()\n",
        "                    for box, score, label in zip(boxes, scores, labels):\n",
        "                        x_min, y_min, x_max, y_max = box\n",
        "                        coco_bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
        "                        coco_results_baseline.append({\n",
        "                            \"image_id\": image_id,\n",
        "                            \"category_id\": label+1,\n",
        "                            \"bbox\": coco_bbox,\n",
        "                            \"score\": score,\n",
        "                        })\n",
        "                    processed_images_count += 1\n",
        "\n",
        "            except Exception as e_infer:\n",
        "                 print(f\"\\nError during baseline inference/postprocessing: {e_infer}\")\n",
        "                 traceback.print_exc()\n",
        "                 continue # Skip batch on error\n",
        "\n",
        "    print(f\"\\nBaseline: Processed {processed_images_count} images over {inference_batches} batches.\")\n",
        "\n",
        "    # Calculate Average Inference Time (per batch)\n",
        "    if inference_batches > 0:\n",
        "        baseline_results['avg_inference_ms'] = total_inference_time_ms / inference_batches\n",
        "        print(f\"Baseline Average Batch Inference Time: {baseline_results['avg_inference_ms']:.2f} ms\")\n",
        "\n",
        "    # Run COCOeval API\n",
        "    if not coco_results_baseline:\n",
        "        print(\"No baseline evaluation results generated.\")\n",
        "    else:\n",
        "        print(\"Running COCO evaluation API for baseline...\")\n",
        "        try:\n",
        "            coco_dt = coco_gt.loadRes(coco_results_baseline)\n",
        "            coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "            coco_eval.evaluate(); coco_eval.accumulate(); coco_eval.summarize()\n",
        "            baseline_results['mAP'] = coco_eval.stats[0]\n",
        "            baseline_results['mAP50'] = coco_eval.stats[1]\n",
        "            print(f\"Baseline mAP: {baseline_results['mAP']:.4f}, mAP50: {baseline_results['mAP50']:.4f}\")\n",
        "            # Cleanup eval objects\n",
        "            del coco_dt, coco_eval\n",
        "        except Exception as e_coco_api:\n",
        "            print(f\"  ERROR during baseline COCOeval: {e_coco_api}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "# Store dummy_input globally if needed for pruning step\n",
        "if 'dummy_input' in locals() and dummy_input is not None:\n",
        "     globals()['dummy_input'] = dummy_input\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "print(\"\\nBaseline Metric Calculation Complete.\")"
      ],
      "metadata": {
        "id": "GovT5AyItlbM",
        "outputId": "88e10a99-3951-4288-a018-96b861c4baa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "2557bb8fe0e84c4dbf2c712c6b6040bc",
            "a18299ae505448d0836682b8123e0b22",
            "abdb19b73db04908a13a095a5f30eda9",
            "bb4e43d3629c490da429489a7b1faa28",
            "bbf00858a6de44f7b2e545abfc6069da",
            "1b585430f0734fad8ae992da0bc9a78a",
            "ac39f380593d48529fdfdca91d43fd8e",
            "be6068b3a91c4be899b320641a4a23cc",
            "4c69347005964b619996e780a0a73a1b",
            "3ca64d3272024cb3993cea1a17e00f1a",
            "a46751f44cb84eeba1cc729cd9103edf"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Baseline Metrics ---\n",
            "Baseline Parameters: 39,877,769\n",
            "Calculating baseline GFLOPs...\n",
            "  Using dummy input size H=800, W=1333 for GFLOPs calculation\n",
            "Baseline GFLOPs: 204.87\n",
            "\n",
            "Calculating baseline mAP and Average Inference Time...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Baseline Evaluation:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2557bb8fe0e84c4dbf2c712c6b6040bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline: Processed 200 images over 200 batches.\n",
            "Baseline Average Batch Inference Time: 196.28 ms\n",
            "Running COCO evaluation API for baseline...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.56s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
            "Baseline mAP: 0.1168, mAP50: 0.2639\n",
            "\n",
            "Baseline Metric Calculation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Pruning, Metrics Calculation (incl. GFLOPs), Evaluation, and Saving Loop (CORRECTED)\n",
        "# =============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import gc\n",
        "import os\n",
        "import torch_pruning as tp\n",
        "from thop import profile # Keep profile import here\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "# from tqdm import tqdm as tqdm_cli # Only if needed\n",
        "import traceback\n",
        "import time\n",
        "\n",
        "print(\"\\n--- Starting Pruning, Metrics Calculation, Evaluation & Saving Loop ---\")\n",
        "\n",
        "# --- Assertions and Setup ---\n",
        "assert 'prepared_base_model' in locals() and prepared_base_model is not None, \"Run Cell 2 first\"\n",
        "assert 'baseline_results' in locals(), \"Run Cell 4 first to get baseline metrics\"\n",
        "assert 'TARGET_PRUNING_RATIOS' in locals(), \"TARGET_PRUNING_RATIOS not defined in Cell 1\"\n",
        "assert 'image_processor' in locals() and image_processor is not None, \"Image processor needed\"\n",
        "assert 'coco_gt' in locals(), \"COCO GT object needed\" # Allow None, but mAP will be skipped\n",
        "assert 'eval_loader' in locals(), \"Eval loader needed\" # Allow None, but mAP will be skipped\n",
        "assert 'output_dir' in locals(), \"Output directory needed\"\n",
        "assert 'CONFIDENCE_THRESHOLD' in locals(), \"Confidence threshold needed\"\n",
        "device = next(prepared_base_model.parameters()).device # Get device from model\n",
        "base_model_params = baseline_results.get('params', 0) # Get baseline params\n",
        "base_model_gflops = baseline_results.get('gflops', -1.0) # Get baseline GFLOPs\n",
        "print(f\"Using Baseline - Params: {base_model_params:,}, GFLOPs: {base_model_gflops:.2f}\")\n",
        "\n",
        "# --- Dummy Input Setup ---\n",
        "if 'dummy_input' not in locals() or dummy_input is None:\n",
        "    print(\"Recreating dummy input...\")\n",
        "    bs = 1; img_h, img_w = 800, 1333 # Default/common size\n",
        "    if hasattr(image_processor, 'size') and isinstance(image_processor.size, dict):\n",
        "         size_dict = image_processor.size\n",
        "         if 'shortest_edge' in size_dict:\n",
        "             shortest = size_dict['shortest_edge']; max_size = getattr(image_processor, 'max_size', 1333); aspect_ratio = 1333 / 800\n",
        "             if shortest == 800 and max_size == 1333: img_h, img_w = 800, 1333\n",
        "             else: img_h = shortest; img_w = int(shortest * aspect_ratio);\n",
        "             if img_w > max_size: img_w = max_size; img_h = int(max_size / aspect_ratio)\n",
        "         elif 'height' in size_dict and 'width' in size_dict: img_h = size_dict['height']; img_w = size_dict['width']\n",
        "         img_h = max(img_h, 32); img_w = max(img_w, 32) # Ensure min size\n",
        "    dummy_input = torch.randn(bs, 3, img_h, img_w, device=device)\n",
        "    print(f\"  Created dummy input shape: {dummy_input.shape} on {dummy_input.device}\")\n",
        "elif dummy_input.device != device:\n",
        "    dummy_input = dummy_input.to(device)\n",
        "    print(f\"Moved existing dummy input to {dummy_input.device}\")\n",
        "# --- End Dummy Input Setup ---\n",
        "\n",
        "pruning_results = {}\n",
        "\n",
        "# --- Loop through each target pruning ratio ---\n",
        "for ratio in TARGET_PRUNING_RATIOS:\n",
        "    print(f\"\\n===== Processing Ratio: {ratio:.2f} =====\")\n",
        "    # --- Initialize variables for this iteration scope ---\n",
        "    pruning_results[ratio] = {}\n",
        "    model_pruned_copy = None\n",
        "    pruner = None\n",
        "    importance = None\n",
        "    ignored_layers = None\n",
        "    nested_model = None\n",
        "    coco_results_pruned = None\n",
        "    coco_dt_pruned = None\n",
        "    coco_eval_pruned = None\n",
        "    # --- End Initialization ---\n",
        "\n",
        "    try:\n",
        "        # --- 1. Deep Copy ---\n",
        "        print(\"  1. Creating deepcopy...\")\n",
        "        model_pruned_copy = copy.deepcopy(prepared_base_model)\n",
        "        model_pruned_copy.eval()\n",
        "        print(f\"     Copy created on {next(model_pruned_copy.parameters()).device}\")\n",
        "\n",
        "        # --- 2. Identify Ignored Layers ---\n",
        "        print(\"  2. Identifying layers to ignore...\")\n",
        "        ignored_layers_modules = []\n",
        "        if not hasattr(model_pruned_copy, 'model') or not isinstance(model_pruned_copy.model, nn.Module): raise AttributeError(\"Nested 'model' module not found\")\n",
        "        nested_model = model_pruned_copy.model\n",
        "        def add_module_and_submodules(module_instance): # Simplified helper\n",
        "             if module_instance is None or not isinstance(module_instance, nn.Module): return\n",
        "             if module_instance not in ignored_layers_modules: ignored_layers_modules.append(module_instance)\n",
        "             for submodule in module_instance.modules():\n",
        "                 if submodule not in ignored_layers_modules and submodule is not module_instance: ignored_layers_modules.append(submodule)\n",
        "        # Add layers to ignore... (keep the same robust logic)\n",
        "        if hasattr(nested_model, 'backbone'):\n",
        "            if hasattr(nested_model.backbone, 'conv_encoder') and hasattr(nested_model.backbone.conv_encoder, 'model'):\n",
        "                 timm_model = nested_model.backbone.conv_encoder.model\n",
        "                 if hasattr(timm_model, 'conv1'): ignored_layers_modules.append(timm_model.conv1)\n",
        "                 if hasattr(timm_model, 'bn1') and isinstance(timm_model.bn1, nn.BatchNorm2d): ignored_layers_modules.append(timm_model.bn1) # Check standard BN\n",
        "                 for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                     if hasattr(timm_model, layer_name):\n",
        "                         res_layer = getattr(timm_model, layer_name)\n",
        "                         if hasattr(res_layer, '__iter__'):\n",
        "                             for block in res_layer:\n",
        "                                 if hasattr(block, 'downsample') and block.downsample is not None: add_module_and_submodules(block.downsample)\n",
        "        if hasattr(model_pruned_copy, 'class_embed'): add_module_and_submodules(model_pruned_copy.class_embed)\n",
        "        if hasattr(model_pruned_copy, 'bbox_embed'): add_module_and_submodules(model_pruned_copy.bbox_embed)\n",
        "        if hasattr(nested_model, 'level_embed'): ignored_layers_modules.append(nested_model.level_embed)\n",
        "        if hasattr(nested_model, 'input_proj'): add_module_and_submodules(nested_model.input_proj)\n",
        "        if hasattr(nested_model, 'query_position_embeddings'): ignored_layers_modules.append(nested_model.query_position_embeddings)\n",
        "        if hasattr(nested_model, 'reference_points'): ignored_layers_modules.append(nested_model.reference_points)\n",
        "\n",
        "        ignored_layers = list(set(m for m in ignored_layers_modules if isinstance(m, nn.Module) and m is not model_pruned_copy and m is not nested_model))\n",
        "        print(f\"     Identified {len(ignored_layers)} unique modules to ignore.\")\n",
        "\n",
        "        # --- 3. Define Pruner ---\n",
        "        print(f\"  3. Setting up Pruner for ratio {ratio:.2f}...\")\n",
        "        importance = tp.importance.MagnitudeImportance(p=1)\n",
        "        if dummy_input.device != model_pruned_copy.device: dummy_input = dummy_input.to(model_pruned_copy.device)\n",
        "        pruner = tp.pruner.MagnitudePruner(model_pruned_copy, example_inputs=dummy_input, importance=importance, pruning_ratio=ratio, ignored_layers=ignored_layers, root_module_types=[nn.Conv2d], round_to=8)\n",
        "        print(f\"     Pruner initialized.\")\n",
        "\n",
        "        # --- 4. Apply Pruning ---\n",
        "        print(\"  4. Applying pruner.step()...\")\n",
        "        pruning_start_time = time.time()\n",
        "        pruner.step()\n",
        "        pruning_end_time = time.time()\n",
        "        print(f\"     Pruning step completed in {pruning_end_time - pruning_start_time:.2f} seconds.\")\n",
        "        model_pruned_copy.eval()\n",
        "\n",
        "        # --- 5. Calculate Physical Metrics (Params and GFLOPs - INTEGRATED) ---\n",
        "        print(\"  5. Calculating pruned physical metrics...\")\n",
        "        # Params\n",
        "        pruned_params = sum(p.numel() for p in model_pruned_copy.parameters() if p.requires_grad)\n",
        "        pruning_results[ratio]['params'] = pruned_params\n",
        "        pruning_results[ratio]['param_reduc%'] = (1 - pruned_params / base_model_params) * 100 if base_model_params > 0 else 0\n",
        "        print(f\"     Pruned Params: {pruned_params:,} (Reduction: {pruning_results[ratio]['param_reduc%']:.2f}%)\")\n",
        "\n",
        "        # GFLOPs (Calculate HERE)\n",
        "        pruning_results[ratio]['gflops'] = -1.0 # Initialize for this ratio\n",
        "        pruning_results[ratio]['gflop_reduc%'] = 0.0\n",
        "        try:\n",
        "             print(\"     Calculating GFLOPs...\")\n",
        "             # Use the model_pruned_copy which is in memory with the correct structure\n",
        "             # Ensure dummy_input is on the same device as the model\n",
        "             if dummy_input.device != model_pruned_copy.device:\n",
        "                 dummy_input = dummy_input.to(model_pruned_copy.device)\n",
        "\n",
        "             flops, params_thop = profile(model_pruned_copy, inputs=(dummy_input,), verbose=False)\n",
        "             pruned_gflops = flops / 1e9\n",
        "             pruning_results[ratio]['gflops'] = pruned_gflops\n",
        "             # Calculate reduction using baseline GFLOPs loaded at the start\n",
        "             pruning_results[ratio]['gflop_reduc%'] = (1 - pruned_gflops / base_model_gflops) * 100 if base_model_gflops > 0 else 0\n",
        "             print(f\"     Pruned GFLOPs: {pruned_gflops:.2f} (Reduction: {pruning_results[ratio]['gflop_reduc%']:.2f}%)\")\n",
        "        except Exception as e_gflops_pruned:\n",
        "             print(f\"     Error calculating pruned GFLOPs: {e_gflops_pruned}\")\n",
        "             # traceback.print_exc() # Uncomment for detailed debug if needed\n",
        "\n",
        "        # --- 6. Calculate Performance Metrics (mAP, Inference Time) ---\n",
        "        print(\"  6. Calculating pruned performance metrics...\")\n",
        "        pruning_results[ratio]['mAP'] = -1.0; pruning_results[ratio]['mAP50'] = -1.0; pruning_results[ratio]['avg_inference_ms'] = -1.0\n",
        "\n",
        "        if coco_gt is None or eval_loader is None:\n",
        "            print(\"     Skipping mAP/Inference Time (COCO GT or Eval Loader missing).\")\n",
        "        else:\n",
        "            coco_results_pruned = [] # Re-initialize list for this ratio\n",
        "            total_inference_time_ms_pruned = 0; processed_images_count_pruned = 0; inference_batches_pruned = 0\n",
        "            model_pruned_copy.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch_data in tqdm_notebook(eval_loader, desc=f\"Evaluating Ratio {ratio:.2f}\", leave=False):\n",
        "                    if batch_data is None: continue\n",
        "                    images, targets = batch_data # Unpack batch\n",
        "                    try:\n",
        "                        # Ensure images is a list for the processor\n",
        "                        if not isinstance(images, list): images = [images]\n",
        "                        inputs = image_processor(images=images, return_tensors=\"pt\").to(device)\n",
        "                        original_sizes = [(t['height'], t['width']) for t in targets]\n",
        "                        target_sizes = torch.tensor(original_sizes, device=device)\n",
        "                        image_ids = [t['image_id'] for t in targets]\n",
        "\n",
        "                        start_time = time.perf_counter()\n",
        "                        outputs = model_pruned_copy(**inputs)\n",
        "                        end_time = time.perf_counter()\n",
        "                        total_inference_time_ms_pruned += (end_time - start_time) * 1000\n",
        "                        inference_batches_pruned += len(images) # Count batches by number of images processed\n",
        "\n",
        "                        results_list = image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=CONFIDENCE_THRESHOLD)\n",
        "\n",
        "                        for i, results in enumerate(results_list):\n",
        "                            image_id = image_ids[i]\n",
        "                            boxes = results[\"boxes\"].cpu().tolist(); scores = results[\"scores\"].cpu().tolist(); labels = results[\"labels\"].cpu().tolist()\n",
        "                            for box, score, label in zip(boxes, scores, labels):\n",
        "                                x_min, y_min, x_max, y_max = box; coco_bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
        "                                # ===================================\n",
        "                                # <<< *** CORRECTED CATEGORY ID *** >>>\n",
        "                                # ===================================\n",
        "                                coco_results_pruned.append({\"image_id\": image_id, \"category_id\": label+1, \"bbox\": coco_bbox, \"score\": score})\n",
        "                            processed_images_count_pruned += 1 # Count images processed\n",
        "                    except Exception as e_infer_pruned:\n",
        "                        print(f\"\\nError during pruned inference/postprocessing (img_ids: {image_ids}): {e_infer_pruned}\")\n",
        "                        traceback.print_exc() # Print traceback for debug\n",
        "                        continue # Skip to next batch\n",
        "\n",
        "            print(f\"     Processed {processed_images_count_pruned} images over {inference_batches_pruned} batches.\")\n",
        "            if inference_batches_pruned > 0:\n",
        "                 # Calculate per-batch average inference time\n",
        "                 pruning_results[ratio]['avg_inference_ms'] = total_inference_time_ms_pruned / inference_batches_pruned\n",
        "                 print(f\"     Pruned Avg Batch Inference Time: {pruning_results[ratio]['avg_inference_ms']:.2f} ms\")\n",
        "\n",
        "            if not coco_results_pruned: print(\"     No pruned evaluation results generated.\")\n",
        "            else:\n",
        "                print(\"     Running COCO evaluation API...\")\n",
        "                try:\n",
        "                    coco_dt_pruned = coco_gt.loadRes(coco_results_pruned)\n",
        "                    coco_eval_pruned = COCOeval(coco_gt, coco_dt_pruned, iouType='bbox')\n",
        "                    coco_eval_pruned.evaluate(); coco_eval_pruned.accumulate(); coco_eval_pruned.summarize()\n",
        "                    pruning_results[ratio]['mAP'] = coco_eval_pruned.stats[0]\n",
        "                    pruning_results[ratio]['mAP50'] = coco_eval_pruned.stats[1]\n",
        "                    print(f\"     Pruned mAP: {pruning_results[ratio]['mAP']:.4f}, mAP50: {pruning_results[ratio]['mAP50']:.4f}\")\n",
        "                except Exception as e_coco_api_pruned:\n",
        "                    print(f\"     ERROR during pruned COCOeval: {e_coco_api_pruned}\");\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        # --- 7. Save Pruned Model ---\n",
        "        try:\n",
        "            pruned_model_save_dir = os.path.join(output_dir, f\"pruned_ratio_{ratio:.2f}\")\n",
        "            print(f\"  7. Saving pruned structure to: {pruned_model_save_dir}\")\n",
        "            os.makedirs(pruned_model_save_dir, exist_ok=True)\n",
        "            # Use save_pretrained, which saves config and weights\n",
        "            # The config will still be the *original* config, but the weights will be pruned.\n",
        "            model_pruned_copy.save_pretrained(pruned_model_save_dir)\n",
        "            if image_processor: image_processor.save_pretrained(pruned_model_save_dir)\n",
        "            pruning_results[ratio]['save_path'] = pruned_model_save_dir\n",
        "            print(f\"     Saved successfully.\")\n",
        "        except Exception as e_save:\n",
        "            print(f\"     Error saving pruned model for ratio {ratio:.2f}: {e_save}\")\n",
        "            traceback.print_exc() # Print traceback for save errors\n",
        "            pruning_results[ratio]['save_path'] = \"Error\"\n",
        "\n",
        "    # --- Error Handling for the whole iteration ---\n",
        "    except Exception as e_ratio:\n",
        "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        print(f\"!! ERROR processing ratio {ratio:.2f}: {e_ratio}\")\n",
        "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        traceback.print_exc()\n",
        "        # Ensure basic error structure exists\n",
        "        pruning_results[ratio] = {'error': str(e_ratio), 'params': -1, 'gflops': -1.0, 'mAP': -1.0, 'mAP50': -1.0, 'avg_inference_ms': -1.0, 'param_reduc%': 0.0, 'gflop_reduc%': 0.0, 'save_path': 'ERROR'}\n",
        "\n",
        "\n",
        "    # --- Explicit Cleanup within the loop ---\n",
        "    finally:\n",
        "        print(f\"--- Cleaning up after ratio {ratio:.2f} ---\")\n",
        "        # Keep the same detailed cleanup logic as before\n",
        "        if 'model_pruned_copy' in locals() and model_pruned_copy is not None: del model_pruned_copy\n",
        "        if 'pruner' in locals() and pruner is not None: del pruner\n",
        "        if 'coco_results_pruned' in locals() and coco_results_pruned is not None: del coco_results_pruned\n",
        "        if 'coco_dt_pruned' in locals() and coco_dt_pruned is not None: del coco_dt_pruned\n",
        "        if 'coco_eval_pruned' in locals() and coco_eval_pruned is not None: del coco_eval_pruned\n",
        "        if 'ignored_layers' in locals() and ignored_layers is not None: del ignored_layers\n",
        "        if 'importance' in locals() and importance is not None: del importance\n",
        "        if 'nested_model' in locals() and nested_model is not None: del nested_model\n",
        "        if 'images' in locals(): del images\n",
        "        if 'targets' in locals(): del targets\n",
        "        if 'inputs' in locals(): del inputs\n",
        "        if 'outputs' in locals(): del outputs\n",
        "        if 'results_list' in locals(): del results_list\n",
        "        if 'batch_data' in locals(): del batch_data\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        print(f\"--- End Cleanup for ratio {ratio:.2f} ---\")\n",
        "\n",
        "\n",
        "print(\"\\n===== Pruning, Metrics, & Saving Loop Finished =====\")\n",
        "globals()['pruning_results'] = pruning_results\n",
        "globals()['baseline_results'] = baseline_results # Ensure baseline is global for Cell 6"
      ],
      "metadata": {
        "id": "HD2wMoE8vDvS",
        "outputId": "19286873-61a5-4b0c-8d1e-57f74ca05fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6e5bea110c0f4d6582e3014f946b6699",
            "d201b70c7bb94a4ebd54520bccaf54a5",
            "97b23fa1fcbc43b48ca0b50d205585d7",
            "70d1e6a3e21d4afda59880e201c25bde",
            "60dd382a024e4250a71b49eeafc8f0b9",
            "62062d5499ed426588a49bab40d1df1f",
            "df5e2d9e2d434aaab680801c226b3767",
            "d2f3f0cff6b64b83862117df16396fd3",
            "21c3867dc87d4749b9e25f88fadb2abb",
            "5d14ae46bb0543fdb362391a0ca11993",
            "963ebedd867a40688e9133f9d6d591e6",
            "92079b134c9743d493d60b6d59fb4e14",
            "4a5a47485e75497692f30c2739f9b87c",
            "0a83af4b24514755aeb7e1895d3a3cf7",
            "b6ebe99182be4bef853174d2fbb9cd68",
            "1846da366c83402ebc8add4f3255abef",
            "7c0e2c4daee340958afe2b52bc78842b",
            "99b1dd112b134077b79eea2060df11b0",
            "4ff6a6d5f37a4802ba399d063aeba119",
            "2a9c92a3b5ec4cebb9cadaeabe10765e",
            "e6be36618e2b47fa86984927bddb19f4",
            "51863891d6c44ec1b4c18bd80a658d37",
            "b2af4969aacf4e9784780be683bfbda6",
            "ebcf7b80d7e14b38b0ab0012c19a33a8",
            "15ab12615f5745059f04a3b96117c243",
            "eea43a0bf7dc4fbdb36bf50251e7244d",
            "81c87310c53343819f36eb78778a6726",
            "8e586670cc5f44e186750cb4a9ed7d5d",
            "702c906920d3476ca618438f29d90e53",
            "c9fd54ac50234c7eb866617278c4c8fb",
            "780017fc9f0d41fda9510ba974284b53",
            "da1170cee547492c99e0457c618cd5bc",
            "086f79c663734690be8cc26816b9f1bc",
            "74d073933744406a9e7c233f14b04d72",
            "854d405794d74415aa63d73da47892fd",
            "ce6d27d70b9741ef97e7348aba8b2083",
            "5508933406b347209d16d300fd62ff8f",
            "ab711ab9ecfc441e82fc9d030c73ca69",
            "98c41e6e234e4208bd55bcd4630317e9",
            "1580650a26004d1eabad003dad473cf5",
            "bea525fe5dc54ddd852fe78d5bfbebe4",
            "8030bb2013054c299fc16ffacea0469b",
            "1efe367800524974ab8526a5fe7707e0",
            "bb0321ca5c314cd5b6c13e37f204df52",
            "d3ac69eb828b42d6b92218fb245154ee",
            "2c356779c2544c09b23cdbf4f1278fc6",
            "29842bf2f05c4b7e9ef0f25c481d4b02",
            "33dc254393d141658b900942164d8bef",
            "3bbb308c2fbd43dbaee38a1ddead9851",
            "26934d1cd3aa45959589cafa3f2c099f",
            "dad3ef7115f8462ab2914172318d26be",
            "4f86c3764e044598b2b1efa93d01f5e7",
            "48e670c1ae1843ae8d0bc7aad67b144d",
            "662afbfaf2a64fb982c0d19216c48370",
            "05242b67b92645e6a424d1463bdff672"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Pruning, Metrics Calculation, Evaluation & Saving Loop ---\n",
            "Using Baseline - Params: 39,877,769, GFLOPs: 204.87\n",
            "\n",
            "===== Processing Ratio: 0.10 =====\n",
            "  1. Creating deepcopy...\n",
            "     Copy created on cuda:0\n",
            "  2. Identifying layers to ignore...\n",
            "     Identified 37 unique modules to ignore.\n",
            "  3. Setting up Pruner for ratio 0.10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_pruning/dependency.py:699: UserWarning: Unwrapped parameters detected: ['model.level_embed'].\n",
            " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
            "  warnings.warn(warning_str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pruner initialized.\n",
            "  4. Applying pruner.step()...\n",
            "     Pruning step completed in 0.34 seconds.\n",
            "  5. Calculating pruned physical metrics...\n",
            "     Pruned Params: 36,535,561 (Reduction: 8.38%)\n",
            "     Calculating GFLOPs...\n",
            "     Pruned GFLOPs: 191.19 (Reduction: 6.68%)\n",
            "  6. Calculating pruned performance metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Ratio 0.10:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e5bea110c0f4d6582e3014f946b6699"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Processed 200 images over 200 batches.\n",
            "     Pruned Avg Batch Inference Time: 194.61 ms\n",
            "     Running COCO evaluation API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
            "     Pruned mAP: 0.0915, mAP50: 0.2250\n",
            "  7. Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.10\n",
            "     Saved successfully.\n",
            "--- Cleaning up after ratio 0.10 ---\n",
            "--- End Cleanup for ratio 0.10 ---\n",
            "\n",
            "===== Processing Ratio: 0.20 =====\n",
            "  1. Creating deepcopy...\n",
            "     Copy created on cuda:0\n",
            "  2. Identifying layers to ignore...\n",
            "     Identified 37 unique modules to ignore.\n",
            "  3. Setting up Pruner for ratio 0.20...\n",
            "     Pruner initialized.\n",
            "  4. Applying pruner.step()...\n",
            "     Pruning step completed in 0.25 seconds.\n",
            "  5. Calculating pruned physical metrics...\n",
            "     Pruned Params: 33,827,049 (Reduction: 15.17%)\n",
            "     Calculating GFLOPs...\n",
            "     Pruned GFLOPs: 180.16 (Reduction: 12.06%)\n",
            "  6. Calculating pruned performance metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Ratio 0.20:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92079b134c9743d493d60b6d59fb4e14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Processed 200 images over 200 batches.\n",
            "     Pruned Avg Batch Inference Time: 195.88 ms\n",
            "     Running COCO evaluation API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
            "     Pruned mAP: 0.0236, mAP50: 0.0544\n",
            "  7. Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.20\n",
            "     Saved successfully.\n",
            "--- Cleaning up after ratio 0.20 ---\n",
            "--- End Cleanup for ratio 0.20 ---\n",
            "\n",
            "===== Processing Ratio: 0.30 =====\n",
            "  1. Creating deepcopy...\n",
            "     Copy created on cuda:0\n",
            "  2. Identifying layers to ignore...\n",
            "     Identified 37 unique modules to ignore.\n",
            "  3. Setting up Pruner for ratio 0.30...\n",
            "     Pruner initialized.\n",
            "  4. Applying pruner.step()...\n",
            "     Pruning step completed in 0.25 seconds.\n",
            "  5. Calculating pruned physical metrics...\n",
            "     Pruned Params: 31,162,281 (Reduction: 21.86%)\n",
            "     Calculating GFLOPs...\n",
            "     Pruned GFLOPs: 171.21 (Reduction: 16.43%)\n",
            "  6. Calculating pruned performance metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Ratio 0.30:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2af4969aacf4e9784780be683bfbda6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Processed 200 images over 200 batches.\n",
            "     Pruned Avg Batch Inference Time: 193.88 ms\n",
            "     Running COCO evaluation API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "     Pruned mAP: 0.0000, mAP50: 0.0000\n",
            "  7. Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.30\n",
            "     Saved successfully.\n",
            "--- Cleaning up after ratio 0.30 ---\n",
            "--- End Cleanup for ratio 0.30 ---\n",
            "\n",
            "===== Processing Ratio: 0.40 =====\n",
            "  1. Creating deepcopy...\n",
            "     Copy created on cuda:0\n",
            "  2. Identifying layers to ignore...\n",
            "     Identified 37 unique modules to ignore.\n",
            "  3. Setting up Pruner for ratio 0.40...\n",
            "     Pruner initialized.\n",
            "  4. Applying pruner.step()...\n",
            "     Pruning step completed in 0.26 seconds.\n",
            "  5. Calculating pruned physical metrics...\n",
            "     Pruned Params: 28,882,313 (Reduction: 27.57%)\n",
            "     Calculating GFLOPs...\n",
            "     Pruned GFLOPs: 161.91 (Reduction: 20.97%)\n",
            "  6. Calculating pruned performance metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Ratio 0.40:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74d073933744406a9e7c233f14b04d72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Processed 200 images over 200 batches.\n",
            "     Pruned Avg Batch Inference Time: 190.35 ms\n",
            "     Running COCO evaluation API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "     Pruned mAP: 0.0000, mAP50: 0.0000\n",
            "  7. Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.40\n",
            "     Saved successfully.\n",
            "--- Cleaning up after ratio 0.40 ---\n",
            "--- End Cleanup for ratio 0.40 ---\n",
            "\n",
            "===== Processing Ratio: 0.50 =====\n",
            "  1. Creating deepcopy...\n",
            "     Copy created on cuda:0\n",
            "  2. Identifying layers to ignore...\n",
            "     Identified 37 unique modules to ignore.\n",
            "  3. Setting up Pruner for ratio 0.50...\n",
            "     Pruner initialized.\n",
            "  4. Applying pruner.step()...\n",
            "     Pruning step completed in 0.24 seconds.\n",
            "  5. Calculating pruned physical metrics...\n",
            "     Pruned Params: 26,899,209 (Reduction: 32.55%)\n",
            "     Calculating GFLOPs...\n",
            "     Pruned GFLOPs: 156.28 (Reduction: 23.72%)\n",
            "  6. Calculating pruned performance metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Ratio 0.50:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3ac69eb828b42d6b92218fb245154ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Processed 200 images over 200 batches.\n",
            "     Pruned Avg Batch Inference Time: 188.51 ms\n",
            "     Running COCO evaluation API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "     Pruned mAP: 0.0000, mAP50: 0.0000\n",
            "  7. Saving pruned structure to: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.50\n",
            "     Saved successfully.\n",
            "--- Cleaning up after ratio 0.50 ---\n",
            "--- End Cleanup for ratio 0.50 ---\n",
            "\n",
            "===== Pruning, Metrics, & Saving Loop Finished =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 5.5: Calculate GFLOPs for Saved Pruned Models (NEW)\n",
        "# =============================================================================\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "from transformers import AutoModelForObjectDetection # Need this for loading\n",
        "from thop import profile\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "\n",
        "print(\"\\n--- Calculating GFLOPs for Saved Pruned Models ---\")\n",
        "\n",
        "assert 'pruning_results' in locals(), \"Pruning results from Cell 5 needed.\"\n",
        "assert 'baseline_results' in locals(), \"Baseline results needed.\"\n",
        "assert 'dummy_input' in locals() and dummy_input is not None, \"Dummy input needed.\"\n",
        "assert 'device' in locals(), \"Device needed.\"\n",
        "\n",
        "base_gflops = baseline_results.get('gflops', -1.0)\n",
        "if base_gflops <= 0:\n",
        "    print(\"WARNING: Baseline GFLOPs not available, cannot calculate reduction.\")\n",
        "\n",
        "for ratio in tqdm_notebook(sorted(pruning_results.keys()), desc=\"Calculating GFLOPs\"):\n",
        "    if 'error' in pruning_results[ratio] or 'save_path' not in pruning_results[ratio]:\n",
        "        print(f\"Skipping GFLOPs for ratio {ratio:.2f} due to previous error or missing path.\")\n",
        "        continue\n",
        "\n",
        "    save_dir = pruning_results[ratio]['save_path']\n",
        "    if not os.path.isdir(save_dir):\n",
        "        print(f\"Save directory not found for ratio {ratio:.2f}: {save_dir}. Skipping GFLOPs.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing Ratio: {ratio:.2f}\")\n",
        "    loaded_model_for_flops = None # Ensure clean state\n",
        "\n",
        "    try:\n",
        "        # Load the saved pruned model\n",
        "        print(f\"  Loading model from: {save_dir}\")\n",
        "        # Use low_cpu_mem_usage if loading large models causes CPU OOM\n",
        "        loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
        "            save_dir,\n",
        "            # low_cpu_mem_usage=True # Optional\n",
        "        )\n",
        "        loaded_model_for_flops.to(device) # Move to GPU for profiling\n",
        "        loaded_model_for_flops.eval()\n",
        "        print(f\"  Model loaded to {device}.\")\n",
        "\n",
        "        # Calculate GFLOPs\n",
        "        print(\"  Calculating GFLOPs...\")\n",
        "        # Ensure dummy input is on the correct device\n",
        "        if dummy_input.device != loaded_model_for_flops.device:\n",
        "             dummy_input = dummy_input.to(loaded_model_for_flops.device)\n",
        "\n",
        "        flops, _ = profile(loaded_model_for_flops, inputs=(dummy_input,), verbose=False)\n",
        "        pruned_gflops = flops / 1e9\n",
        "\n",
        "        # Update results dictionary\n",
        "        pruning_results[ratio]['gflops'] = pruned_gflops\n",
        "        pruning_results[ratio]['gflop_reduc%'] = (1 - pruned_gflops / base_gflops) * 100 if base_gflops > 0 else 0\n",
        "        print(f\"  GFLOPs: {pruned_gflops:.2f} (Reduction: {pruning_results[ratio]['gflop_reduc%']:.2f}%)\")\n",
        "\n",
        "    except Exception as e_flops:\n",
        "        print(f\"  Error calculating GFLOPs for ratio {ratio:.2f}: {e_flops}\")\n",
        "        traceback.print_exc()\n",
        "        pruning_results[ratio]['gflops'] = -1.0\n",
        "        pruning_results[ratio]['gflop_reduc%'] = 0.0\n",
        "\n",
        "    finally:\n",
        "        # Cleanup for this iteration\n",
        "        print(\"  Cleaning up loaded model...\")\n",
        "        if loaded_model_for_flops is not None:\n",
        "            del loaded_model_for_flops\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        print(\"  Cleanup complete.\")\n",
        "\n",
        "print(\"\\n--- GFLOPs Calculation Finished ---\")\n",
        "# Update global results\n",
        "globals()['pruning_results'] = pruning_results"
      ],
      "metadata": {
        "id": "aw1zGDdO9n40",
        "outputId": "482ec447-0a15-4496-8a73-c875758de561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6943b74d04f54336aa2b0018a44ab373",
            "a8b7fbc516834c1ab48ea6534f2ac70f",
            "678671d72f5a43dead17969a26bea8d9",
            "06110da8335b4dce99dbb3966ed196f4",
            "8a81969d02484baea87ead0697c86a5a",
            "0946e4bdbd624a95ae613c69aea2eadf",
            "8a7ff4ec56c048489a708d71a1f93eaa",
            "212667b3dc604579871fbfcaf5914672",
            "b72991a7a1374a3a85b2841e8b04da7b",
            "3175da1bdc034d92af4df662c47cb7d1",
            "78668c2f94bc42a89db8c972251f7afa"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating GFLOPs for Saved Pruned Models ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calculating GFLOPs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6943b74d04f54336aa2b0018a44ab373"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Ratio: 0.10\n",
            "  Loading model from: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.10\n",
            "  Error calculating GFLOPs for ratio 0.10: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up loaded model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-b851656bcfae>\", line 39, in <cell line: 0>\n",
            "    loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cleanup complete.\n",
            "\n",
            "Processing Ratio: 0.20\n",
            "  Loading model from: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.20\n",
            "  Error calculating GFLOPs for ratio 0.20: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up loaded model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-b851656bcfae>\", line 39, in <cell line: 0>\n",
            "    loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cleanup complete.\n",
            "\n",
            "Processing Ratio: 0.30\n",
            "  Loading model from: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.30\n",
            "  Error calculating GFLOPs for ratio 0.30: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up loaded model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-b851656bcfae>\", line 39, in <cell line: 0>\n",
            "    loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cleanup complete.\n",
            "\n",
            "Processing Ratio: 0.40\n",
            "  Loading model from: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.40\n",
            "  Error calculating GFLOPs for ratio 0.40: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up loaded model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-b851656bcfae>\", line 39, in <cell line: 0>\n",
            "    loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cleanup complete.\n",
            "\n",
            "Processing Ratio: 0.50\n",
            "  Loading model from: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.50\n",
            "  Error calculating GFLOPs for ratio 0.50: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "  Cleaning up loaded model...\n",
            "  Cleanup complete.\n",
            "\n",
            "--- GFLOPs Calculation Finished ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-b851656bcfae>\", line 39, in <cell line: 0>\n",
            "    loaded_model_for_flops = AutoModelForObjectDetection.from_pretrained(\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n",
            "    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 824, in _load_state_dict_into_meta_model\n",
            "    _load_parameter_into_model(model, param_name, param.to(param_device))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 712, in _load_parameter_into_model\n",
            "    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DeformableDetrFrozenBatchNorm2d:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Final Summary and Save Results (MODIFIED)\n",
        "# =============================================================================\n",
        "import json       # <-- Added import\n",
        "import pandas as pd\n",
        "import os\n",
        "import traceback  # <-- Added import for robust error handling\n",
        "\n",
        "print(\"\\n--- Final Summary and Saving Results ---\")\n",
        "\n",
        "# Ensure results dictionaries exist\n",
        "assert 'baseline_results' in locals(), \"Run Cell 4 first for baseline metrics.\"\n",
        "assert 'pruning_results' in locals(), \"Run Cell 5/5.5 first for pruning loop results.\"\n",
        "assert 'output_dir' in locals(), \"Output directory must be defined in Cell 1.\"\n",
        "\n",
        "# --- Define Output Filenames ---\n",
        "json_filename = \"pruning_results_summary.json\"\n",
        "csv_filename = \"pruning_results_summary.csv\"\n",
        "json_filepath = os.path.join(output_dir, json_filename)\n",
        "csv_filepath = os.path.join(output_dir, csv_filename)\n",
        "\n",
        "# --- Combine Results for JSON Saving ---\n",
        "# Create a single dictionary holding both baseline and pruned results\n",
        "all_results_to_save = {\n",
        "    \"baseline\": baseline_results,\n",
        "    \"pruning_ratios\": pruning_results # This already contains results keyed by ratio\n",
        "}\n",
        "\n",
        "# --- Save to JSON ---\n",
        "print(f\"\\nSaving detailed results to JSON: {json_filepath}\")\n",
        "try:\n",
        "    with open(json_filepath, 'w') as f:\n",
        "        # Use indent for readability\n",
        "        json.dump(all_results_to_save, f, indent=4, sort_keys=True)\n",
        "    print(\"  JSON results saved successfully.\")\n",
        "except Exception as e_json:\n",
        "    print(f\"  ERROR saving results to JSON: {e_json}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "# --- Prepare Data for CSV and Print Summary ---\n",
        "print(\"\\n--- Baseline Model Metrics (for reference) ---\")\n",
        "print(f\"Parameters: {baseline_results.get('params', 'N/A'):,}\")\n",
        "print(f\"GFLOPs: {baseline_results.get('gflops', -1.0):.2f}\")\n",
        "print(f\"mAP: {baseline_results.get('mAP', -1.0):.4f}\")\n",
        "print(f\"mAP50: {baseline_results.get('mAP50', -1.0):.4f}\")\n",
        "print(f\"Avg Inference Time (ms/batch): {baseline_results.get('avg_inference_ms', -1.0):.2f}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "print(\"\\n--- Pruned Model Metrics Summary ---\")\n",
        "data_for_df = []\n",
        "\n",
        "# Add baseline as the first row for comparison in the CSV/DataFrame\n",
        "data_for_df.append({\n",
        "    'Ratio': \"Baseline\",\n",
        "    'Params': f\"{baseline_results.get('params', 0):,}\",\n",
        "    'Param Reduc %': \"0.00\",\n",
        "    'GFLOPs': f\"{baseline_results.get('gflops', -1.0):.2f}\",\n",
        "    'GFLOP Reduc %': \"0.00\",\n",
        "    'mAP': f\"{baseline_results.get('mAP', -1.0):.4f}\" if baseline_results.get('mAP', -1.0) >= 0 else \"N/A\",\n",
        "    'mAP50': f\"{baseline_results.get('mAP50', -1.0):.4f}\" if baseline_results.get('mAP50', -1.0) >= 0 else \"N/A\",\n",
        "    'Avg Inf Time (ms)': f\"{baseline_results.get('avg_inference_ms', -1.0):.2f}\" if baseline_results.get('avg_inference_ms', -1.0) >= 0 else \"N/A\",\n",
        "    'Save Path': \"N/A (Baseline)\"\n",
        "})\n",
        "\n",
        "# Add results for each pruning ratio\n",
        "sorted_ratios = sorted(pruning_results.keys())\n",
        "for ratio in sorted_ratios:\n",
        "    res = pruning_results[ratio]\n",
        "    if 'error' in res:\n",
        "         data_for_df.append({\n",
        "            'Ratio': f\"{ratio:.2f}\",\n",
        "            'Params': \"ERROR\", 'Param Reduc %': \"ERROR\",\n",
        "            'GFLOPs': \"ERROR\", 'GFLOP Reduc %': \"ERROR\",\n",
        "            'mAP': \"ERROR\", 'mAP50': \"ERROR\",\n",
        "            'Avg Inf Time (ms)': \"ERROR\",\n",
        "            'Save Path': res.get('save_path', 'ERROR')\n",
        "         })\n",
        "         # Optionally print error during summary generation\n",
        "         # print(f\"\\nERROR details for ratio {ratio:.2f}: {res['error']}\")\n",
        "    elif res.get('params', -1) == -1 and res.get('gflops', -1.0) == -1.0:\n",
        "        # Handle cases where loop might have skipped without explicit error key\n",
        "         data_for_df.append({\n",
        "            'Ratio': f\"{ratio:.2f}\",\n",
        "            'Params': \"SKIPPED\", 'Param Reduc %': \"SKIPPED\",\n",
        "            'GFLOPs': \"SKIPPED\", 'GFLOP Reduc %': \"SKIPPED\",\n",
        "            'mAP': \"SKIPPED\", 'mAP50': \"SKIPPED\",\n",
        "            'Avg Inf Time (ms)': \"SKIPPED\",\n",
        "            'Save Path': res.get('save_path', 'SKIPPED')\n",
        "         })\n",
        "    else:\n",
        "        # Format valid results\n",
        "        data_for_df.append({\n",
        "            'Ratio': f\"{ratio:.2f}\",\n",
        "            'Params': f\"{res.get('params', 0):,}\",\n",
        "            'Param Reduc %': f\"{res.get('param_reduc%', 0.0):.2f}\",\n",
        "            'GFLOPs': f\"{res.get('gflops', -1.0):.2f}\" if res.get('gflops', -1.0) >= 0 else \"Error\",\n",
        "            'GFLOP Reduc %': f\"{res.get('gflop_reduc%', 0.0):.2f}\" if res.get('gflops', -1.0) >= 0 else \"Error\",\n",
        "            'mAP': f\"{res.get('mAP', -1.0):.4f}\" if res.get('mAP', -1.0) >= 0 else \"N/A\",\n",
        "            'mAP50': f\"{res.get('mAP50', -1.0):.4f}\" if res.get('mAP50', -1.0) >= 0 else \"N/A\",\n",
        "            'Avg Inf Time (ms)': f\"{res.get('avg_inference_ms', -1.0):.2f}\" if res.get('avg_inference_ms', -1.0) >= 0 else \"N/A\",\n",
        "            'Save Path': res.get('save_path', 'N/A')\n",
        "        })\n",
        "\n",
        "# --- Create DataFrame ---\n",
        "df = pd.DataFrame(data_for_df)\n",
        "# Set Ratio as index AFTER creating DataFrame for better control when saving CSV\n",
        "df.set_index('Ratio', inplace=True)\n",
        "\n",
        "# --- Save to CSV ---\n",
        "print(f\"\\nSaving results summary table to CSV: {csv_filepath}\")\n",
        "try:\n",
        "    # index=True saves the 'Ratio' column which is now the index\n",
        "    df.to_csv(csv_filepath, index=True)\n",
        "    print(\"  CSV results saved successfully.\")\n",
        "except Exception as e_csv:\n",
        "    print(f\"  ERROR saving results to CSV: {e_csv}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "# --- Print Summary Table To Output ---\n",
        "print(\"\\n--- Summary Table ---\")\n",
        "if not df.empty:\n",
        "    # Display relevant columns - adjust columns if needed\n",
        "    display_columns = ['Params', 'Param Reduc %', 'GFLOPs', 'GFLOP Reduc %', 'mAP', 'mAP50', 'Avg Inf Time (ms)']\n",
        "    # Filter out columns that might not exist if all runs failed, etc.\n",
        "    display_columns = [col for col in display_columns if col in df.columns]\n",
        "    if display_columns:\n",
        "         print(df[display_columns])\n",
        "    else:\n",
        "         print(\"No valid metric columns found to display in table.\")\n",
        "else:\n",
        "    print(\"No pruning results to display.\")\n",
        "\n",
        "# --- Print Saved Model Locations ---\n",
        "print(\"\\n--- Saved Model Locations ---\")\n",
        "if not df.empty and 'Save Path' in df.columns:\n",
        "    # Iterate through the DataFrame to print paths cleanly\n",
        "    for ratio_idx, row in df.iterrows():\n",
        "         print(f\"Ratio {ratio_idx}: {row['Save Path']}\")\n",
        "else:\n",
        "     print(\"No models were saved or results DataFrame is empty.\")\n",
        "\n",
        "print(\"\\n--- End of Summary ---\")"
      ],
      "metadata": {
        "id": "CMqLCXXn5coi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499b34ad-1cc2-4994-c044-30573a632180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Summary and Saving Results ---\n",
            "\n",
            "Saving detailed results to JSON: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruning_results_summary.json\n",
            "  JSON results saved successfully.\n",
            "\n",
            "--- Baseline Model Metrics (for reference) ---\n",
            "Parameters: 39,877,769\n",
            "GFLOPs: 204.87\n",
            "mAP: 0.1168\n",
            "mAP50: 0.2639\n",
            "Avg Inference Time (ms/batch): 196.28\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "--- Pruned Model Metrics Summary ---\n",
            "\n",
            "Saving results summary table to CSV: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruning_results_summary.csv\n",
            "  CSV results saved successfully.\n",
            "\n",
            "--- Summary Table ---\n",
            "              Params Param Reduc %  GFLOPs GFLOP Reduc %     mAP   mAP50  \\\n",
            "Ratio                                                                      \n",
            "Baseline  39,877,769          0.00  204.87          0.00  0.1168  0.2639   \n",
            "0.10      36,535,561          8.38  191.19          6.68  0.0915  0.2250   \n",
            "0.20      33,827,049         15.17  180.16         12.06  0.0236  0.0544   \n",
            "0.30      31,162,281         21.86  171.21         16.43  0.0000  0.0000   \n",
            "0.40      28,882,313         27.57  161.91         20.97  0.0000  0.0000   \n",
            "0.50      26,899,209         32.55  156.28         23.72  0.0000  0.0000   \n",
            "\n",
            "         Avg Inf Time (ms)  \n",
            "Ratio                       \n",
            "Baseline            196.28  \n",
            "0.10                194.61  \n",
            "0.20                195.88  \n",
            "0.30                193.88  \n",
            "0.40                190.35  \n",
            "0.50                188.51  \n",
            "\n",
            "--- Saved Model Locations ---\n",
            "Ratio Baseline: N/A (Baseline)\n",
            "Ratio 0.10: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.10\n",
            "Ratio 0.20: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.20\n",
            "Ratio 0.30: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.30\n",
            "Ratio 0.40: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.40\n",
            "Ratio 0.50: /content/drive/MyDrive/kitti_torch_pruning_results_v2/pruned_ratio_0.50\n",
            "\n",
            "--- End of Summary ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjjOibOkaDTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}